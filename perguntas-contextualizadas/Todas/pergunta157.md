**Pergunta 157**: Quais são os dois tipos de erros que podem ocorrer no processo de aprendizado de máquina?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 3447
- *Score:* 0.8657625913619995
- *URL:* oculto
- *Início:* 01:28:09
- *Fim:* 01:30:20
- *Transcrição:* mesmo erro que vai para camada anterior ele vai lá para o começo também vai ajudar o eu nesse tamanho aqui né vai ajudar atualizar essa camada Inicial então todo esse errinho é o gradiente que tava começando a sumir aqui ele foi somado né que ele foi somado com o erro que veio de lá de longe né porque a rede neural passa como tem informação né ela transmite essa informação lá longe Então ela recebe o erro lá de longe também e isso ajuda bastante evitar o gradiente que some Ah tá E aqui o atalho que não é de informação Passando só a entrada direto e aqui processando né uma camada uma Olha que interessante né agora não tem só um caminho né de processar a imagem de convolução tem dois né Então essa isso aqui recebe não só a saída dessa convolução mas recebe a saída dessa também né e ou seja Lembra daquela ideia de que as camadas né vão pegando características de baixo nível aqui retas aqui Quinas sei lá e vai compondo aqui né aqui quadrado na hora que eu junto aqui ó eu junto o que vem dessa camada que pegou a imagem né então eu meio que volta a olhar de novo característica de baixo nível e agrega com outras características de alto nível então isso pode ser benéfico também para fazer predições né E na hora de treinar também ajuda muito né que essa aqui que tá com coisa de baixo nível vai receber né um erro aqui ó bem maior né do que essa pelo caminho normal né que essa aqui receberia é o erro que iria sumindo com ao passar pelas camadas né então o que que acontece toda vez que o erro passa por uma camada ele tem tendência de diminuir né E nesse caso como eu tenho um salto aqui ó como eu tenho um salto né Então essa aqui recebe um erro que passou por menos camadas do que esse aqui que recebeu um erro que passou por três camadas

- *Corpus ID:* 3415
- *Score:* 0.8629000782966614
- *URL:* oculto
- *Início:* 00:30:35
- *Fim:* 00:33:10
- *Transcrição:* complexidade aqui ó complexidade no eixo X o modelo vou colocar o t aqui de time ele tem né um erro aqui de treino tá sei lá nessa medida aqui azul né um erro de validação aqui ambos autos né alto erro que considerar como alto aí vem o modelo médio que é o laranja aliás vou colocar o verde aqui que é o laranja tá não vou colocar todos então o médiozinho que é o verde aí ele tem um erro médio aqui não quer dizer que é o melhor tá é só que é complexidade aqui é o minúsculo pequeno intermediário e grande Tá é só isso E aí o médio tem um erro de treino mais baixo mais um erro de validação mais alto ele vai lançar mais alta e o modelo maior ali que é o vermelho colocar o arde aqui ó large que é o vermelho tem um trevo de treinar ainda mais baixo e um erro de validação ainda mais alta ainda mais alta então Digamos que né o ponto ótimo já foi ultrapassado aqui no modelo médio mas olha que interessante aqui a ideia é será que será que não é o caso que porque a gente tá num probleminha aqui né do modelo desse pequeno para o médio já teve um salto né o erro de validação ó no erro no pequeno no laranja termina aqui e no Médio já tem essa explosão aqui gigantesca tá é muito um salto muito grande será que não tem alguma coisa que daria mesmo que eu tenha um modelo um pouco que a princípio parece demais Será que não tem como eu fazer alguma algum ajuste aqui no modelo alguma coisa que eu possa colocar no treinamento desse modelo que impeça que isso aqui de acontecer nesse o erro de treino ser tão baixo mas o erro de teste ser tão alto e a boa notícia é que sim existe né é são técnicas que a gente pode usar em redes neurais que combatem o overfite Tá aí uma delas é a regularização outra é o droppauts eu vou falar delas agora ou seja se a gente tem uma rede

- *Corpus ID:* 1061
- *Score:* 0.8622552156448364
- *URL:* oculto
- *Início:* 00:00:07
- *Fim:* 00:02:34
- *Transcrição:* Tá então vamos falar de métricas e de avaliação Tá bom então Alguém já me perguntou ali ai a melhor coisa que é igual a acurácia Então vamos falar ali eu falei sobre os problemas de overfitem lá e aí a gente tem que entender que tem dois tipos de erros tá nesse processo de aprendizado um chamado erro de treino eu aparente o erro de substituição que é o número de instâncias que eu classifico erroneamente na minha função de mapeamento no caso que eu ilustrei ali da árvore de decisão seria um instâncias que eu cheguei lá numa folha e bom a maioria tá classificada com aquele rótulo x lá mas por falta de opção tem um que tá misturado isso que seria o chamado erro de trem os erros chamados de generalização são erros onde eu tô avaliando a minha capacidade de fazer pressão e por isso que eu disse às vezes é melhor a gente ter um modelo menos ajustados aos dados Nos quais a gente treinou mas com uma maior capacidade de analisar para pegar uma situação que eu nunca vi e tentar usar minha função de mapeamento para atribuir um rótulo Então os bons modelos eles vêm desse erro baixo de treinamento né Mas acima de tudo dessa capacidade de realização que quer dizer na verdade capacidade de predição para ilustrar essa diferença né Eu queria passar rapidamente por situações que são reais imagina que eu quero saber se um animal é mamífero ou não tá E aí então eu tenho aqui vários animais porco espinho gato morcego baleia salamandra dragão de komodo anaconda salmão águia e copia não me lembro exatamente o que que é E aí de acordo com esses critérios aqui de temperatura do corpo se ele tem filhotes ou não se ele tem quatro portas ou não você libera ou não eu tenho o meu rótulo sim se ele é mamífero e não se ele é não mamífero tá essas instâncias aqui são instâncias malclassificadas Então erroneamente o meu morcego e a

- *Corpus ID:* 3408
- *Score:* 0.8597962856292725
- *URL:* oculto
- *Início:* 00:17:51
- *Fim:* 00:20:07
- *Transcrição:* a curva aqui não é tão suave mas a tendência vai ser essa só que o modelo simples é um modelo simples vai estar com erro alto ó erro alto no treino que a linha azul aqui e eu alto no teste também mesmo que o GAP aqui seja baixo né o erro de treino o erro de teste esteja próximo do erro de treino o eu de treino tá alto né de 30 alto mas para saber se é alto mesmo eu vou e aumenta a complexidade ou entrei no modelo com essa complexidade aqui complexidade aqui para nós em termos de redes ne tá é número de camadas e número de neurônios por camada ou filtros né filtros e neurônios por camada um caso resto convolucionais né enfim cada tipo de rede Vai ter o que que é a complexidade tá então você treinou aqui o primeiro modelo seu não tinha nenhuma camada oculta digamos assim aí você treinou o segundo modelo com uma camada oculta E aí você treinou o modelo adicionou camada convolucional e mais camada oculta assim foi né Assim se for que vai aumentando a complexidade E aí chegou nesse cara que eu tinha esse erro de de treino e esse erro de generalização né na validação tá E aí depois o modelo mais complexo de todos botar lá cinco camadas ocultas 10 convolucionais etc o erro de treino foi baixinho mas na hora de testar o erro foi muito grande então aqui é o over Fitness que se mudar um pouquinho né o os dados ali de ficar um pouquinho diferente do que ele viu no treino né ele o erro vai lá em cima ou seja ele não consegue generalizar ele não aprende o padrão né subjacente ali aos dados ele não aprende ele aprendeu decorou cada ponto de dados aqui né então ele decorou tipo assim que a imagem em um é um gato a imagem dois é um cachorro aí você vê outra imagem que não é a imagem 1 mas que seja um gato ele se perde Então isso é o ver filho e nesse modelo intermediário aqui ó é o que teve o menor erro de generalização

- *Corpus ID:* 1504
- *Score:* 0.8592813014984131
- *URL:* oculto
- *Início:* 01:55:02
- *Fim:* 01:57:08
- *Transcrição:* com aprendizado de máquina e a gente olhar para os dados olhar para os dados e encontrar questões ali nos dados que eventualmente vamos chamar atenção né Por exemplo se a gente olhar para os atributos e a distribuição deles por classe ali a gente consegue já perceber alguns atributos que tem um valor muito diferente entre as classes Então são atributos que Possivelmente são relevantes para aquele problema né então são essas questões a mais para acostumando vocês olharem e analisarem assim criticamente esse tipo de dado tá professora sem querer pressionar ou aperrear pela correção assim mais a gente consegue ter um feedback assim do primeiro mais ou menos quando é porque eu percebi que o segundo temas perguntas que envolve o primeiro é tipo assim eu fiz uma percepção errada muito errada de dados eu vou continuar errando né daqui para frente né sim é assim ó eu não vou conseguir garantir né infelizmente da gente ter resposta no primeiro antes do entrega desse segundo tá então essas essas novas monitoras elas começaram a trabalhar no curso essa semana então agora por exemplo todo esse material que está sendo entregue né a entrega desse do um tá até domingo né se eu não me engano era é eu pedi que você estivesse até hoje né idealmente Mas eu deixei no mundo até domingo Então me diga que eu ver por exemplo tá é então é bom eu não vou mudar isso agora mas fechando a tarefa eu vou passar para elas tá então realmente essa primeira eu não vou conseguir que elas entreguem para vocês antes a entrega do segundo Tá mas a ideia é que a gente possa não demorar muito nesse feedback foi uma coisa que eu conversei com ela sobre isso também né Para a gente tentar se para organizar para que o mais rápido possível tem o feedback e usem esse feedback para melhorar nos próximos exercícios

- *Corpus ID:* 4370
- *Score:* 0.8587351441383362
- *URL:* oculto
- *Início:* 01:07:10
- *Fim:* 01:09:16
- *Transcrição:* vezes o erro tá o erro então deixa eu colocar o erro aqui por enquanto tá ok a gente ainda não só não especificou o erro né Nós vamos especificar o que que é o erro Professor a diga eh será eu tô pensando aqui por que aquelas equações eh esse essa questão da diferença ali de predição menos alv menos predição é será que nas redes neurais eu queria diminuir né o erro e e agora eu quero aumentar alhe a recompensa tem a ver com isso será Talvez Mas de qualquer forma eu quero diminui o erro da estimativa também né Essa estimativa aqui tem um erro né esse erro aqui inclusive né É É um pedaço dele e eu quero diminuí-lo também né tanto que de uma forma ou de outra eu tô diminuindo o erro só escrevi o erro de outro jeito né mas talvez tenha a ver um pouco disso né no aprendizado por reforço que é maximizar então bota o mais ali no sentido de é uma subida de Gradiente né em vez de uma descida de Gradiente talvez não tudo bem Beleza não só fiquei pensando nisso aí mas é mas pode ser um raciocínio mesmo que possa né estar embutido lá na no momento que que foi concebido nessa essa regra de atualização talvez tenha a ver com com essa ideia de maximizar mesmo ã Mas então tá ó então estamos com agora a gente vai expandir o que que é o erro aqui tá eh e vamos lá né o erro alvo menos predição predição é justamente isso aqui ó o que que eu esperava ganhar né então vamos lá nosso Delta é igual alvo menos né O que que eu esperava ganhar por ter feito a ação no caso de pra esquerda lá no Grid né naquele estado que eu tava eu esperava ganhar o zero que eu tinha lá né o o valor Q Q né a o próprio desenho aqui do Grid é a tabela q viu gente Então nesse estado aqui ó né na primeira linha segunda coluna os valores q né de para cima pra esquerda para baixo e pra direita né estão são essa tabela estão

- *Corpus ID:* 2304
- *Score:* 0.8583973050117493
- *URL:* oculto
- *Início:* 00:06:43
- *Fim:* 00:08:51
- *Transcrição:* referências Caso vocês queiram analisar outros algoritmos tá desculpa então quando a gente tá falando tipo de erros em teste de hipótese basicamente tem dois tipos o erro tipo um e o erro tipo 2 o erro tipo um são falsos positivos e o erro Tipo dois são falsos negativos então quando a gente tem o falso positivo é basicamente quando a gente tem essa hipótese nula verdadeira Mas ela é rejeitada por esse teste tá então em aprendizado de máquina né esse esse hipótese nula hipótese de igualdade né então basicamente a gente tá sumindo que dois modelos diferentes possuem um desempenho equivalente certo então eles são diferentes mas o desempenhos São equivalentes tá então quanto eu digo que a minha hipótese é nula que é essa daqui ou seja que os meus modelos eles têm o desempenho equivalente quando eu rejeito ela então basicamente eu tô dizendo que o desempenhos são diferentes que um modelo é melhor que o outro então isso me dá um falso positivo é dizer que há uma diferença significativa de desempenho entre dois modelos quando na verdade não há erro Tipo dois seria falso negativo é quando a hipótese não é falsa e não é rejeitada Ou seja eu tenho uma diferença real e significativa no desempenho mas eu falo em detectar por limitações do teste em aprendizado de máquina as particularidades que a gente tem da forma como a gente avalia os modelos é que a gente tem muitas fontes de variações diferentes dos Testes estatísticos Ou pelo menos variações que não foram talvez previstas né nos testes estatísticos para serem controlados ou minimizadas a gente tem a variação aleatória nos dados de teste nos erros de classificação Então os dados de teste mudam e isso com certeza obviamente muda a avaliação do modelo avaliação aleatória do modelo em razão da seleção de dados de Treinamento Então essa essa divisão treine teste faz

- *Corpus ID:* 8168
- *Score:* 0.8578283786773682
- *URL:* oculto
- *Início:* 00:32:34
- *Fim:* 00:34:56
- *Transcrição:* eu tivesse um dataset gigantesco fica humanamente impossível analisar cada falha a partir de que momento que você consegue a aceitar os erros esse erro é aceitado normalmente é eh isso se dá pel aquelas métricas de acurácia F1 macro Por exemplo quando a gente vê um 92 ali a gente sabe que Isso tá muito bom tem erros tem e aqui nesses erros não tá bom de ver aqui eu de fato não sei dizer agora o que aconteceu que isso aqui deveria est o texto original mas tem erros que são erros da estrela como a a professora Viviane falou anteriormente a pessoa deu uma revisão negativa mas ela colocou cinco estrelas sabe e e na verdade o algoritmo acertou a anotação que tá errada tá então quando tem esse tipo de erro é é só revisar aota e entender o Limiar que tu tá me pedindo aqui numa decisão de negócio por exemplo eu posso usar esse classificador em produção pode 92% dos casos ele Tá acertando eu já tenho acura tá claro que o acompanhamento disso em produção deve ser feito então tu tem que tirar amostras ali no dia a dia tá do como é que se chama o o operational machine learning né que tá muito em voga agora assim como é que tu vê isso até que ponto teu classificador tá bom amanhã a gente insere um novo produto a Americanas Colocam um novo produto que tem features e né coisas eh explicações assim que não vão ser tão simples da gente ver por exemplo a gente falar que um ar condicionado tá gelando muito né é uma coisa positiva mas talvez para um outro produto gelar ah ou fininho e coisas assim elas podem não ser positivas enquanto que para outras para um notebook ser fininho é uma coisa boa né então eu tudo isso tem que ser analisado o limar aqui o corte essas métricas e sempre mais de uma né Não não é uma coisa assim que tu vai pegar só a Cura Tu vai olhar fil macro também talvez a matriz de confusão entender estamos

- *Corpus ID:* 2057
- *Score:* 0.8575615286827087
- *URL:* oculto
- *Início:* 00:11:18
- *Fim:* 00:13:23
- *Transcrição:* que ele é sequencial por isso que eu não consigo fazer um treinamento paralelo Porque dependendo dos erros dos modelos anteriores além disso a gente pode perceber que os pesos Associados às instâncias que ele classificou corretamente diminuíram certo então isso reforça ainda mais essa diferença né que o próximo modelo aprenda a partir de alguns pelo menos algumas dessas instâncias que o anterior não conseguiu acertar E cada vez que eu treino modelo desculpe esse algoritmo ele tem uma taxa de erro e uma taxa de confiança certo calculada em função da qualidade desse desse modelo tá existem diversas formas para fazer isso não vou entrar em detalhes aqui de como especificamente esses valores foram gerados tá mas se eu tivesse digamos assim dados de validação para cada modelo eu conseguiria estimar um nível de confiança poderia ser uma acurácia enfim dependendo da métrica tá então eu tenho aqui associado como se fosse uma qualidade do modelo e os erros desse modelo então daqui desse cenário de dois parte né vai partir digamos assim amostragem de dados para o segundo modelo tá vamos supor que esse segundo modelo ele a mostrou os dados para treinar e ele acabou aprendendo essa Fronteira de decisão tá então com base nos dados que foram mostrados para o treinamento provavelmente né envolvendo essas instâncias erradas ele gerou essa Fronteira de decisão de novo uma fronteira de decisão com alto viés também poderia ser a mesma árvore decisão com a profundidade máxima de um E aí a gente pode perceber que esse modelo ele também comete erros né então ele tem essas instâncias à direita ele vai classificar como negativo pelo por uma questão de proporção de instâncias por classe a esquerda como positivo isso faz com que ele acerte todas essas

- *Corpus ID:* 3010
- *Score:* 0.8559082746505737
- *URL:* oculto
- *Início:* 00:15:29
- *Fim:* 00:17:47
- *Transcrição:* 50 mil E aí ele vai testar outro então agora eu vou testar ou foi igual a zero ponto sei lá 10 a menos cinco é ele mudou radicalmente aqui bem bem baixo que aí vai ser o laranjinha ó é o mesmo neurônio tá o mesmo sigmoide mesmo arquitetura né digamos assim mas aí ele testa aliás os laranjinha não a laranjinha foi bom né então o verdinho aqui aí ele executa esse com Alfa igual a essa taxa aqui de aprendizado aí ele faz o treinamento todo ao final de 10 mil épocas ele chega no custo final sei lá de 10 e aí ele vai testar outro valor vamos pôr laranja aqui é o terceiro alvo que ele testa terceiro Alfa que aí é 0.01 é 10 vezes menor que o primeiro aí depois das aí ele vai medindo erro em cada época do treinamento e aí chega ao final das 10 mil obtém o erro final e o final igual a sei lá e é isso se a gente só deu três tentativas para ele aí no final das três tentativas ele vai dizer o melhor Alfa É esse aqui né aí a gente pega esse alfa e vai treinar vai ser esse Alfa que a gente vai usar né no fim das contas para nossa rede neural a minha dúvida não tá especificamente aí não mas é porque esse erro que você calcular o final ela é uma aplicação da função de curso não é isso a questão de curso aí então ele está no seguinte na hora que você diz quantas épocas ele vai ele vai ter que tal ele vai ter que calcular ele vai ter no final para cada época um valor para a função de custo e aí ele vai saber o que que ele vai fazer com esse alcancelado Ah vou diminuir vou aumentar tudo bem o que eu tô dizendo o seguinte a função de custo Quando é o problema é de regressão linear assim a gente a gente só vai fazer uma vez desculpa a gente vai fazer essas essa essas 10 mil épocas quando o


**Resposta gerada pelo LLM**: Erro de treino (ou aparente) e erro de generalização.

**Referências**:
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should accurately identify the two types of errors in the machine learning process. Supporting Evidence: The RESPONSE correctly identifies "erro de treino" (training error) and "erro de generalização" (generalization error) as the two types of errors that can occur in machine learning. This directly addresses the PROMPT, providing a complete and accurate answer.  Score: 3


---
