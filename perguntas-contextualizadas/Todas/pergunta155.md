**Pergunta 155**: Como o algoritmo Naive Bayes lida com atributos numéricos?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 1569
- *Score:* 0.877121090888977
- *URL:* oculto
- *Início:* 00:00:02
- *Fim:* 00:02:06
- *Transcrição:* falou de atributos categóricos eu queria mostrar para vocês a base de como algoritmo calcula com atributos numéricos que inclusive foi uma das perguntas que a gente teve do Antônio ali no início como é que posso trabalhar com atributos numéricos Tá eu vou falar um pouco que sobre a questão do navez depois eu vou discutir com vocês essas particularidades no site do ano porque vocês vão ver que no site do ano né na biblioteca mesmo original com dados numéricos existem outras bibliotecas que foram propostas depois que calculam desculpa aqui propõe extensões que permitem calcular essas probabilidades com atributos mistos numéricos e categóricos sem esse orçamentos Então a gente vai discutir aqui só para você ter ideia do que acontece né que você se preocupa né umas coisas acontecem Mas é para entender porque que a gente vai trabalhar com que a gente chama gauchen na ebays gaussiano tá então quando a gente tem atributos numéricos a gente tem algumas opções né as principais que a gente normalmente escute é bom eu vou no pré-processamento desses dados discretizar os valores dos atributos Isso Quer Dizer Que atributos numéricos né lembrando tô falando com atributos numéricos agora eu vou descritizar em faixas a partir da distribuição dos dados em Fatos pré-determinadas por exemplo tem um valor que me lembro agora a questão do IMC eu posso usar as categorias os pontos de corte para determinado para categorizar aquilo abaixo do Peso né o peso ideal sobrepeso enfim ou se é uma outra idade uma outra informação como idade eu posso pegar distribuição desses dados e olha disseram até as 20 de 21 a 30 entende eu posso terminar essas esses pontos de corte E aí descritizar esses processos

- *Corpus ID:* 1579
- *Score:* 0.8684929013252258
- *URL:* oculto
- *Início:* 00:16:02
- *Fim:* 00:18:20
- *Transcrição:* da prática e do que que acontece lá no naive-10 no site com mais bens então na prática se eu tenho atributos mistos numéricos e categóricos eu poderia usar como é que eu poderia calcular para homenagem posteriori a probabilidade de uma classe da probabilidade que a multiplicação das probabilidades condicionais dos categóricos a multiplicação dos numéricos e isso me daria uma probabilidade única posterior funcionaria super bem né então isso acontece é muito prático digamos assim teórico de lidar com atributos mistos porque como eu posso assumindo a independência condicional basta analisar probabilidade total dos categóricos faculdade total dos numéricos né as condicionais multiplicar a probabilidade da classe e ter então a minha posteriori essa daqui aí Claro que vai acontecer aqui na prática Dependendo de qual ferramenta a gente tá usando que implementam e fez não vai deixar a gente fazer isso e essa é a questão do sexto ano o site ele tem duas implementações principais né para lidar com dados estruturados categórico ou NB e para os numéricos o gaucho NBA tá então já percebam que eu tenho duas funções diferentes cada uma lida com um tipo de dado Tá qual é a nossa solução para trabalhar com dados mistos que que vocês acham que a gente poderia fazer usando o site plano dentro do que a gente discutiu exatamente uma possibilidade né eu posso transformar numérica em categórico e usar só o categórico isso isso seria é bem prático de fazer a outra possibilidade é eu separar pegar dados categóricos analisar categóricos numéricos analisar com cálcio na Space E aí juntar essas probabilidades

- *Corpus ID:* 1542
- *Score:* 0.8657115697860718
- *URL:* oculto
- *Início:* 00:57:40
- *Fim:* 00:59:53
- *Transcrição:* atributo numérico mesmo usando alguma distribuição de probabilidade Dá Uma segurada aí que já vai já vai discutir exatamente esses pontos tá eu acho que vai ficar bem claro porque tem exemplos aqui como é que a gente pode fazer Então vamos lá bom tá então justamente né falando agora do cálculo das probabilidades a gente vai fazer alguns exemplos com base em alguns dados aqui para a gente discutir bom a probabilidade da classe Y ela é estimada a partir da contagem de cor outras instâncias pertencem aquela classe Y em função de todas as instâncias que eu tenho nos meus dados tá então por exemplo se eu tenho a probabilidade de spam por exemplo a gente vai ver que é o número de e-mails spam dividido pelo né por número de e-mail geral ou seja spam não spam tá soma de todos tá então é uma contagem assim como a gente tava tava comentando o Antônio tinha perguntado dessa questão quando a gente tá falando dos atributos a forma que a gente estima esse esse cálculo também essa probidade também vai depender se eles são categóricos ou numéricos E aí eu já adianto que os categóricos vão funcionar de uma forma muito parecida com isso contagens e os numéricos a gente vai poder trabalhar de duas formas que é Ou discretizando eles ou usando uma distribuição de probabilidade para calcular a probabilidade de um valor numérico especificamente tá eu bom antes de aqui tem algoritmo leveza você não gosta de colocar né tipo pseudo algoritmo assim quando a gente pode quando a gente está trabalhando com algoritmo que é relativamente simples mas eu vou eu vou passar na ideia desse do nariz agora e na sequência a gente vai discutir essa questão de como calcular as probabilidade com um exemplo em que a gente vai justamente aplicar esse algoritmo para vocês entenderem tá são algoritmo ele ele calcula a

- *Corpus ID:* 1846
- *Score:* 0.8634612560272217
- *URL:* oculto
- *Início:* 01:04:42
- *Fim:* 01:06:45
- *Transcrição:* esse atributo a raiz atributo raiz ele é muito importante porque quando eu tinha todos os dados ele foi o mais informativo né claro que existe formas diferentes aos sumérios a essa importância com base numa árvore a gente vai discutir na disciplina seguinte mas se eu tiver que escolher um atributos e olha isso é muito importante da raiz tá a Carolina tem uma pergunta pode falar professora como é que a gente lida com problemas eu tô lembrando lá da dinâmica do nave Davis onde a gente tinha atributos numéricos e categóricos misturados né e a gente tinha duas abordagens para fazer a classificação se isso acontece aqui como é que a gente faz isso é uma coisa boa assim aqui em árvores de decisão Ela é bem flexível para isso tá ele é um é um dos modelos mais flexíveis porque ele é um modelo que não assume distribuição dos dados ele é um modelo que não faz comparação entre instâncias Então aquela questão da normalização ele não é impactado e nessa questão de atributos diferentes tipo categóricos e numéricos eles os algoritmos conseguem lidar com isso tá porque para o categórico ele vai fazer os Ramos né dividido de acordo com os valores das categorias tá então todos os valores possíveis se for grande formação ou divisões binárias né com base nos conjuntos se foram num médico ele vai testar um ponto de corte idade menor ou igual a 35 esse 35 ele não chegou aleatoriamente ele testou valores de 35 ele tem uma estratégia interna para pegar alguns valores que são mais promissores e entre esses mais promissores e a qual divide melhor as classes então ele lida automaticamente com isso Só que essa parte dos atributos numéricos ele é um custo computacional mais alto para o algoritmo então não quer dizer que ele não se beneficia de um pré-processamento se a gente tiver um

- *Corpus ID:* 1536
- *Score:* 0.8605875372886658
- *URL:* oculto
- *Início:* 00:48:08
- *Fim:* 00:50:20
- *Transcrição:* isso isso nunca apareceu sem um problema para o navbess a um nave base assim ele tem ele é um algoritmo que é muito utilizado foi muito utilizado inclusive para cálculo para análise de spam né quando não existia aprendizado profundo e isso nunca foi nunca foi determinado como fator que prejudicasse a ocorrência do nariz deles é claro que isso não vê esta sendo aplicado em dados que são muito correlacionados entre si os atributos obviamente ele vai ele ele sofre um pouco mais no sentido assim de que existe essa correlação ele não tá conseguindo absorver nada dessa correlação porque ele olha para os atributos separadamente então ele não tá conseguindo se utilizar dessa informação né porque ele olha separadamente então ele vai considerar sei lá idade e ano de nascimento são totalmente Independentes embora estejam altamente correlacionados Tá mas isso nunca foi nunca era extremamente importante a gente normalizar porque se a escala entre se a escala todos ou muito diferentes é uma determinada escala muito grande aquele atributo nunca vai ter um peso digamos suficiente para que eu ele eu procuro um vizinho mais próximo baseado nos valores daquele atributo né Porque quanto mais mais quanto maior os valores né ele vai acabar calculando cálculo da distância uma distância maior essa distância maior eu não quero eu quero as distâncias menores e nesse caso Então tudo na evidez é extremamente necessário a gente fazer o que a gente remover os atributos que são altamente correlacionados E aí ele funciona melhor seria isso isso Exatamente esse esse tipo de algoritmo é essa esse pré-processamento para achar os atributos relacionados normalmente É vantajoso né Por nave base Exatamente é que como eu falei ele ele até certo ponto robusto a isso mas assim

- *Corpus ID:* 2121
- *Score:* 0.8595863580703735
- *URL:* oculto
- *Início:* 00:25:06
- *Fim:* 00:27:28
- *Transcrição:* seguinte mas uma das formas possíveis por exemplo seria codificar esses valores como numéricos tá então aqui por exemplo Sei lá eu vou colocar zero um e dois tá então basicamente tudo que é boa eu vou usar o valor dois desculpe tudo que é regular eu vou usar o valor 1 e tudo que é ruim eu vou usar o valor zero Isso é uma forma de fazer isso aí deixou até criar uma página aqui nova porque isso acho que é uma coisa interessante tem até algumas perguntas que eu acho que em relação a isso mas só para a gente pensar vamos porque eu tenho um atributo avaliação tá E essa avaliação como eu falei ela pode ser boa regular o ruim tá então uma das abordagens seria como eu falei né a gente atribui valores numéricos a esses atributos né ao valor de atributos então eu vou eu sugerei colocar dois um e zero por exemplo tá isso seria uma uma possível abordagem para atributos que não são nominais né que são atributos que não têm ordem implícita né então se você lembrar nada das primeiras aulas a gente falou que os dados categóricos podem ser originais ou nominais então originais Eles não têm ordem explícita entre eles ordem esperada nenhuma ordem de grandeza de importância enfim nada e os nominais eles possuem uma ordem né então existe uma outra abordagem que quando a gente tá falando com esses atributos que não possuem uma ordem entre eles é que é usar o que a gente chama de One hot and coulder Tá o que que esse onehot and colder vai fazer ele vai pegar cada valor desse atributo e transformar numa variável binária uma variável binária que vai ser zero ou um né então se aquela Instância tem o valor boa quer dizer que boa tem que ser um e todos os outros tem que ser zero e uma outra

- *Corpus ID:* 2124
- *Score:* 0.8592805862426758
- *URL:* oculto
- *Início:* 00:30:17
- *Fim:* 00:32:32
- *Transcrição:* não né mas a questão é que numericamente é isso que vai acontecer numericamente eu vou ter o dobro de distância ou seja duas vezes mais diferente mais distante boa de ruim do que regular de ruim então qualquer momento que eu pegar valores categóricos mesmo valores que tenham uma horta implícita né então por exemplo um exemplo que eu sempre dou são se eu tô falando de classificar uma peça de roupa se a pessoa vai comprar ou não e tem o tamanho da peça então vou ter p m e g por exemplo tá então poderia dizer olha é 0 1 e 2 enfim menos um zero e um a questão toda a gente pensar o seguinte a diferença numérica que vai surgir dessas comparações no momento que for comparado duas instâncias para não cair ele no sdm faz sentido para árvore de decisão não teria nenhum problema pode ficar boa como dois regular como um ruim como zero porque a árvore de decisão não faz esse tipo de comparação Mas mesmo não faz esse tipo de comparação agora KNN redes neurais svm regressões eles vão realmente comparar numericamente E aí a questão é a gente pensar e aquela diferença aritmética que a gente está observando né Um Valor numérico faz sentido do ponto de vista da semântica dessa atributo né então esse seria o problema uma coisa pensar nessas escolhas tá que por exemplo Alexandre comentou Será que né usar menos um zero e um então é um é um é um ponto a considerar Mas de fato isso pode a escolha desses números né que vão representar as categorias realmente pode mudar não necessariamente vai ser zero um dois três assim por diante eu posso eu posso então adotar com o padrão do meu projeto usar sempre One hot hot Rosen independente ela é ordenada ou não assim do ponto de vista do algoritmo pode pode porque mesmo qualquer algoritmo vai lidar bem com isso Tá Mas sempre tem umas né e o que que seria o problema

- *Corpus ID:* 1592
- *Score:* 0.8586573600769043
- *URL:* oculto
- *Início:* 00:37:32
- *Fim:* 00:39:52
- *Transcrição:* inteiro tá aqui inteiro aqui inteiro enfim e aí depois eu tenho esses óbvio que são normalmente para gente né no contexto que a gente tá trabalhando aqui significa que eu tenho atributos textuais categóricos né então a gente pode até ver se a gente voltar aqui a gente tem é cimento ao réu física numéricos eu não sei exatamente pode ser um score né não sei dizer exatamente Mas podem ver por exemplo a idade a idade ela não é numérica né um óbvia porque porque ela é uma string aqui um texto né Oi 80 o mais velho de 70 74 tá o Racing e os outros possibilidades aqui isso diabéticos sim ou não então por isso que ele ele Retorna ali o tipo como óbito então para a gente esses óptica eles acabam sendo justamente atributos categóricos tudo bem até aqui pessoal [Música] E aí Claro aqui eu tô só fazendo uma soma do quando a gente falou o nosso DF é o nosso Data Frame eu tô chamando essa função Snow verifica se é nulo né retornaria verdadeiro ou falso para cada coluna do meu Data Frame e em cima desse resultado Tô fazendo uma soma e aí então ele soma todas as vezes isso retorna verdadeiro tá E aí por isso que a gente vai ver o resultado dessa linha 5 tá aqui embaixo ó eu tenho zero para todos porque só uma outra forma de confirmar que eu não tenho valores nulos E aí a gente vai começar a trabalhar um pouquinho os dados para identificar e salvar em digamos assim listas que a gente chama aqui no Python que é uma mesma ideia de um outras linguagens a gente vai ter então um conjunto ali de nomes os atributos categóricos e um conjunto os nomes atributos numéricos tá Por que isso porque a gente é basicamente o que a gente quer fazer aqui é permitir que depois a manipulação

- *Corpus ID:* 1430
- *Score:* 0.8581876158714294
- *URL:* oculto
- *Início:* 01:19:12
- *Fim:* 01:21:15
- *Transcrição:* sem atributos né dependendo Claro do número de Instância sem atributos podes estimativa dimensionalidade muito alta para o número de instâncias que eu tenho para conseguir treinar o meu modelo e é isso impacta porque o que vai acontecer que quando eu tenho uma dimensão muito grande Tá por exemplo sem atributos essa diferença de valor quantitativo né de distância do vizinho mais próximo para o vizinho mais distante vai ser muito pequena vamos porque eu tenho 100 atributos né e eu tenho variações em 10 atributos digamos assim 10 entre 100 a quantidade né o impacto dessa variação no valor de distância final é muito Sutil Então o que acontece é que o algoritmo acaba tendo não funciodo bem digamos assim né perdendo o seu potencial preditivo porque essa essas diferenças né quantitativas entre instâncias próximas realmente semelhantes em distâncias distantes passa a ser muito pequena então ele é um algoritmo que ele se beneficia né Mais Uma Vez Mais um motivo se beneficia do processo de seleção de atributos ou de técnicas de redução de mensalidade como acho que foi o Antônio que comentou o PCA por exemplo tá seleção de atributo é uma forma de reduzir dimensionalidade tá IPCA também é outra forma que é mais a linha que a gente chama de extração de atributos tá Então são duas formas de reduzir a dimensionalidade do meu problema então o PCA eu posso ter um problema com 300 atributos reduzido para 34 dimensões são ficar com as três quatro componentes principais Então isso acaba sendo uma das desvantagens então algoritmo que a gente tem que cuidar um pouquinho quando tem problema com alta dimensionalidade porque o KNN ele passa até essa dificuldade diferenciar o que tá longe o que tá perto porque a medida de distância Varia muito pouco em função do grande número

- *Corpus ID:* 2376
- *Score:* 0.8569189310073853
- *URL:* oculto
- *Início:* 00:13:03
- *Fim:* 00:15:22
- *Transcrição:* com relação a diabetes né então esse hoje não encontra é esse aí perfeito ele faz isso aqui ele faz essa codificação seguindo essa numeração né 0 1 e 2 tem algumas coisas interessantes assim não quer dizer que se o atributo for original vocês não possam aplicar Vocês poderiam poderia botar tamanho P tamanho M tamanho g e tem um vetor tá a questão é que vocês não podem fazer para um atributo nominal Por que que não pode por que que eu digo que não pode né porque se vocês forem desculpem passei sem querer se vocês forem usar uma gama de algoritmos para para verificar por exemplo Qual é o melhor vocês provavelmente vão usar o sbm provavelmente vão usar uma rede neural enfim que são algoritmos que seriam impactados por esse tipo de análise de desculpa de transformação tá porque são algoritmos que fazem análise de distâncias de comparações entre os atributos os vetores Enfim então eu ter ordem né grandezas diferentes para valores que na prática todos possuem a mesma importância a gente não poderia permitir que isso aconteça Agora se vocês tiverem usando mais bens e árvores de decisão mesmo atributos atributos nominais Vocês poderiam fazer essa codificação original porque eles são algoritmos que não tem essa essa não sou impactados porque eles analisam a tributo atributo eles não fazem uma análise por exemplo dois vetores de atributos Qual é a diferença entre eles a distância entre eles a árvore de decisão ela analisa o ganho de Formação por atributo o naipe fez a probabilidade condicional por atributo Então se vocês têm esse tipo de algoritmo baseado em árvores ou em gravidez Vocês poderiam aplicar a ordem no encontro para tudo certo então o caso do notebook são os dois algoritmos que a gente tá usando lá Ah bom tá eu não lembrava da aula 2 eu não lembrava exatamente por isso que usamos então ali né o word


**Resposta gerada pelo LLM**: O algoritmo Naive Bayes lida com atributos numéricos de duas formas: discretizando os valores dos atributos em faixas (pré-processamento) ou usando uma distribuição de probabilidade para calcular a probabilidade de um valor numérico específico.  Para atributos mistos (numéricos e categóricos), uma abordagem é transformar os numéricos em categóricos e usar apenas os categóricos; outra é separar os dados, analisar os categóricos com o NB categórico e os numéricos com o Gaussian NB, e então juntar as probabilidades.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should address how the Naive Bayes algorithm handles numerical attributes specifically. Supporting Evidence: The RESPONSE directly addresses the PROMPT by explaining how the Naive Bayes algorithm deals with numerical attributes through discretization and probability distributions. It also discusses handling mixed attributes, which is relevant to the broader context of the algorithm's application. This comprehensive explanation covers the entire scope of the PROMPT effectively.  Score: 3


---
