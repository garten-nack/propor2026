**Pergunta 72**: Qual é a limitação do Q-learning?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 4401
- *Score:* 0.8394150137901306
- *URL:* oculto
- *Início:* 00:19:46
- *Fim:* 00:22:02
- *Transcrição:* no k learning mesmo a gente tem que testar a mesma coisa várias vezes né o próprio agente aqui ó testa a mesma ação um monte de vez né Para justamente descobrir o valor dela né em especial aqui no estado Inicial né ele fica eh rodando aqui um monte de vez testando o valor das ações para descobrir o verdadeiro né e ele só vai realmente aprendendo o valor verdadeiro quando ele visita lá né quando ele consegue uma trajetória que termina né vai lá no no estado final e finaliza o o aprendizado quer dizer finaliza o episódio né que o aprendizado Nunca Termina o aprendizado só termina quando a gente define o critério de do que o e o critério de parada é até uma coisa importante da gente comentar agora também né não vou deixar o ag gente fazer todo o percurso aqui pode poderia demorar mas o critério de parada né Deixa eu obter aqui ó critério de parada no algoritmo do a gente pode definir o número máximo de episódios é número máximo de episódios ou de de interações com o ambiente né Número máximo de Pass aqui vou colocar Passos ou episódios é um critério outro critério é ver a variação nos valores q né variação aqui vou esse delho aqui ó variação nos valores q ou seja se o aprendizado tá se estabilizando né se o agente tá interagindo bastante com o ambiente lá e os valores que não estão mudando muito n então eu posso definir isso como critério de par uma combinação das Duas né sempre bom ter um número máximo de Passos aqui né e enquanto isso né Igual no em redes neurais lá tem aqueles tem como mandar né o treinamento ser interrompido antes né o early stopping Então posso definir aqui uma parada prematura né se eu ver que o aprendizado já não tá né o ag gente tá meio que estagnado ali não tá mudando os valores tá então aqui né Essa comentári sobre o critério de

- *Corpus ID:* 4195
- *Score:* 0.8360674977302551
- *URL:* oculto
- *Início:* 00:43:52
- *Fim:* 00:46:02
- *Transcrição:* fazer de de já dar silhuetas cores de várias coisas então é o é o é o se kit learn só que de forma visual então vocês podem usar como eu falei para prototipar o resultado né e depois sabendo qual algoritmo é melhor quais os parâmetros são melhores talvez implementarem em Python em outra linguagem não fica muito muito simples Até de explicar né Qual é o pipeline que vocês estão usando essas ferramentas surgiram TM sido usadas ultimamente mas é isso as limitações são é eh eventualmente não ter o componente que vocês precisam mas aí vocês têm opção de de código em nesse caso em Python no knime tem código em Java e mas assim eu já percebi o Orange por exemplo para bancos de dados grandes ele tem uma limitação todos os componentes visuais eles não mostram mais do que 2000 elementos Então quer gerar um gráfico alguma coisa não vai conseguir enxergar tudo né e a tabelas também tem algumas limitações de memória em relação a consumo Então realmente para prototipar ele é bom mas para fazer dados com experimentos reais ele ele vai ter algumas limitações oime ele é um pouco mais robusto mas mas eu eu usei pouco ele eu tenho usado mais o o Orange para fazer essas essas disciplinas né onde o pessoal não não não conhece programação eles são interessantes por isso para entender o processo de mineração poder fazer alguns experimentos e e já ter alguns resultados né enfim a ideia era dar uma um Panorama para vocês e e agora usar esse resto do tempo que nós temos para fazer os os exercícios né na verdade tem um exercício E aí a gente termina a disciplina por

- *Corpus ID:* 1320
- *Score:* 0.8317605257034302
- *URL:* oculto
- *Início:* 00:00:03
- *Fim:* 00:02:02
- *Transcrição:* ei pessoal então desculpa aí vamos Vamos recomeçar aqui então a gente falou né bastante até agora sobre a questão do QI onde é que se encaixa pintado de máquina O que é aprendizado de máquina né do ponto de vista de capacidade de aprendizado ali dentro da em relação uma e a mais clássica né e a simbólica a questão do uso de aprendizado de máquina como uma ferramenta eu vou chamar assim né importante para a parte de ciência de dados agora vou falar um pouquinho mais entrar um pouquinho mais a parte de aprendizado de máquina para a gente entender assim um pouco melhor o que que é o aprendizado de máquina né como uma como uma área do conhecimento e depois a gente vai falar um pouquinho sobre a questão das tarefas principais ele classificação e regressão tá disciplina em si muitas outras coisas que eu vou falar para vocês hoje a gente vai repetir elas ao longo do curso tá então Não se preocupem é claro tirei em dúvidas né a vontade mas não se preocupem se algumas coisas ficarem Claras porque elas vão a gente vai discutindo nessa medida que a gente for estudando os algoritmos especificamente Tá mas eu gosto de contextualizar essa parte mais geral antes da gente falar de questões específicas tá que seria os algoritmos então quando a gente está falando de aprendizado de máquina então a gente quer aprender a partir dos dados né fazer com que os métodos programas sejam capazes de aprender a partir dos dados ao invés de serem explicitamente programados para resolver uma tarefa tá então de aprendizado de máquina está falando de um processo de indução de hipótese a partir da experiência passada essa experiência passada elas são os dados né e a gente normalmente trabalha mas tem um conjunto de dados representativos são os nossos exemplos ali nossas instâncias

- *Corpus ID:* 2223
- *Score:* 0.8314595818519592
- *URL:* oculto
- *Início:* 00:10:04
- *Fim:* 00:11:59
- *Transcrição:* limitação do roldauto mesmo quando eu faço Roll da alta repetido 10 vezes por exemplo né ou mais ele não garante que toda a Instância vai ser usada para teste uma vez ou seja se eu tenho número n de Instância dependendo de como eu faço essa divisão né teste número de interações eu não vou garantir que eu uso toda a distância pelo menos uma vez para teste porque porque eu pego os meus dados de vida entre ele teste por exemplo aqui tá divido em treino vou usar esse aqui de duas vezes divido entrei no teste certo mesmo que eu repita de novo esse processo pode ter instâncias que nas R repetições caem no treino né então nunca são vistas no teste porque é um processo aleatório eu pego por exemplo 20% das instâncias aleatoriamente ou 15% Enfim então a gente tem um problema que ele não garante que toda Instância vai ser usada pelo menos uma vez para teste e por que eu gostaria de garantir que toda instância é usada menos uma vez para teste para ter certeza que o meu modelo ele foi digamos assim confrontado com todo tipo possível de padrão que tem no meu dado E aí a gente vai ver que para né se eu tenho todos os tipos de padrões possíveis para aqueles dados de entrada eu vou conseguir observar que obviamente vai ter alguns padrões que ele não vai sair muito bem vai sair bem agora se eu não garantir isso eu posso estar eventualmente tendo viagem avaliação porque o meu modelo nunca se deparou com algum tipo de uma entrada sub padrão digamos assim de entrada específico Então essas características dessas instâncias né juntas formam os seus padrões sobre padrões e esse padrões podem mudar de distância parece tanto as mesmas instâncias associadas na mesma classe posso ter né grupos diferentes Então essa é uma limitação do roldalto mesmo ele repetido ele não garante que todo

- *Corpus ID:* 1412
- *Score:* 0.8308150768280029
- *URL:* oculto
- *Início:* 00:50:39
- *Fim:* 00:52:57
- *Transcrição:* próximos e toma uma decisão tá por isso que ele é chamado um algoritmo laser certo ele é só uma característica então percebam que o custo de treinar um KNN é zero zero não existe curso de treinar o custo de treinamento é o custo de armazenamento de dados mas não tem custo de tempo digamos assim importante agora o custo de classificar novas instâncias com KNN ele é alto né e ele depende justamente do número de instâncias de Treinamento Então a gente tem que cuidar um pouquinho normalmente com grandes volumes de dados o cai nele é usado em formas modificadas né para aprimorar esse processo de classificação de novas instâncias porque se eu tenho milhões de instâncias eu não posso calcular para cada Nova Instância a distância para outras milhões né então a gente precisa pensar em estratégias para lidar com isso muitas vezes as estratégias não estão dentro do KN mas estão na manipulação de dados como eu comentei a juntar a parte de agrupamento com KNN para poder comparar essas distâncias só com aquele cluster né Por exemplo com alguns clãs mais próximo tá tem uma pergunta o Carlos pode falar Carlos e olha só que interessante tá o KNN mesmo com K igual a 1 que vocês podem pensar né k igual a um valores extremamente simples é o vizinho mais próximo ele faz uma superfície de decisão uma fronteira decisão extremamente complexa tá porque ele ele faz o semelhante ao diagrama de poronoi que a gente tem representado nessa figura que ele coloca essas retas né Sempre passando pelo ponto médio entre duas instâncias então eu crie uma decisão uma uma fronteira de decisão bastante complexa mesmo com k = 1 e só pegar aqui né então basicamente o que ele vai o que ele vai digamos assim tentar fazer Claro que ele tá mostrando todas né mas é como se eu tivesse Enfim uma fronteira de decisão

- *Corpus ID:* 4402
- *Score:* 0.8305273652076721
- *URL:* oculto
- *Início:* 00:21:27
- *Fim:* 00:23:54
- *Transcrição:* critério de par uma combinação das Duas né sempre bom ter um número máximo de Passos aqui né e enquanto isso né Igual no em redes neurais lá tem aqueles tem como mandar né o treinamento ser interrompido antes né o early stopping Então posso definir aqui uma parada prematura né se eu ver que o aprendizado já não tá né o ag gente tá meio que estagnado ali não tá mudando os valores tá então aqui né Essa comentári sobre o critério de parada do que learning e o dilema exploração exploitatie ter né uma probabilidade de explorar isso é necessário para aprender os valores das ações né e isso faz o que o learning funcionar tá tudo bem tem uma condição meio forte aqui né mas eu vou eh comentar ela eh mas o que o lan funciona se a gente mantém né um agente explorando né e hã cada ação é executada né Em cada estado no caso aqui para convergir matematicamente tem que ser tá até em redes neurais é assim também tá então número infinito de atualizações e a taxa de aprendizado decai apropriadamente né os valores inicializados arbitrariamente convergem para os verdadeiros com 100% de probabilidade né probabilidade um quer dizer 100% então esse é o teorema aqui do da convergência do q tá hã e o que que acontece né Igual aqui eu executei só por 10 Episódios e certamente né esses valores não são os corretos aqui né não convergiu ainda então eu vou retomar aquela ideia de executar em background lá por sei lá 1000 Episodes 1000 aqui ó em background menos q aqui aí dier rodou 1000 episódios lá e chegou nessa política chegou nessa política aqui é o nesses valores tá nesses valores que e eu não não sei exatamente se eles são os valores corretos ainda né mas o que dá para ver aqui ó que a partir do Estado Inicial né ele tem uma política correta aqui para para conseguir chegar né no aliás ainda fal não tá correta

- *Corpus ID:* 4560
- *Score:* 0.8304901123046875
- *URL:* oculto
- *Início:* 01:08:25
- *Fim:* 01:10:47
- *Transcrição:* possibilidades e aqui aí enfim cada posição que ele tá né abre duas possibilidades aqui então é o número digamos exponencial aqui de possíveis trajetórias né e ele vai seguir só uma delas eu vou medir o desempenho só com uma dessas trajetórias possíveis então daí vem essa eh instabilidade e a então a ideia né o o ator crítico aqui ó a ideia principal é não esperar até o final do episódio para atualizar a política vamos usar a uma ideia né Vamos pegar emprestado a ideia de diferença temporal que é simplesmente né que é aquela ideia do que learning de usar isso aqui ó de calcular esse erro né do que que eu achava que eu ia ganhar que que eu acho que eu vou ganhar e o que que eu ganhei é no que lean é assim né O que que eu ganhei né o alvo e o o que que eu achava que ia ganhar é a predição Ok a vantagem disso né é que cada vez que eu executo uma ação no ambiente eu já atualizo né minhas estimativas né minhas estimativas de valor eu não preciso esperar até o final do episódio né ou seja se o agente tem uma política que é muito errática que fazer ele ficar voltando pro estado Inicial muitas vezes pode ser né que ele fique perdido e demore muito para chegar até o é o estado final né mas se eu tenho no caso do q learning com essa política ele já vai vendo que não tá dando certo isso né então já vai testando outros caminhos então tem um ganho em não esperar até o final do episódio Tá parte do alvo aqui ó parte do alvo é a estimativa de valor do estado que o agente atingiu nós vamos usar esse elemento aqui né como um dos elementos do ator crítico tá então tem dois componentes nessa arquitetura A primeira é o ator né O Agente né a política Qual é a chance de executar né uma ação em determinado estado tá eu poderia simplesmente fechar aqui ó mas eu tô deixando bem explícito

- *Corpus ID:* 3014
- *Score:* 0.8289268016815186
- *URL:* oculto
- *Início:* 00:22:10
- *Fim:* 00:24:31
- *Transcrição:* tarefas E aí a gente não é matemática os espertos que são também tentam trazer nesse essa metáfora para a matemática no sentido de que o neurônio só a matemática ele tem limitações né A gente vai ver exatamente quais são essas limitações Então vou preparar o próximo conjunto de slides aqui para a gente que é o de redes neurais propriamente dita Então vamos lá agora a gente vai entrar né no na parte de limitações do neurônio individual para entender né Deve estar aparecendo aí para vocês os slides se não tiver aparecendo me avisem né Para a gente chegar no na rede neural eu vou depois eu vou falar do mini back aqui mas para aproveitando o gancho né redes neurais Profundas eu vou deixar o mini back Talvez para o final da aula que vai ser melhor para a gente não perder a linha de raciocínio aqui porque Qual que é a questão a limitação de um neurônio simples Vamos considerar a tarefa aqui de regressão linear né eu tenho quero um neurônio aqui simples com ativação linear né então a saída dele vai ser vai aplicar né a função de ativação aqui ó e a função de ativação linear E aí vamos supor que a gente tem um conjunto de dados que com uma entrada só né só um X1 aqui ó X1 tem aqui Um y e lembrando né o nosso neurônio o w x + b ali a curva que ele implementa é uma reta é um w x w x + b é o que o neurônio faz E aí mas vamos supor então para nossa nosso desespero aqui ó que o conjunto de dados é tem essa comportamento aqui ó E aí para o melhor que a gente tem que fazer um ajuste né melhor que seja a nossa reta aqui ó a gente não vai conseguir qualquer reta que a gente tente né colocar aqui infelizmente não vai ser bom suficiente

- *Corpus ID:* 3539
- *Score:* 0.8271487355232239
- *URL:* oculto
- *Início:* 00:09:04
- *Fim:* 00:11:21
- *Transcrição:* calcular as possibilidades de combinações então se você tem dois parâmetros duas possibilidades e um parâmetro e duas possibilidades em outros seria dois vezes dois a quatro mas a gente colocou lá por exemplo sei lá alguns lugares eu via alguns assim usa 200 mas para mim ficou não ficou muito Claro não sei se vocês assim ó os parâmetros que vocês estão tentando otimizar são discretos né Tem uma lista de valores né e parando só podem assumir os valores daquela lista quando esse número tentativas faz mais sentido quando você tem parâmetros contínuos né Por exemplo se estivessem tentando otimizar taxa de andropausa e taxa de aprendizado são valores contínuos a quantidade possível de valores é infinita né então aí que você tem que definir um limite de tentativas para o iPad combinações também fosse enorme né tivesse um bilhão de possíveis combinações aí você tem que definir o limite para ele inteligentemente naquele orçamento né naquele limite de tempo ele conseguia achar melhor possível é que no nosso caso ele está limitado pela quantidade de opções mesmo né não é por quantidades de ter entre tentar testar todas as opções entende é entendi faz mais sentido com variáveis contínuas Não beleza obrigado jóia pessoal no grupo Três tinha me chamado quando eu tava conversando com o grupo né tinha pedido um pouquinho mais de tempo aí vocês querem me avisem aqui tá que a gente conversa um pouquinho mais caso contrário ou será questão me esperando ali é eu acho que eles estão me esperando lá na chamada depois eu entro lá com ele de novo então aqui com vocês tudo certo tudo né Qualquer última dúvida aí para a gente fechar a aula de hoje problema Oi eu tô bem eu sou só para agradecer

- *Corpus ID:* 5422
- *Score:* 0.8270182609558105
- *URL:* oculto
- *Início:* 00:26:04
- *Fim:* 00:28:07
- *Transcrição:* um burburinho e recentemente eu vi aí o tal do Quantum machine learning né e adaptando algoritmos né fazendo trabalhos aí é uma curiosidade vocês têm pesquisado né T tido al muito interesse nesse assunto isso é é é assim é muito na indústria Eu vejo algumas pessoas da área de física né falarem sobre isso talvez pela na proximidade mas eh eu S tem reparado assim algum interesse vocês têm trabalhado né alguma coisa nesse sentido assim dentro do grupo especificamente eu não conheço ninguém que tá esteja assim trabalhando com computação quântica de maneira assim direta explícita entendeu Ah mas a gente tá atento obviamente né porque é uma estura nova que pode revolucionar totalmente né então assim eh só título de curiosidade tipo o ano passado a gente teve né aqui na a gente organizou um evento aqui latino-americano de a desempenho seu aqui em Porto Alegre e a gente convidou uma especialista da Espanha para vir falar sobre isso aí comentou várias coisas interessantes assim de como que a gente vai usar e tal né Qual que é o envolvimento eh do pessoal da Computação né como que vai envolver né e uma das coisas que me marcou quando ela fez a sua apresentação eh foi que a a que a parte de quântica digamos assim ela vai funcionar né em digamos assim sinergia com o que a gente já tem hoje entendeu então ela simplificou né é uma simplificação Talvez um pouco grosseira ela simplificou que é como se a placa Quantum quântica digamos assim né compador quântico vai ficar como se fosse uma aceleradora na máquina né então da mesma forma como é uma GPU hoje entendeu então a gente vai ter ainda uma existência dessa nossa arquitetura tradicional não vai ser uma substituição né pelo menos por enquanto a Ah e teve uma outra uma outra apresentação que talvez eu eu vou tentar recuperar depois tá que a gente tem um um colega que é o


**Resposta gerada pelo LLM**: O Q-learning requer um número infinito de atualizações e uma taxa de aprendizado que decai apropriadamente para convergir matematicamente; valores inicializados arbitrariamente convergem para os verdadeiros com 100% de probabilidade.  Executar apenas por um número limitado de episódios (ex: 10) não garante que os valores sejam corretos, pois o aprendizado não convergiu.  Além disso, a exploração é necessária para aprender os valores das ações, o que é uma condição forte para o funcionamento do Q-learning.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: P

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. Supporting Evidence: The RESPONSE directly addresses the limitations of Q-learning by discussing the need for infinite updates, appropriate learning rates, and the necessity of exploration for effective learning. It provides a comprehensive explanation of these limitations, which aligns well with the PROMPT's request for information on the limitations of Q-learning.  Score: 3


---
