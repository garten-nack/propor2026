**Pergunta 142**: Quais são as principais decisões que precisam ser tomadas durante a preparação e pré-processamento de dados para o desenvolvimento de um modelo? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2170
- *Score:* 0.8714226484298706
- *URL:* oculto
- *Início:* 00:12:17
- *Fim:* 00:14:18
- *Transcrição:* que como eu falei ela não necessariamente é linear ela começa a linear mas muitas vezes a gente tem que revisar etapas anteriores voltar né E essas diferentes decisões opções de métodos estratégias isso junto né O que a gente prega é a nossa metodologia Então quando vocês forem escrever um desenvolvimento do modelo vocês vão iniciar descrevendo inclusive decisões de pré-processamento de dados porque faz parte da metodologia de trabalho de vocês Né desde essa etapa de coleta preparação né e um pré-processamento específico então assim essa sequência de decisões que a gente toma né E todos esses pontos em que a gente tem que tomar realmente decisões porque existem diferentes possibilidades isso faz a nossa metodologia claro que a gente normalmente tem um conjunto de aspectos que a gente precisa prestar atenção e dependendo de um problema Alguns alguns aspectos eu vou levar em conta outros eu vou ver que não preciso certo por exemplo você não tem o valores faltantes eu não preciso pensar numa estratégia de como que eu vou lidar com essa situação mas é de uma forma geral né os pontos que a gente é tem que prestar atenção né são é um grande conjunto de opções e a gente conforme né caso a caso a gente vai discutindo e decidindo como abordar cada uma delas dependendo das demandas do projeto dos dados tá então isso é a metodologia então aqui fica claro a ideia da disciplina a ideia da disciplina é a gente passar por vários dessas desses problemas né ou decisões que a gente tem que tomar ao desenvolver o modelo é que na disciplina anterior a gente não fez porque o foco era a gente entender um pouquinho mais como é que ocorre o aprendizado supervisionado ok então na disciplina anterior né a gente focou como eu tinha comentado entendeu Nacional por trás de algoritmos pressionado Como é que os algoritmos

- *Corpus ID:* 2169
- *Score:* 0.8661644458770752
- *URL:* oculto
- *Início:* 00:10:46
- *Fim:* 00:12:47
- *Transcrição:* decisões na coleta né Que atributos que eu vou utilizar Que tipo de informação de indicadores de características eu tenho que mensurar sobre aquele problema que eu quero abortar como é que eu particiono os meus dados né para fazer o desenvolvimento do modelo como é que eu lido com valores faltantes Será que eu preciso aumentar fazer algum tipo de deitar um processo que a gente aumenta os dados através de ou instâncias artificiais ou algumas alterações para poder ter mais dados Será que eu tenho que reduzir os meus dados enfim tá então tem várias decisões depois eu tenho a parte de engenharia de atributos Será que eu preciso criar ou transformar atributos né Será que eu preciso fazer uma redução de dimensionalidade seja com seleção de atributos seja com técnicas como PCA então tem várias questões que entram aí e depois na parte de treinamento e avaliação de modelos também a gente vai decidir quem algoritmos a gente vai utilizar para treinar que a gente vai explorar como é que a gente vai fazer a divisão de dados de forma independente Ou seja eu tenho que ter dados diferentes para avaliar o desempenho do modelo né em relação aos dados que eu usei para treinar como é que eu vou otimizar e preparaâmetros que métrica desempenho eu vou eu vou avaliar E qual vai ser a minha métrica principal enfim existem diversas decisões né Em vários pontos aqui então essa metodologia tem essa sequência de etapas que como eu falei ela não necessariamente é linear ela começa a linear mas muitas vezes a gente tem que revisar etapas anteriores voltar né E essas diferentes decisões opções de métodos estratégias isso junto né O que a gente prega é a nossa metodologia Então quando vocês forem escrever um desenvolvimento do modelo vocês vão iniciar descrevendo inclusive decisões de pré-processamento de dados porque faz parte da metodologia de trabalho de

- *Corpus ID:* 2314
- *Score:* 0.8633869886398315
- *URL:* oculto
- *Início:* 00:00:04
- *Fim:* 00:02:18
- *Transcrição:* ok pessoal então bom dia a todos vamos dar início então a essa semana dessa disciplina de metodologia de aprendizados supervisionado onde a gente vai começar a falar sobre o processamento de dados tá então na semana passada a gente falou sobre a parte de avaliação de modelos Claro que não é um assunto encerrado né conforme vocês tenham dúvidas a gente a gente pode discutindo a gente pode detalhar algumas coisas a mais em momentos de aula pelo fórum e é uma coisa que vocês vão usar ao longo da disciplina tá E de outras questão de avaliação de modelos certo só que a disciplina ela também tem uma ideia de discutir a parte para processamento de dados né então hoje a gente vai fazer uma introdução a esse tema e a gente vai falar sobre diferentes tarefas envolvidas nessa parte de limpeza e transformação de dados tá então a primeira etapa para processamento comentando assim alguns problemas comuns algumas soluções comuns tá é difícil né já adiantando nessa área a gente a gente dá uma receita de bolo né dizer Olha dessa situação esse tipo de solução melhor nessa situação esse tipo de solução é melhor eu tento trazer dicas para vocês Tá mas digamos assim nada que a gente pode afirmar que uma solução ou outra é a melhor a gente vai precisar realmente dependendo dos dados do contexto fazer essa essa avaliação Tá bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou

- *Corpus ID:* 2195
- *Score:* 0.8621951341629028
- *URL:* oculto
- *Início:* 00:51:40
- *Fim:* 00:53:53
- *Transcrição:* coisas como normalização de dados transformação de atributos Auto laires valores faltantes isso sim isso vai ser aplicado agora outras coisas como por exemplo vazamento de dados não porque a gente supervisionado a gente tem aquela ideia de ter um alvo e aprender a estimar aquele alvo a partir dos dados né então o vazamento de informações tá quando eu uso dados de teste que a gente tá sumindo que não conhece essa saída para o treinamento do modelo então aí essa relação né de vazamento de dados aí já é diferente mas a questões por exemplo de avaliação de modelos muda Tu aprendeu as coisas do nada também existem estratégias para avaliar modelos novos profissionado é mas elas são diferentes supervisionado tá então eu diria que eu diria que a parte pré-processamento de dados ela se aplica tá ela se aplica bem porque muitos desses algoritmos nós pressionados vão demandar preparação de dados para processamento Ok Ok mais alguma pergunta acho que a gente vai começar então a discussão sobre estratégia de divisão de dados então como eu comentei né primeiro assunto da disciplina avaliação de modelos preditivos tá então a gente vai aprofundar o que a gente vem discutindo e essa avaliação de modelos preditivos a primeira coisa que a gente vai discutir estratégias de divisão de dados porque a gente viu que a gente não pode avaliar modelos em dados que não sejam Independentes ou seja dados que não foram vistos em tempos de treinamento e existem diversas estratégias para a gente fazer isso né então a gente vai discutir essas mais comuns e uma que é considerada tipo assim talvez né o chamaria o estado da arte tinha mais recomendada que a validação cruzada tá e tem diversas variações Ainda assim eu trouxe outras que vocês inclusive já ouviram falar que

- *Corpus ID:* 1438
- *Score:* 0.8612441420555115
- *URL:* oculto
- *Início:* 00:06:22
- *Fim:* 00:08:26
- *Transcrição:* Qual é o melhor modelo tá então por isso que eu preciso ser capaz de avaliar o desempenho desses modelos só tomar uma água aqui então assim ó essa etapa de validação e seleção de modelos é o que a gente chama né a validação como eu comentei antes etapa de avaliação e selecionar o modelo da determinado todos os modelos que eu treinei com as suas variações de algoritmos de prepararmos Esse é o melhor modelo tá essa é uma etapa extremamente crítica quando eu tô desenvolvendo um modelo tá e a gente vai iniciar nesse assunto de como fazer isso usando uma estratégia como eu falei uma estratégia simples que é o rolda alto mas ela ainda é muito utilizada em alguns alguns casos principalmente o aprendizado profundo que o custo de desenvolver treinar múltiplos modelos é mais alto então ela ainda é utilizada Tá mas depois a gente vai discutir formas de fazer isso com um pouco mais de robustez assim principalmente em relação a variação de desempenho enfim tá mas ela é uma etapa crítica seja se eu não fizer isso bem se não fizer isso usando dados Independentes avaliando bem o desempenho dos meus modelos né as medidas de desempenho certo eu posso estar seleciodo o modelo que não é o melhor então quando a gente está falando de poder generalização eu quero saber isso né como é que o meu modelo se citai né para fazer previsões né o determinar a saída para dados que ele nunca viu tá então a gente tem Normalmente quando a gente faz esse tipo de tarefa a gente tem um conjunto de dados Então olha aqui tá esse conjunto de dados aqui eu gostaria que você treinasse que um classificador vai determinar se um aluno de uma universidade vai desistir ou não do curso tá então amor tem uma base histórica né de alunos forma matriculados de desistências enfim eu quero ser capaz de prever isso para agir

- *Corpus ID:* 2194
- *Score:* 0.8599343299865723
- *URL:* oculto
- *Início:* 00:50:04
- *Fim:* 00:52:15
- *Transcrição:* vai discutir ao longo dessas etapas de pré-processamento como fazer as coisas sem deitar sem vazamento de dados tá E aí eu vou Relembrando com vocês Esse conceito mas isso é muito importante porque às vezes o pessoal faz para processamento de forma que de fato adiciona digamos assim né esse risco de contaminação de dados bom e o que a gente vai discutir então é a gente vai começar agora depois vai fazer um intervalo e vai continuar é justamente a questão de avaliar os modelos preditivos tá é claro que a gente aqui ele tá falando explore muitos modelos e selecione os melhores o que a gente vai discutir é seja nessa etapa de checking seja numa etapa de ajuste fino dos modelos como é que eu faço a divisão de dados para poder fazer essa avaliação e na segunda aula da semana como é que eu avalio esses modelos do ponto de vista de outras métricas de desempenho tá então a ideia a gente expandir um pouco as métricas de desempenho na aula que vai ficar gravada para vocês que vai ser a aula do feriadão ok uma pergunta até aqui pessoal antes a gente para o segundo parte dos likes pode falar só uma perguntinha essa metodologia que a gente tá vendo para o aprendizado supervisionado ela se aplica ou não supervisionado também algumas coisas assim outras não porque outras por exemplo coisas como normalização de dados transformação de atributos Auto laires valores faltantes isso sim isso vai ser aplicado agora outras coisas como por exemplo vazamento de dados não porque a gente supervisionado a gente tem aquela ideia de ter um alvo e aprender a estimar aquele alvo a partir dos dados né então o vazamento de informações tá quando eu uso dados de teste que a gente tá sumindo que não conhece essa saída para o treinamento do modelo então

- *Corpus ID:* 2177
- *Score:* 0.8594819903373718
- *URL:* oculto
- *Início:* 00:23:02
- *Fim:* 00:25:13
- *Transcrição:* treinamento do modelo né mas da parte já é essa divisão dos dados dados Independentes treinamento a validação enfim se eu fizer isso de forma Impecável se os meus dados forem muito ruins essa modelagem Impecável do ponto de vista de metodologia ela não salva esses dados ela dificilmente salva esses dados certo então a gente tem que cuidar a gente tem que entender o que que a gente precisa trabalhar em nível de dado né para que a gente possa tentar melhorar esse esse dado aqui que não é não é bom mas a gente também tem que cuidar para que a nossa metodologia do ponto de Treinamento não insira viésis não faço uma avaliação ruim né do ponto de vista de não perceber que tem um overfite tem coisas desse tipo ok e tem a questão da metodologia né do ponto de vista de risco de vieses e esse ponto apareceu um pouquinho naquele notebook que a gente fez né do nave base com dados de risco de doenças cardíacas em que tinha pessoas de diferentes Ali era variável raça né quantificada então e aí chamava atenção o caso ali que por exemplo nós tínhamos não tínhamos asiáticos com registro para doença né cardíaca e a gente discutiu um pouco isso pode ser uma questão de amostra de dados né um viés de amostra enfim a questão é que quando a gente não não Cuida dessa questão metodológica do desenvolvimento dos modelos e nesse ponto tá incluso né A questão da gente avaliar os dados perceber se a gente tem potenciais vieses enfim a gente acaba criando modelos com viés Então o que a gente tem que ver é que o nosso modelo ele não pode se cumprir com o nosso objetivo da tarefa de aprendizado de máquina né claro que a gente quer fazer isso aí mas isso não é a única questão a gente tem que garantir que ele não tenha implicações sociais

- *Corpus ID:* 2190
- *Score:* 0.8587787747383118
- *URL:* oculto
- *Início:* 00:44:03
- *Fim:* 00:46:03
- *Transcrição:* de alguns métodos voltados para interpretação dos modelos tá ou seja tentar entender quem que levou o modelo tomar determinada decisão para aquela pessoa para aquele cliente para aquele paciente enfim certo então algumas coisas que a gente vai discutir são vários tópicos né Vocês podem imaginar assim que a minha ideia alonga disciplina é trazer algumas possibilidades para todas essas esses problemas digamos assim para processamento enfim e claro sempre vão haver mais alternativas além daquilo que a gente discutiu né mas eu acho que vocês tendo a base vocês também explorarem outras alternativas é muito mais fácil Se você já tem uma base né mas sólida pelo menos de alguns métodos mais comuns tá então como nós temos Oito aulas essas Oito aulas vão abordar esse tema com exemplos práticos enfim né mas infelizmente não de forma exaustiva a gente realmente precisaria mais tempo para aprofundar em cada uma dessas possibilidades mas acredito que vai dar uma boa base para vocês para entenderem os problemas entenderem possíveis soluções estarão preparados para buscar novas soluções de coisas que não foram discutidas na disciplina tá tem um ponto importante que é um conceito que a gente vai discutir muito ao longo da disciplina no sentido de tentar evitar esse fenômeno que é o conceito de deita liquete ou vazamento de dados ou ainda contaminação de dados tá então é muito comuns ele ter no inglês mesmo por isso que eu trouxe ele em inglês tá basicamente isso acontece quando eu tô usando dados de fora dos dados de treinamento né para tomar alguma decisão Em relação a preparar os dados desenvolver os modelos Ou seja quando o meu desenvolvimento do modelo seja uma decisão de preprocessamento de dados seja uma

- *Corpus ID:* 8683
- *Score:* 0.8582955002784729
- *URL:* oculto
- *Início:* 01:51:23
- *Fim:* 01:53:16
- *Transcrição:* na modelagem lá na frente eh por quê porque cada modelo ele a gente entendeu também pelas aulas aí alguma pesquisa de que eles eles os modelos eles têm comportamentos diferentes de acordo com o tipo de texto que a gente tá usando Eh sei lá o o modelo x vai se comportar melhor com o texto com stopwords ou o outro vai se comportar pior então a gente acabou criando as quatro colunas de texto do pré-processamento para vamos dizer assim iterar o comportamento treino desses modelos e ver com qual a versão de texto ele se comportam melhor tá aí essa imagem é para vocês verem mais ou menos como é que ficou a a nosso Data Set depois do pré-processamento né e o balanceamento aí dos nossos rotos tá bom aí passamos aqui paraa etapa de modelagem né a etapa de modelagem a gente acabou escolhendo cinco modelos cinco modelos tipos de modelos eh parece muito mas e e como o tema é uma coisa muito nova para toda a equipe a gente acabou pegando os cinco né três de de machine learning e dois de Deep learning né os Escolhidos por machine learning foram esses aqui o ren Forest o regressão logística e o multinomial de KN base né Eh então todos eles passaram pela etapa de vetorização dos textos né com o TF DF eh a gente utilizou uma a técnica de romiz de search CV search Cross validation né E por que não utilizar o Grid search o Grid search e Apesar de ele extrair melhor né melhor versão de hiperparâmetros de cada um dos modelos ele vem a um custo de processamento muito alto e a gente a gente começou a perceber nessa fase da da da nossa histria das nossas etapas aí da da modelagem que isso não ia ser uma coisa legal pra gente poder explorar um pouco mais aí as outras etapas então a gente acabou utilizando ROM resarch validation porque ele trabalha com um um Range menor de variação desses IP parâmetros ele não pega provavelmente né o melhor como Grid search mas ele ele busca o

- *Corpus ID:* 2354
- *Score:* 0.8579998016357422
- *URL:* oculto
- *Início:* 01:04:29
- *Fim:* 01:06:41
- *Transcrição:* dados faria todo o pré-processamento aí depois dividiria um treino e teste mas esse raciocínio então não tá correto né eu preciso primeiro dividir meus dados no treino e teste seja lá quais outros técnicas lá de divisão aí fazer só nos dados de treino para processamento e guardar digamos esse esses as técnicas que foram utilizadas para depois não vai pirar e usar o teste Exatamente é porque assim a gente acha que às vezes a gente tem impressão que usar o dados de teste para por exemplo aprender como fazer imputação de valores é algo que não vai ter feito mas na verdade tem tem porque eu tô estimando uma média com dados que o modelo ainda não viu então isso isso pode influenciar o modelo às vezes até de forma positiva sabe colocar um valor digamos assim seja estimado por um modelo ou por valor fixo isso pode acabar envezando o desempenho do modelo positivamente Então o que a gente faz é isso todo dado que ele é de teste ou de validação porque também isso também vale para validação como você falou né dependendo das estratégias tem várias estratégias para gerar o dado de validação Mas a gente não pode usar nada referente esses dados para desenvolver o nosso modelo esses dados são usados especificamente validar ou seja comparar e preparametos ou algoritmos de validação e o de teste para dar o meu desempenho final tá agora não esqueçam que depois que a gente termina toda essa parte de desenvolvimento do modelo o nosso modelo de produção ele vai ser sempre gerado com base nos dados todos que a gente tinha no primeiro momento e é isso vai digamos assim vai passar também por um processo de restimar essas por exemplo média ou mediana ou retreinar esse modelo certo para tornar digamos assim o modelo e o pipeline que transforma os dados prontos para esse modelo de produção esse modelo que vai ser


**Resposta gerada pelo LLM**: As principais decisões envolvem: coleta de dados (atributos a serem utilizados e informações a serem mensuradas); particionamento dos dados para desenvolvimento do modelo; tratamento de valores faltantes (aumento ou redução de dados); engenharia de atributos (criação ou transformação de atributos e redução de dimensionalidade); escolha de algoritmos para treinamento; divisão de dados para avaliação independente do desempenho do modelo; otimização de hiperparâmetros; escolha da métrica de desempenho principal; e estratégias para lidar com vazamento de dados.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should address the main decisions involved in data preparation and preprocessing for model development. Supporting Evidence: The RESPONSE directly addresses the PROMPT by listing the key decisions that need to be made during data preparation and preprocessing. It covers various aspects such as data collection, handling missing values, feature engineering, algorithm selection, data partitioning, and performance evaluation metrics. Each point mentioned is relevant to the overall process of preparing data for model development, thus providing a comprehensive answer to the PROMPT.  Score: 3


---
