**Pergunta 104**: Quais tipos de problemas se beneficiam do aprendizado profundo? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 7128
- *Score:* 0.8622201681137085
- *URL:* oculto
- *Início:* 00:14:51
- *Fim:* 00:16:54
- *Transcrição:* e aprendizado profundo bom talvez a gente possa dizer que nem visão computacional isso é né Isso é e a mesmo principalmente padrões mesmo mas quando a gente aplica problemas de visão a gente dá uma nova cara para isso né e eh e começa a pensar em soluções que são aplicáveis Nesse contexto e eventualmente não são aplicáveis para um contexto de eh sei lá eh predição de tráfego de rede ou eh análise automática de invasão em Sistemas distribuídos não sei né então a gente poderia usar esse monte de coisa para Outras aplicações questões da Computação eh mas a gente tenta né customizar isso pros nossos problemas de interesse na disciplina eh bom isso aqui naturalmente vai ser melhor detalhado ao longo da disciplina como um todo né mas eh no cronograma ali eu acho que tá um pouquinho mais organizado na como como a gente pretende apresentar esses conceitos para vocês bom eh com relação a a como a gente gerencia disciplina né acho que isso aqui é padrão também tá então todo o material ela é ele é disponibilizado no Moodle tá então eh tanto prático quanto teórico eventualmente os práticos vão envolver uma lista de exercícios ou eh eh um trabalho né ou uma prova os enunciados né as portas de entrada para Essas atividades práticas elas vão estar no Moodle também e eventualmente a gente usa uma ferramenta externa como colab por exemplo que vocês já usaram aí em algum em alguma outra disciplina tá a nossa comunicação ela é feita através dos fóruns eh do Moodle então A ideia é que a gente use de fato os fórums do Moodle eh eu sei que a gente tem esse espaço no no teams né Eh mas o que eu e o Claude fizemos né nas últimas edições dessa disciplina foi

- *Corpus ID:* 1435
- *Score:* 0.8596016764640808
- *URL:* oculto
- *Início:* 00:01:47
- *Fim:* 00:03:46
- *Transcrição:* principalmente aprendizado profundo se usa muito então ela é uma estratégia útil Tá mas depois a gente vai motivar porque que a gente precisa outras estratégias e a gente vai explorar essas outras estratégias na disciplina seguinte lembre quando a gente falou da base de aprendizado de máquina né a gente discutiu o processo é o processo não Desculpem a característica de desculpe a característica de generalização tá generalização Seria isso quão bem esse modelo se sai na classificação na regressão enfim para novas instâncias instâncias que ele nunca viu que não estão na base de treinamento tá esse é o grande objetivo do aprendizado de máquina eu quero modelar bem os dados que eu tenho mas o objetivo em fazer isso a ser capaz de tomar decisões sobre novos dados e eu preciso fazer ter formas de avaliar essa capacidade de anenalização seja tão bem esse modelo vai sair quando ele for confrontado com dados que ele não viu que não estava na base de treinamento Quando eu digo em dados que ele não viu tem toda uma questão muito importante a gente citar que a gente está discutindo a respeito de um problema específico de uma distribuição de dados né então esses dados que ele não viu não quer dizer que são Dados totalmente diferentes né Se forem totalmente diferentes ele não vai sair bem mas são Dados que a gente assume que surge na mesma distribuição da mesma população então se eu tô tentando analisar aquela questão de probabilidade de uma pessoa vira fazer compras em uma loja né É porque eu tô lidando com conjunto de dados uma população Ou seja a base que eu tô usando para treinamento são de características que essa nova pessoa esse novo cliente sim vai se integrar ali na distribuição de alguma forma tá é uma coisa totalmente diferente se eu tô falando sobre a questão de

- *Corpus ID:* 1257
- *Score:* 0.8553904294967651
- *URL:* oculto
- *Início:* 00:09:07
- *Fim:* 00:11:04
- *Transcrição:* para o meu lado mas aprendizado de máquina é um dos principais componentes dessa área não resolve o problema sozinho como vocês vão ver né diversos problemas de ciências de dados a gente vai ter que lidar com computação de auto desempenho com a parte armazenamento de dados saber visualizar as informações corretamente né de uma forma que permita Facilite a extração de insights mas o aprendizado de máquina é hoje um dos principais componentes ciências de dados é muitos dos projetos ciências de dados depende de métodos de algoritmos dentro de ciência de desculpe de aprendizado de máquina para serem desenvolvidos e a área de aprendizado de máquina ela é uma área que ela está dentro da área de Inteligência Artificial então assim todo aprendizado de máquina é uma inteligência artificial Mas nem toda e a inteligência artificial é um aprendizado de máquina porque aí há por si só é uma área enorme que tem diversos outros subir áreas que a gente não aborda aqui tá então aqui a gente vai falar especificamente de aprendizado de máquina e o aprendizado profundo que vocês vão discutir posteriormente com professor Anderson é uma sub área de aprendizado de máquina então eu gosto de esclarecer essa relação entre esses conceitos tá então a gente tem a área de ar dentro da área de ar tem todo um conjunto de métodos algoritmos que são voltados por aprendizado de máquina e dentro de aprendizado de máquina a gente tem então essa sub área que vem se desenvolvendo e crescendo de uma forma impressiote nos últimos anos que é o aprendizado ok e quando a gente fala de aprendizado de máquina a área é enorme assim a gente tem muitos algoritmos que são voltados para diferentes aplicações e por isso né que a gente resolveu dividir um pouco isso no curso Então a gente tem todo um conjunto de algoritmos que é por aprendizado não supervisionado que como a gente vai

- *Corpus ID:* 2625
- *Score:* 0.8522149324417114
- *URL:* oculto
- *Início:* 00:17:22
- *Fim:* 00:19:12
- *Transcrição:* interessante porque assim falando aqui nessa questão né de questões mais enfim bancárias ficeiras então eles dava um conjunto de dados com milhares de indivíduos né que tinha aspectos históricos de crédito e informando se o indivíduo não pagou empréstimo tá então tinha informações e basicamente a tarefa era criar um modelo caixa preta tá para prever a inadimplência de empréstimos em seguida explicar a caixa preta então o desafio diz assim você tem que criar um modelo caixa preta para prever esse risco de inadimplência e propor um método uma forma de explicar essa caixa preta tá E aí basicamente o que a maioria dos times que participaram desse desafio pensou o seguinte se a competição exige que se cria um modelo caixa preta que normalmente são modelos mais complexos por exemplo uma rede neural profunda né amor a própria rede neural tradicional enfim usbm o problema é realmente demanda o uso de tal modelo né para poder ser resolvido E aí teve um timeverse que ele era coordenado pela professora Cinthia ruden que observou o seguinte fizeram um treinamento de um modelo de aprendizado profundo né baseado em redes neurais e o modelo de regressão linear clássico que tem a questão da interpretabilidade que a gente comentou agora tá da questão dos coeficientes e observou entre os dois modelos menos de 1% de diferença na acurácia nessa tarefa de prevenir de preferência tá E sendo que o modelo representado profunda era muito mais complexo não é interpretável então basicamente o que eles observaram isso é que um modelo interpretável aqui representado pela regressão era tão bom quanto esse modelo não interpretável e ele se depararam a situação que é ou eu sigo as regras do desafio e apresento o meu modelo de aprendizado profundo e apresenta uma estratégia para tentar explicar o que esse modelo tá prevendo que tem técnicas para isso Ou eu

- *Corpus ID:* 6686
- *Score:* 0.8511657118797302
- *URL:* oculto
- *Início:* 00:16:19
- *Fim:* 00:18:23
- *Transcrição:* expas anteriores mas só pra gente aplainar o conhecimento de todos aqui né Eh então assim a ideia é que a a gente vai usar o aprendizado Prof fundo quando a gente tem muitos dados né muitas observações e o problema ele é suficientemente complexo né Por exemplo um problema de linguagem né como a gente tem visto os language models por aí ou um problema de visão computacional também que é complicado de fazer através de algoritmos clássicos né então o problema tem que ser complexo assim tipo não ter um uma forma simples de resolver uma outra questão também que os dados eles não são não estão estruturados também então a gente pode pode partir de imagens né que são totalmente são fotos de objetos ou de cenários né ou de texto texto livre né em alguma língua e o que a gente quer obter né é um melhor modelo possível não seria um modelo ótimo digamos assim ou que mas aquele melhor que a gente pode obter assim se a gente não é tão exigente assim em relação a a a resposta digamos assim então a é quando usar né E quando não usar seria o contrário daquilo ali né em situações onde a gente tem poucos dados então não vale a pena usar tem que ter realmente bastante informação e essa informação ela como a gente tá trabalhando com aprendizado Prof fundo é supervisionado né a gente tem que ter muitos dados várias observações têm que estar já anotadas digamos assim saber o que que tem ali naqueles dados pra gente poder criar esse melhor modelo possível né ã a gente não precisa usar também a prisada fundo quando os métodos tradicionais eh funcionam bem e aí aqui eh eu coloquei métodos tradicionais de aidade máquina mas a gente poderia tornar isso aqui mais amplo onde os métodos estatísticos já funcionam bem né então por exemplo se eu quero fazer uma regressão linear esse tipo de coisa tem métodos que já funcionam super bem e que

- *Corpus ID:* 1277
- *Score:* 0.8506661653518677
- *URL:* oculto
- *Início:* 00:40:14
- *Fim:* 00:42:23
- *Transcrição:* aprendizado por reforço né que basicamente vai avaliar decisões sucessivas e ajudar criar uma política que nos leve a um a digamos assim o desfecho que a gente quer né Por Exemplo né um agente se mover pelo pelo ambiente conseguir chegar sei lá por exemplo Aquele caso do robô né onde tá mais sujo Enfim então é uma decisões excessivas que ele vai tendo feedback né se aquela Decisão foi boa se aquela ação foi boa ou não então tem várias formas a gente fazer né um computador Aprender Pensando no computador de forma geral então a área de aprendizado de máquina são esses sistemas que são treinados para realizar uma tarefa né ao invés de terem explicitamente programados para tal então assim eu não programo passo a passo daquela tarefa eu treino ele para que ele aprenda a realizar uma tarefa específica para que ele aprenda a detectar o diagnóstico para que ele aprenda a prever o valor das ações para que ele aprenda determinasse se um cliente vai parar de comprar na minha loja para eu poder enviar algumas promoções para esse cliente então ele consegue aprender a realizar aquela tarefa né eu não quando a gente fala explicitamente programados eu não estou programando passo a passo as regras eu estou treido ele para aprender essas regras ou esses padrões certo E aí aqui vem esse treinados é justamente isso ele tem a habilidade de aprender a partir de exemplos passados por isso que quando a gente fala de aprendizado de máquina e é especificamente falando de aprendizados nossos pressionado aprendizado profundo a gente tá falando de ter dados porque a gente precisa ter dados para permitir que aquele algoritmo aprenda os padrões que estão subjacentes aqueles dados certo e para a gente dar um exemplo né sobre isso essa habilidade de aprender a

- *Corpus ID:* 4521
- *Score:* 0.8497371673583984
- *URL:* oculto
- *Início:* 00:00:03
- *Fim:* 00:02:16
- *Transcrição:* tá começando ali beleza a gravação começou Então essa é o Nossa quarta perdão quarta e última aula do nosso curso de introdução ao aprendizado por reforço ã eu queria começar hoje me avisem se não tiver aparecendo o compartilhamento de tela Acredito que esteja né falando um pouco talvez um formalizar um pouco do de alguns assuntos que a gente viu né sobre algoritmo e ambientes de aprendizado por reforço profundo eh perdão eh deu alergia com foco na parte da programação tá eh porque o que que a gente tem temos um uma uma grande ã repositório uma grande biblioteca de algoritmos né de de aprendizado por reforço profundo cada um com suas características tá que eu não vou eh não vai dar tempo de enumerar todas essas características aqui mas o que a gente tem que cada algoritmo tem as suas ã peculiaridades e suas aplicações né Por exemplo tá o dqn ele só funciona em ambientes com ações contínuas ações contínuas aliás ações discretas perdão ações discretas por exemplo né no caso lá do Atari né Tem 18 ações possíveis né que é as combinações dos botões enfim ambientes desse tipo ã E aí algumas melhorias em cima dele também né tem a mesma peculiaridade tá o outros algoritmos por exemplo SAC né eles são para ações contínuas somente ações contínuas tá eles têm alguma característica neles lá que torna eles incompatíveis com ações discretas né então aqui por exemplo eh aquele ambiente do pêndulo né de equilibrar a varetinha para para cima n é fixa né num ponto e e fica Tem Você Tem que aplicar um torque aqui né então é contínua o do carro Tem duas versões né o Mountain Car né Tem um que eh você define quanto de aceleração você vai colocar de né do mínimo né que é o

- *Corpus ID:* 1290
- *Score:* 0.8497083187103271
- *URL:* oculto
- *Início:* 01:00:35
- *Fim:* 01:02:44
- *Transcrição:* aí eu comentei vocês né que Justamente a gente tá vai falar que ele habilidade de aprender a partir delas passados Então sempre que a gente falar aqui do nosso aprendizado de máquina a gente vai assumir que tem conjuntos de dados disponíveis certo Então essa é a área né que foi criada enfim aprendizado de máquina e aí depois eu não vou entrar em detalhes na nossa disciplina por conta né que a gente vai ter uma disciplina de aprendizado profundo vocês vão ver mas depois surgiu somente o aprendizado profundo que são modelos que tem uma capacidade de extração de conhecimento tecção de padrões muito maiores assim então principalmente lidando com dados não estruturados que seria a imagens texto vídeo áudio né então existe que foi toda essa área de plano tá de aprendizado profundo então por exemplo eu não vou falar de redes neurais na nossa disciplina porque a gente decidiu juntar no curso eles orais com aprendizado profundo Tá mas a gente tinha um modelo de redes neurais o algoritmo de redes neurais né que que era muito utilizado E aí começou a trabalhar mais uma evolução dessa de aprendizado de redes neurais para ter um número de camadas maior camadas implementando alguns filtros que você era muito bons por exemplo a imagens e é isso foi gerando toda essa área de aprendizado profundo que esse plano certo então todas essas evoluções Elas acabaram gerando muitas novas aplicações de a que não eram possíveis com aquelas formas de a mais clássicas que a gente discutiu lá no início certo e aí eu fiz um compilado de algumas oportunidades mas obviamente a gente tem muito além né do que Opa do que a gente deixou só que aí do que a gente vai discutir aqui mas tem toda a questão dos assistentes pessoais por exemplo a Siri eu sempre esqueço o nome dessa da do Google enfim

- *Corpus ID:* 2626
- *Score:* 0.849563717842102
- *URL:* oculto
- *Início:* 00:18:47
- *Fim:* 00:20:41
- *Transcrição:* representado profunda era muito mais complexo não é interpretável então basicamente o que eles observaram isso é que um modelo interpretável aqui representado pela regressão era tão bom quanto esse modelo não interpretável e ele se depararam a situação que é ou eu sigo as regras do desafio e apresento o meu modelo de aprendizado profundo e apresenta uma estratégia para tentar explicar o que esse modelo tá prevendo que tem técnicas para isso Ou eu apresento meu modelo de agressão linear e mostro olha por que que eu vou fazer um modelo não interpretável se eu consigo resolver com um desempenho tão bom quanto usando um modelo interpretável então basicamente o que eles fizeram eles submeteram esse modelo baseado na regressão linear eles fizeram um site interativo que mostrava né basicamente o que que tava contribuindo para esse risco de nardimplência para um determinado cliente tá através da análise desses coeficientes e eles não ganharam o desafio mas eles ganharam esse porque eles basicamente né trouxeram esse modelo totalmente transparente em uma dashboard friendly então não só o modelo era transparente Mas eles permitiu que as pessoas interagir com isso e na realidade o maior ganho desse desse dessa equipe pesquisadora foi trazer né para discussão do momento de Por que que a gente precisa começar já determido que o problema tem que resolver tem que ser resolvido com o modelo que não é interpretável tá porque se tem essa falsa ideia de que modelos não interpretáveis são esses modelos mais complexos são os únicos possíveis de resolver um problema aparentemente complexo com desempenho razoável tá ou satisfatório Então existe essa discussão e aí essa pesquisadora ela falou essa internet essa escolha imposta entre a curasse a interpretabilidade é de modelos é uma falsa dicotomia né

- *Corpus ID:* 7170
- *Score:* 0.8492812514305115
- *URL:* oculto
- *Início:* 01:28:32
- *Fim:* 01:30:43
- *Transcrição:* Deep learning isso era bem Inicial né então vocês podem esperar muito mais do que isso para hoje tá aqui a gente tem um outro sistema do metp que é um sistema comercial e eles T outros sistemas outros dispositivos de captura né eventualmente alguns dispositivos capturam informação tridimensional também outros capturam só cor e e a partir das informações de cor a gente pode reconstruir né uma ou fazer uma reconstrução tridimensional do ambiente também e Navegar eventualmente né Por esse ambiente virtual eh usando esse tipo de ferramenta tá isso aqui se tornou bastante Popular especialmente fora do Brasil não sei como é que tá aqui dentro para eh em Sistemas de Imobiliária né Então a gente tem uma imobiliária tem um apartamento que a gente quer alugar Quer comprar uma casa e ao invés de me deslocar ir lá e e ver que eu não gostei né antes de tudo dá para fazer uma navegação virtual e bom se eu achei que é legalzinho de repente eu eu pago né o Uber pago o ônibus pago a gasolina para ir até lá ver tá mas mas fica um sistema de screening assim né para determinar se eu devo ou não devo investir naquela compra naquele aluguel tá eh e hoje em dia a gente tem soluções aqui é um dispositivo específico aqui é outro dispositivo específico para captura eh mas a gente tem soluções que tão mais portáteis né mais na palma da mão do que do que nunca então sei lá eu eu vou falar do iPhone embora não tenha um iPhone eu vou falar do iPhone porque eu sei que tem aplicativo para isso nele eh em que a gente de fato faz esse tipo de reconstrução eventualmente não é tão boa quanto né desses exemplos que foram dados mas ele consegue de uma forma ou de outra fazer um mapeamento de ambientes pequenos e e e te ajudam né a interagir com esses ambientes tá Ahã Professor


**Resposta gerada pelo LLM**: Problemas de linguagem, como os modelos de linguagem, e problemas de visão computacional complexos demais para algoritmos clássicos, que envolvem dados não estruturados como imagens, texto livre ou outros tipos de dados não estruturados.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should address the types of problems that benefit from deep learning comprehensively. Supporting Evidence: The RESPONSE directly addresses the PROMPT by identifying specific types of problems that benefit from deep learning, such as language problems and complex computer vision tasks. It also mentions the nature of the data involved (non-structured data like images and free text), which adds relevant context. This comprehensive coverage of the types of problems aligns well with the PROMPT's request.  Score: 3


---
