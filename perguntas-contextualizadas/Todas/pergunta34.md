**Pergunta 34**: Qual é a importância do pré-processamento de dados para o sucesso de modelos de aprendizado de máquina? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2176
- *Score:* 0.8828456997871399
- *URL:* oculto
- *Início:* 00:21:37
- *Fim:* 00:23:35
- *Transcrição:* vezes os dados são bons só que estão cheio de ruídos precisam de tratamento né tem que falar tem alto lá ele tem valores faltantes enfim tem que passar por um pré-processamento de quantificação categórico numérico numérica categórico tem uma série de questões ali normalização então às vezes não é só o dado não quer dizer que ele seja o suficiente para aquela tarefa ele só precisa desse refinamento digamos assim tá então isso é um é digamos assim senso comum e aprendizado de máquina vocês provavelmente Vão ouvir falar várias vezes que até garganta de alta né então por isso que a gente tem que evitar alimentar esse processo de alimentos modelos com dados que são lixo que são ruins Ok E aí tem duas questões aqui importantes né Se eu tiver dados muito bons né que representam esse diamante Se eu tivesse dados muito bons tiveram um processo de modelagem de treinamentos de modelos ruins certo então por exemplo eu não cuidei overfiting eu não tô avaliando bem o meu modelo enfim o meu resultado sim pode ser ruim eu posso estragar digamos aquele potencial dos dados em função de não explorar bem essa modelagem na parte de Treinamento avaliação e seleção dos modelos agora quando eu tenho dados ruins mesmo que eu faço essa metodologia de treinamento do modelo né mas da parte já é essa divisão dos dados dados Independentes treinamento a validação enfim se eu fizer isso de forma Impecável se os meus dados forem muito ruins essa modelagem Impecável do ponto de vista de metodologia ela não salva esses dados ela dificilmente salva esses dados certo então a gente tem que cuidar a gente tem que entender o que que a gente precisa trabalhar em nível de dado né para que a

- *Corpus ID:* 2175
- *Score:* 0.8792329430580139
- *URL:* oculto
- *Início:* 00:20:03
- *Fim:* 00:22:04
- *Transcrição:* vai ver de como eu vou dividir os dados como eu vou avaliar meu modelo tá então a gente muitas vezes começa a pensar nisso mesmo numa etapa anterior ao treinamento propriamente dito certo então enfim algumas referências vocês vão ver 70% 80%, eu usei uma referência aqui que eu poderia citar nessa estimativas podem variar mas é um consenso a gente gasta muito mais tempo no pré processamento dos dados e muitas vezes a gente passa por essa etapa mais de uma vez né a gente inicia faz o treinamento percebe que ainda não tá bom volta no pré-processamento resolve outros problemas né então não dá para a gente desprezar a importância dessa boa metodologia de aprendizado de máquina para o sucesso dos modelos né pensando nesse ponto com uma certa ênfase na questão é processamento de dados e tem um dito popular digamos assim aprendizado de máquina talvez alguns já tenham ouvido falar que é esse garbage em garbar de alto tá então basicamente o que ele tá dizendo o seguinte se o meu modelo Se eu tentar desenvolver o modelo a partir de lixo ou seja dados que a gente chama lixo porque são Dados que são ruins para aquele propósito certo o meu modelo vai ser um lixo também então é basicamente a nossa análise o nosso modelo ele só vai ser tão bom quando for em nossos dados então se eu não tiver dados bons e às vezes os dados eles podem ser deficientes para aquela tarefa mas às vezes os dados são bons só que estão cheio de ruídos precisam de tratamento né tem que falar tem alto lá ele tem valores faltantes enfim tem que passar por um pré-processamento de quantificação categórico numérico numérica categórico tem uma série de questões ali normalização então às vezes não é só o dado não quer dizer que ele seja o suficiente para aquela tarefa ele só precisa desse

- *Corpus ID:* 2314
- *Score:* 0.8788168430328369
- *URL:* oculto
- *Início:* 00:00:04
- *Fim:* 00:02:18
- *Transcrição:* ok pessoal então bom dia a todos vamos dar início então a essa semana dessa disciplina de metodologia de aprendizados supervisionado onde a gente vai começar a falar sobre o processamento de dados tá então na semana passada a gente falou sobre a parte de avaliação de modelos Claro que não é um assunto encerrado né conforme vocês tenham dúvidas a gente a gente pode discutindo a gente pode detalhar algumas coisas a mais em momentos de aula pelo fórum e é uma coisa que vocês vão usar ao longo da disciplina tá E de outras questão de avaliação de modelos certo só que a disciplina ela também tem uma ideia de discutir a parte para processamento de dados né então hoje a gente vai fazer uma introdução a esse tema e a gente vai falar sobre diferentes tarefas envolvidas nessa parte de limpeza e transformação de dados tá então a primeira etapa para processamento comentando assim alguns problemas comuns algumas soluções comuns tá é difícil né já adiantando nessa área a gente a gente dá uma receita de bolo né dizer Olha dessa situação esse tipo de solução melhor nessa situação esse tipo de solução é melhor eu tento trazer dicas para vocês Tá mas digamos assim nada que a gente pode afirmar que uma solução ou outra é a melhor a gente vai precisar realmente dependendo dos dados do contexto fazer essa essa avaliação Tá bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou

- *Corpus ID:* 2194
- *Score:* 0.8774141669273376
- *URL:* oculto
- *Início:* 00:50:04
- *Fim:* 00:52:15
- *Transcrição:* vai discutir ao longo dessas etapas de pré-processamento como fazer as coisas sem deitar sem vazamento de dados tá E aí eu vou Relembrando com vocês Esse conceito mas isso é muito importante porque às vezes o pessoal faz para processamento de forma que de fato adiciona digamos assim né esse risco de contaminação de dados bom e o que a gente vai discutir então é a gente vai começar agora depois vai fazer um intervalo e vai continuar é justamente a questão de avaliar os modelos preditivos tá é claro que a gente aqui ele tá falando explore muitos modelos e selecione os melhores o que a gente vai discutir é seja nessa etapa de checking seja numa etapa de ajuste fino dos modelos como é que eu faço a divisão de dados para poder fazer essa avaliação e na segunda aula da semana como é que eu avalio esses modelos do ponto de vista de outras métricas de desempenho tá então a ideia a gente expandir um pouco as métricas de desempenho na aula que vai ficar gravada para vocês que vai ser a aula do feriadão ok uma pergunta até aqui pessoal antes a gente para o segundo parte dos likes pode falar só uma perguntinha essa metodologia que a gente tá vendo para o aprendizado supervisionado ela se aplica ou não supervisionado também algumas coisas assim outras não porque outras por exemplo coisas como normalização de dados transformação de atributos Auto laires valores faltantes isso sim isso vai ser aplicado agora outras coisas como por exemplo vazamento de dados não porque a gente supervisionado a gente tem aquela ideia de ter um alvo e aprender a estimar aquele alvo a partir dos dados né então o vazamento de informações tá quando eu uso dados de teste que a gente tá sumindo que não conhece essa saída para o treinamento do modelo então

- *Corpus ID:* 2195
- *Score:* 0.8761346936225891
- *URL:* oculto
- *Início:* 00:51:40
- *Fim:* 00:53:53
- *Transcrição:* coisas como normalização de dados transformação de atributos Auto laires valores faltantes isso sim isso vai ser aplicado agora outras coisas como por exemplo vazamento de dados não porque a gente supervisionado a gente tem aquela ideia de ter um alvo e aprender a estimar aquele alvo a partir dos dados né então o vazamento de informações tá quando eu uso dados de teste que a gente tá sumindo que não conhece essa saída para o treinamento do modelo então aí essa relação né de vazamento de dados aí já é diferente mas a questões por exemplo de avaliação de modelos muda Tu aprendeu as coisas do nada também existem estratégias para avaliar modelos novos profissionado é mas elas são diferentes supervisionado tá então eu diria que eu diria que a parte pré-processamento de dados ela se aplica tá ela se aplica bem porque muitos desses algoritmos nós pressionados vão demandar preparação de dados para processamento Ok Ok mais alguma pergunta acho que a gente vai começar então a discussão sobre estratégia de divisão de dados então como eu comentei né primeiro assunto da disciplina avaliação de modelos preditivos tá então a gente vai aprofundar o que a gente vem discutindo e essa avaliação de modelos preditivos a primeira coisa que a gente vai discutir estratégias de divisão de dados porque a gente viu que a gente não pode avaliar modelos em dados que não sejam Independentes ou seja dados que não foram vistos em tempos de treinamento e existem diversas estratégias para a gente fazer isso né então a gente vai discutir essas mais comuns e uma que é considerada tipo assim talvez né o chamaria o estado da arte tinha mais recomendada que a validação cruzada tá e tem diversas variações Ainda assim eu trouxe outras que vocês inclusive já ouviram falar que

- *Corpus ID:* 2119
- *Score:* 0.8738810420036316
- *URL:* oculto
- *Início:* 00:22:02
- *Fim:* 00:23:58
- *Transcrição:* quer dizer que vocês não possam fazer vocês podem fazer tá não tem nenhum problema em relação a isso tá tem uma pergunta do Antônio Fagner pode falar Oi Mariana é só para acrescentar o seguinte né quando a gente se a gente for fazer isso para todos os algoritmos por exemplo fazer normalização é importante a gente é tipo deixar dentro de uma função porque porque os dados que a gente vai receber que não conhece a gente a gente tem que aplicar as mesmas transformações que aplicamos que nós aplicamos nos dados então é sempre interessante a gente deixar isso pronto para aplicar nos dados não vistos ainda exato toda transformação que vocês fizerem dados de Treinamento vocês vão precisar fazer nos novos dados Então isso é bem colocada essa preocupação tem que ter porque se o modelo aprende a partir de dados normalizados quando chegar em novos dados eles não podem estar na distribuição original Eles também precisam passar pela mesma transformação e a gente vai discutindo disciplina seguinte que tem uma ideia no site ele tem um recurso que chama um pipeline então a gente cria um pipeline a gente vai fazer alguns exemplos disso cria um pipeline e que é como se o passo a passo né de transformação de dados e depois treinamento ou predição né dependendo se eu tô fazendo desenvolvimento do modelo ou se eu tô fazendo avaliação do modelo com novos dados Então isso é interessante porque vocês mesmo que vocês não usem o site plano independente da ferramenta da linguagem você realmente precisam Esse passo a passo de pré-processamento se prepararem para preparar para aplicar nos dados de teste tá então isso é bem notado falando um pouquinho de dados categóricos tá valores categóricos aqui principalmente dos atributos ou seja não em relação a classe tá mas uma coisa que vocês vão notar é que por exemplo svm e

- *Corpus ID:* 2315
- *Score:* 0.8736072778701782
- *URL:* oculto
- *Início:* 00:01:45
- *Fim:* 00:03:41
- *Transcrição:* bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou quase tudo eu diria quase tudo a gente também tem que fazer o conjunto de teste tá então as etapas que a gente vai discutir hoje de limpeza do conjunto de Treinamento praticamente todas a gente tem que replicar no conjunto de teste tá tem outras conforme a gente for avançando eu vou comentando com vocês o que que a gente não faz no conjunto de teste porque tem algumas questões que a gente realmente não é adequado a gente fazendo o conjunto de teste bom E aí lembrando também que a gente falou na nossa aula introdutória que quando a gente está falando de desenvolvimento de modelos de aprendizado de máquina está falando de uma metodologia envolvida né e diversos Passos Então as nossas decisões a respeito dessa metodologia é o que é decisões a respeito de cada passo é o que define a nossa metodologia do ponto de vista de pré-processamento a gente tem tanta parte de decisões da coleta e preparo dos dados Então quais são os atributos como é que vou transformar esse atributos como é que eu vou particionar os dados para desenvolver o modelo né treinar validar otimizar e preparamos como é que eu vou lidar com valores faltantes enfim tá E também a parte de engenharia de atributos Então a gente vai estar discutindo um pouquinho essas etapas iniciais esse processo de preparar os dados

- *Corpus ID:* 1408
- *Score:* 0.871679961681366
- *URL:* oculto
- *Início:* 00:44:24
- *Fim:* 00:46:40
- *Transcrição:* usar esse tipo de análise para definir questões de pré-processamento como por exemplo a questão de como fazer a normalização dos dados né a gente basicamente o que a gente tem algumas combinações às vezes que podem até sair melhor por exemplo de questão de preprocessamento com algoritmo mas é coisas que são aspectos muito difícil da gente estabelecer regras tá então a gente normalmente isso se vocês podem fazer esse tipo de avaliação é interessante comprar é processamento de normalização de forma de imputação de valores a questão é que muitas vezes isso decorre um custo muito grande computacional porque a gente vai estar fazendo isso em Loops depois a gente vai ver que tem vários looks de avaliação quando a gente discutir na próxima disciplina estratégia de validação cruzada enfim tá então mas eu posso dizer o seguinte o impacto dessas normalizações ele não é tão grande assim tá assim no sentido de que vai mudar drasticamente o resultado do modelo de vocês tá pode ser que uma técnica ajude um pouco mais a determinar alguns padrões mas isso a gente tem que observar caso a caso mas por exemplo se vocês têm tempo e recurso limitado vale muito mais a pena selecionar uma um tipo de normalização usei scoremax de forma bem arbitrária digamos assim olha escolhi mimax né E focar em explorar mais algoritmos do que gastar mais tempo com essa parte escolher uma estratégia de normalização invariavelmente vai funcionar porque porque não importa se os teus dados obedecem distribuição normal ou não o mimax você pode utilizar e talvez assim olha só não tô realmente tô pensando agora se você tem uma distribuição que é normal aí você aplica normalização ele vai colocar ali com a média zero dizia o padrão é um É sim Ali vai se adaptar vai ficar legal assim é mais você independente do tipo de distribuição que

- *Corpus ID:* 2354
- *Score:* 0.871597170829773
- *URL:* oculto
- *Início:* 01:04:29
- *Fim:* 01:06:41
- *Transcrição:* dados faria todo o pré-processamento aí depois dividiria um treino e teste mas esse raciocínio então não tá correto né eu preciso primeiro dividir meus dados no treino e teste seja lá quais outros técnicas lá de divisão aí fazer só nos dados de treino para processamento e guardar digamos esse esses as técnicas que foram utilizadas para depois não vai pirar e usar o teste Exatamente é porque assim a gente acha que às vezes a gente tem impressão que usar o dados de teste para por exemplo aprender como fazer imputação de valores é algo que não vai ter feito mas na verdade tem tem porque eu tô estimando uma média com dados que o modelo ainda não viu então isso isso pode influenciar o modelo às vezes até de forma positiva sabe colocar um valor digamos assim seja estimado por um modelo ou por valor fixo isso pode acabar envezando o desempenho do modelo positivamente Então o que a gente faz é isso todo dado que ele é de teste ou de validação porque também isso também vale para validação como você falou né dependendo das estratégias tem várias estratégias para gerar o dado de validação Mas a gente não pode usar nada referente esses dados para desenvolver o nosso modelo esses dados são usados especificamente validar ou seja comparar e preparametos ou algoritmos de validação e o de teste para dar o meu desempenho final tá agora não esqueçam que depois que a gente termina toda essa parte de desenvolvimento do modelo o nosso modelo de produção ele vai ser sempre gerado com base nos dados todos que a gente tinha no primeiro momento e é isso vai digamos assim vai passar também por um processo de restimar essas por exemplo média ou mediana ou retreinar esse modelo certo para tornar digamos assim o modelo e o pipeline que transforma os dados prontos para esse modelo de produção esse modelo que vai ser

- *Corpus ID:* 1848
- *Score:* 0.8706811666488647
- *URL:* oculto
- *Início:* 01:07:51
- *Fim:* 01:09:52
- *Transcrição:* decisão baseada em proporções de exemplos por classe né então isso impacta menos né do que do que outros algoritmos que a gente discutiu ele impacta menos mas sempre que a gente vai trabalhar com aprendizado de máquinas de ruídos e outlanders que são pontos que vale a pena a gente pensar em tratar como pré-processamento tá mas ele é menos sensível a isso e essa questão da flexibilidade Eu já comentei né que ele é um algoritmo muito flexível em relação a suposições então a gente diz que ele é um método não paramétrico ele não tem nenhuma suposição sobre a natureza dos dados tipo de distribuição essa questão da comparação dos valores com escalas diferentes isso não impacta a árvore de decisão tá então ele é um algoritmo que a gente pode dizer assim é poucos requisitos em relação a pré-processamento algumas outras questões enfim alguns problemas né replicação de estruturas tá então pode acontecer de eu ter subarvores ou seja são conjuntos de testes encadeados que se repetem no modelo tá isso pode acontecer ou seja até mesmo sequência de testes mais em cima da árvore e depois mais abaixo da árvore isso pode acontecer por conta né da forma que ele olha só o que tá o que é melhor naquele momento não reviso que já foi feito nem o que vai ser feito no futuro elas são bastante propensas a over fiting pessoalmente quando tem uma árvore profunda Ou seja quando eu tô gerando partições super pequenas e aí a gente vai ver que algumas regras são geradas para se adaptar aquele ruído lá né do que tá no meu dado de Treinamento E aí isso gera um overflite no outro material que a gente não vai discutir hoje até posso mostrar rapidinho vai gerar um overfite tá ela não consegue detectar linearidade entre atributos e classes ou entradas e saídas tá justamente porque essas saídas sempre


**Resposta gerada pelo LLM**: O pré-processamento de dados é crucial para o sucesso dos modelos de aprendizado de máquina, pois dados ruins resultam em modelos ruins ("garbage in, garbage out").  Dados podem ser bons, mas conter ruídos, valores faltantes, necessitando de tratamento (quantificação categórica/numérica, normalização).  Um bom pré-processamento refina os dados, tornando-os adequados para a tarefa.  A metodologia de treinamento impecável não salva dados ruins; a qualidade dos dados é fundamental.  Gasta-se muito tempo no pré-processamento, muitas vezes repetidamente, até se obter um resultado satisfatório.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. Supporting Evidence: The RESPONSE directly addresses the importance of data preprocessing for the success of machine learning models, which is the core of the PROMPT. It explains how poor data quality can lead to ineffective models, emphasizes the need for handling noise and missing values, and highlights the significance of refining data to make it suitable for training. The mention of the time spent on preprocessing further supports the argument about its critical role in achieving satisfactory results. Therefore, the RESPONSE is relevant to all aspects of the PROMPT.  Score: 3


---
