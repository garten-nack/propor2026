**Pergunta 130**: Como o Hadoop garante a redundância de dados?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 6001
- *Score:* 0.870415449142456
- *URL:* oculto
- *Início:* 01:41:01
- *Fim:* 01:42:55
- *Transcrição:* digamos assim né então comparando os bancos de dados relacionais com bancos de do do Map redu né ou do hdfs por trás né então Eh enquanto os bancos de dados tradicionais eles priorizam mais esse acesso iterativo né o map redus é só processamento em Bet tá em termos de atualização a gente a gente pode escrever uma única várias vezes num banco de dados tradicional né faz update e tudo mais no hdfs map reduce tu escreve uma vez tu pode até fazer concatenação e tudo mais né num banco de dados tu tem aquelas transações acid né que é as características acid atômicas consistentes isolados e duráveis né Tem tem o conceito de transação né que é absurdamente importante para inúmeros eh problemas por exemplo de transações bancárias esse tipo de coisa né numa redus isso simplesmente não existe tá então tu tem que ter outras formas de garantir isso tá então em termos de integridade alta no banco de dados escalabilidade não é linear né mas no map redu Tu tem uma uma integridade baixa né porque pode dar problema e tudo mais e tu perder as réplicas né E talvez tu não consiga reconstruir tudo e aí tu perde a informação né então tem que ter um cuidado bastante grande nesse aspecto mas a escalabilidade é linear né então tipo se tu tem a falta de falta de tem problemas de escalabilidade é muito melhor usar o map redus só só comprar mais máquina e concatená-las né então fica fácil fazer upgrade em um cluster map redu só tu comprar mais máquina coloca o sistema roda data noes disde que aqueles data noes existem e deu né então é bem fácil estender o a plataforma e as máquinas não precisam ser necessariamente idênticas né o pessoal que botou no chat aqui né que todas as máquinas tem aquelas carterísticas mas bom se for comprar mais máquina hoje provavelmente a CPU

- *Corpus ID:* 5949
- *Score:* 0.8658781051635742
- *URL:* oculto
- *Início:* 00:15:21
- *Fim:* 00:17:42
- *Transcrição:* para ler a integralidade dos dados ou seja tudo é feito eh no disco digamos assim out of Core que a gente que eh nada é guardado em memória Ok então quando a gente executa aquele grafo de tarefas aquele grafo de tarefas ele é efêmero né Ele é executado Ele lê os pedaços dos arquivos é feito o processamento mas assim que termina toda a informação intermediária é perdida entendeu é guardado só a resposta final certo então ã por isso que a gente diz assim que ele tem que ter alta vazão esse sistema ele tem que ser capaz de ler grandes volumes rapidamente né porque ele não tá usando memória isso destoa bastante do que a gente vai ver semana que vem que é o Spark que o Spark é a mesma coisa só que em Memory daí né então ã então ele usa também clusters de computadores né para fazer esse processamento né como a gente já falou né em relação aos padrões de acesso por streaming acaba tendo uma característica bastante importante que é interessante a gente guardar que disto enormemente das dos bancos de dados tradicionais como Oracle e amigos post enfim MySQL esse tipo de coisa né é que aqui a gente vai escrever o dado uma única vez e a gente não pode alterar em geral entendeu a gente até pode alterar mas para alterar a gente tem que é um esforço bastante grande porque envolve eh ler o dado extraí-lo mudá-lo e depois injetar de novo então na real alterar mesmo no próprio radut não tem como tá é bem complicado de fazer isso né então o padrão é sempre esse escrever uma única vez e depois se entende que uma vez o dado lá no hdfs a gente vai ler ele várias vezes e ele e o sistema ele é feito para otimizar a leitura do dado certo ele é feito paraar só a leitura de maneira que a leitura seja mais rápida possível tá E ele assume também E aí pode ser surpreendente né ele assume também que as consultas requerem a leitura completa dos dados então H toda

- *Corpus ID:* 5932
- *Score:* 0.8607862591743469
- *URL:* oculto
- *Início:* 01:00:08
- *Fim:* 01:02:12
- *Transcrição:* facilidade na realidade assim existe depois a gente vai ver a estrutura do do hdfs né existe no hdfs um servidor específico para manter o rastreamento das réplicas então quando tu vai eh pedir o dado tu vai pedir para esses servidores Ah me dá o dado e ele já vai saber onde estão as réplicas entendeu então ele vai dizer não Ah tu quer esse dado aqui então tem uma réplica aqui tu pode contatar essa máquina aqui entendeu então aonde estão as réplicas é tudo bem bem bem registrado Entendeu então acaba tendo acaba não tendo essa noção de probabilidade de encontrar porque a gente sempre vai encontrar se o dado tá lá entendeu eh existe esse como se fosse um dicionário entendeu É como se fosse aquele conceit de name node data node para fazer Exatamente exatamente eu tô falando do name node entu bu ã então tá então isso é os dados estão distribuídos né A Ideia dois eh as aplicações elas são distribuídas Seguindo os dados então isso diz respeito à descentralização da aplicação Então em vez da aplicação executar no nosso notebook ou executar em uma única máquina né já que os dados estão distribuídos a aplicação tem que ser distribuída também né E quando digo de distribuição é exatamente o conceito que a gente já viu lá no no desk né quando vocês criavam aquele gráfico de tarefas vocês já estavam eh quebrando a aplicação em pedaços né e e claro eh é o escalador que ia distribuir ela né mas já existia essa descentralização da aplicação então isso eh pode não ser tão simples né hoje em dia tá simples ali de fazer né porque a gente tem o dask esse tipo de ferramenta a gente vai ver o raduk também tem as ferramentas associadas mas mas pode ser isso pode ser uma tarefa bem complicada de fazer eh porque a gente pode ter um cluster muito grande né então como é que gerencia né a tu pega uma única aplicação tu já quebrou ela em pedaço como é que tu executa ela no cluster

- *Corpus ID:* 6126
- *Score:* 0.8577920198440552
- *URL:* oculto
- *Início:* 00:15:35
- *Fim:* 00:17:52
- *Transcrição:* entendi é se a gente tiver US Bruno se a gente tiver usando o hdfs Né o hdfs ele não permite ass tipo assim tu alterar o dado entendeu tu pode no máximo concatenar o dado no final Entendeu essa é uma característica do hdfs né então se uma aplicação ela já começou a ler um bloco né E outra aplicação vem e começa a concatenar no final daquele arquivo né Eh eu imagino assim que eu eu eu eu imagino que não exista uma um mecanismo assim de eh eh que vai avisar as aplicações e que Ah tu tem alguém escrevendo no dado que tu tá lendo entendeu ou no escrevendo no final no caso né fazendo a concatenação então é realmente fica a responsabilidade de tu ter um eh workflow né Eh que coordena nas tuas aplicações então tipo que que roda primeiro uma aplicação e depois roda outra né se a gente quiser fazer ã algum tipo de tratamento de dados em streaming né que é aí nós temos outros componentes do apach né do ecossistema da apat que nem a gente viu lá naqueles slides bem rapidamente né Eh que eu mostrei o site para vocês lembra com a lista e tal das da das aplicações da dos frameworks que estão nesse ecossistema né lá tem alguns frameworks que lidam com eh streaming de dados né que daí tu pode ter eh tu tem que criar digamos tarefas né que lidam com a leitura com o tratamento e depois escrev em paralelo esse tipo de coisa e aí talvez pudesse ser um pouco no contexto do teu questionamento entendeu Mas de base assim se a gente for olhar o hdfs Eu acredito que ele não tenha nenhum tipo de mecanismo para proteger de um uso onde tu tem leitura e escrita ao mesmo tempo ainda que ela escrita só aconteça no final dos arquivos bom Ah então Eh cada aplicação vai ter esse esse isolamento né então o comp de dados é sempre feito através do file System né e e as aplicações Spark elas podem operar a mesma aplicação Spark ela pode operar sobre diferentes

- *Corpus ID:* 5968
- *Score:* 0.8572496771812439
- *URL:* oculto
- *Início:* 00:46:34
- *Fim:* 00:48:44
- *Transcrição:* é no mesmo onde tá o name node tradicional e ele tá sempre normalmente um pouco atrasado em relação ao principal Então porque assim as coisas acontecem sempre com name noes e de vez em quando o name node ele sincroniza o espelho dele ok mas então quer dizer se acontecer alguma coisa nesse interstício assim antes de acontecer essa sincronização e alguma coisa mudou né algo vai ser perdido mas não vai ser perdido tudo tá Então essa é é a vantagem de ter o name nomes então assim eh existe dentro do rup um negócio chamado hdfs High availability que é o ha para evitar o Down time de substituição Então nesse caso a gente mantém um par de name nodes em stand by e e basicamente as atividades elas são recebidas por todos os nodes a gente consegue meio que ter uma capacidade de resposta de metadados mais rápida para nossas aplicações então é como se a gente tivesse um vários nam noodes funciodo em uníssono digamos assim para responder aos pedidos de informação sobre os arquivos e e orientando as aplicações aonde que elas devem entrar em quais data noes elas devem entrar em contato para obter os dados um cluster de name nodes é daria para dizer que seria um cluster de name nodes mas ele sempre vai ser um conjunto bem menor do que o cluster de data nodes né que o cluster de data nodes é onde estão os dados mesmo aqui ali tem um monte daí mas a gente pode ter um mini cluster de name nodes daí para responder mais rápido só você faz backup de name node data node não é normalmente faz backup só de porque assim tu fazer um backup de data noes envolve fazer um backup dos de todos os dados é dos todos os dados né assim tipo normalmente não tem como né tipo tu a menos que tu tenha uma plataforma Idêntica a que tu tens para tu replicar tudo assim né ocuparia muito espaço né Entendi então assim esses mas assim esse backup ele já meio que

- *Corpus ID:* 8878
- *Score:* 0.8565118312835693
- *URL:* oculto
- *Início:* 00:15:18
- *Fim:* 00:18:08
- *Transcrição:* que ele faz então qualquer sistema distribuído ele tem que ele pode no caso né optar por duas propriedades E aí a gente consegue usando duas propriedades consegue garantir que a base de dados eh se mantém consistente né então aqui a gente tem consistência né disponibilidade e tolerância de partição Então a gente tem aí no caso três combinações Diferentes né então por exemplo aqui o que que a gente pode usar Então posso usar com consistência e e disponibilidade né Então aí a gente eh eh para aplicações onde a tolerância de partição então a a falha de rede não vai ter um impacto tão grande então no no desempenho e na consistência das aplicações né então aqui um outro tipo né de de combinação de consistência quando eu tenho a consistência dos dados Então eu preciso sempre trabalhar com os dados corretos Mas e a tolerância de partição Então eu tenho que eh cuidar né Para que se der alguma falha de rede o sistema né continue eh operando então aqui a gente nesse caso a gente vai flexibilizar a disponibilidade né então são para as aplicações em que a gente a gente pode né ficar um tempo com os dados indisponíveis até eles né voltarem e a última eh combinação que a gente tem então é disponibilidade e né tolerância de partição E aí a gente tem né uma a consistência ela pode est ameaçada né então aqui o que a gente vai fazer é para em cada um dos casos né a gente vai analisar o contexto da aplicação né E aí a gente vai ver quais são as necessidades prioritárias então tem alguns bancos de dados que mantém as três né aí a gente vai ter Possivelmente alguma penalização de desempenho mas muitos então assim o que é rígido que mantenha pelo menos duas restrições né então se eu pego por exemplo eh se lá um sistema bancário por exemplo eu preciso ter consistência e preciso ter

- *Corpus ID:* 5953
- *Score:* 0.8564503788948059
- *URL:* oculto
- *Início:* 00:21:49
- *Fim:* 00:24:06
- *Transcrição:* eh com grande volume né Não sei se isso Responde então tua pergunta Alexandre Marques Mas é isso que eu tinha como resposta vamos adiante então Eh então assim eh então essa parte do projeto do hdfs né então tem essa essas ideias filosóficas aí né Tem obviamente algumas desvantagens né então por exemplo se eu quero fazer acesso a dados com baixa latência eu quero por exemplo Ah eu quero a linha de número tal do meu da minha tabela lá e aí eu quero pegar um da um uma pequena coluna lá e tal aí isso não funciona muito bem porque o o o ele não foi projetado para ter baixa latência o hdfs ele foi projetado para ter alta vazão claro que é difícil ter as duas coisas né então assim eles fizeram uma escolha Foram pela alta vazão então existem alguns subprojetos do do do próprio rup aí né Do do ecossistema do rup que se propõe a ser eh escolhas melhores se tu precisa de uma coisa mais estilo base de dados assim né tipo base de dados relacional tradicional que ao invés de ser relacional puro assim que seja mais mais no sentido assim de rup e tal aí nesse caso tu um dos subprojetos é o esse hbase aqui né daí ele ele tenta mimicar um pouco assim o comportamento de bases de dados tradicionais eh uma outra desvantagem que acontece bastante frequentemente é se eu tenho um monte de arquivo pequeno tá se eu tenho um monte de arquivo pequeno o o rup o hdfs não foi feito para isso porque um dos componentes do rup a gente vai ver logo em seguida ele é responsável por guardar os metadados E esses metadados são guardados em memória Então vai ter lá um servidor de nomes né E esses metadados ficam na memória desse servidor de nomes então se eu tenho muito arquivo pequenininho acaba que a gente pode bater no limite da memória desse servidor de nomes né então pode faltar memória enfim e aí tem no livro ali né a referência que cada arquivo diretório

- *Corpus ID:* 6033
- *Score:* 0.8564127087593079
- *URL:* oculto
- *Início:* 00:45:16
- *Fim:* 00:47:21
- *Transcrição:* do serviço data node que tá com aquele bloco levar ele até um nó onde foi alocado aquela tarefa de mapeamento eh eh bom então assim na saída do Map Então a gente tem dados efêmeros tá que eles não são feitos não são escritos no hdfs porque eles são temporários eles são intermediários né então o que que o o map faz ele registra Eh esses dados eh no disco local digamos assim né fora do hdfs né E esses dados intermediários eles vão ser lidos pelas tarefas de redução né porque é a tarefa de redução é a segunda etapa digamos assim né o mapeamento Ele simplesmente massivamente paralelo mapeamento é massivamente paralelo em função da quantidade de blocos que a gente tem é um mapeamento para cada bloco E aí o que que tem na saída vai ter tipo um checkpoint só que esse checkpoint como ele é efêmero né é a saída do mapeamento é uma coisa assim que daquela aplicação Então é assim ele salva no disco local ele não injeta no hdfs a gente não precisa de replicação eh essa ideia porque se porventura eh aquele no que tem que executou a tarefa de mapeamento tem que tem o dado da saída do mapeamento falhar se esse nó falhar não tem problema tipo assim o yarne vai se dar conta disso e vai dizer assim ó onde é que tá um bloco uma réplica daquele bloco que aquele mapeamento lá executou Aí ele diz ah tá em outro nó ele vai lá e lança de novo o mapeamento lá não tem problema então assim tipo é a ideia de tolerância Fes É nesse aspecto também então aí entra a fase de redução então a a fase de redução infelizmente ela não consegue usufruir da localidade dos dados né porque vocês Imaginem tem blocos espalhados pela máquina inteira cada bloco foi processado por um mapeamento em cada um desses nós onde esse esse mapeamento foi executado vão ter os as saídas do mapeamento aí agora a tarefa de redução ela é É como tem esse nome né de redução Então ela tem que se

- *Corpus ID:* 5971
- *Score:* 0.8562113046646118
- *URL:* oculto
- *Início:* 00:51:39
- *Fim:* 00:53:50
- *Transcrição:* nesse caso seria a quantidade de blocos já tinha identificado quantas colunas tinha então provavelmente ele leu o início do primeiro bloco ali pegou a informação de Eh quantas colunas tem os tipos dos dados etc né e nos deu mas ele não leu efetivamente né então ele só vai ler efetivamente e e orientar os datanodes a lerem integralmente os dados na hora que a nossa aplicação efetivamente vai fazer uma operação e isso acontece sem envolvimento do nam node né acontece diretamente do cliente com os data noes então Eh o nam node tem um papel interessante aqui porque ele pode cooperar com o escalonador da aplicação para balancear o uso dos data nodes né então normalmente as aplicações elas tentam eh realmente usufruir da distribuição dos dados e tal para que a gente não sobrecarregue um data node com muitas requisições de leitura ã eh em relação ao tratamento das réplicas né na leitura né aí a abordagem ela ela escalável porque os clientes se conectam direto com os data nodes né então o envolvimento do nam node aqui ele é bastante rápido né Tipo o cliente vai lá contata pede Quais são os blocos e onde eles estão e deu e o já sai da jogada né e por outro lado o hdfs ele tem uma característica interessante na questão das réplicas que normalmente a gente consegue calcular uma distância entre os data nodes do cliente essa distância é uma distância lógica digamos assim não é uma distância física tá que é quantos hopes de de quantos hops de rede por exemplo eu preciso saltar para chegar lá no data node então consigo ordená-los de acordo com a a proximidade eh do leitor né E aí na hora que tu for ler uma réplica tu vai ler aquela que tá mais próxima de ti essa que é a ideia Ok jancarlo pode falar por isso quando a gente tem o cluster seguro vamos dizer assim você quer manter ele isolado se você precisar expor o hdfs você tem que

- *Corpus ID:* 5965
- *Score:* 0.8547390103340149
- *URL:* oculto
- *Início:* 00:41:40
- *Fim:* 00:43:58
- *Transcrição:* disponibilidade a não seria mais a probabilidade de encontrar um dado mas a a probabilidade de gente obter o dado que a gente quer rápido né porque a gente vai pedir pro pro hdfs Ah me dá esse esse arquivo aqui aí eh se as réplicas estiverem bem eh projetadas né talvez a gente consiga inclusive pedir assim ah eu quero esse bloco aqui com muita urgência e ele vai te é o primeiro que responde te responde a gente pode pedir para ler vários blocos o mesmo Bloco Eh várias vezes né porque ele tem réplicas e aquela réplica que é lida primeiro é aquela que tu vai usada daí entendeu E as outras tu descarta depois né Então essas duas coisas permitem a gente eh ter algumas vantagens assim né tipo de tolerância falas também no caso de problemas e tudo mais e na questão da alta disponibilidade então hã Essa é parte de vantagens tá não sei se você tem alguma dúvida mas qualquer coisa me interrompo tá agora falando da arquitetura do sistema né a arquitetura do sistema tem dois elementos principais tem um name noes que vai ser digamos assim o o coordenador o mestre né E tem os data nodes né os data nodes vão ser vários data nodes então Eh Essa é a arquitetura tradicional de um mestre vários trabalhadores é uma arquitetura centralizada tá isso tem até seus problemas tá porque tendo um único name node se o name node desaparece os data noes não sabem onde estão os dados né então isso pode ser um problema então é uma arquitetura bem tradicional o papel do Dame node é que Hã o os dados eles são persistentes né então isso vai ficar num disco local e a ideia do nam node é gerenciar o espaço de nomes do sistema de arquivos Então seria ele que mantém assim a informação de quais diretórios existem de de quais são os arquivos em cada diretório Quem são os donos desses arquivos Quais são as permissões E aí também saber quais são os blocos quantos blocos tem aonde


**Resposta gerada pelo LLM**: O Hadoop garante redundância de dados através de réplicas.  Quando um dado é solicitado, o sistema sabe onde estão as réplicas e direciona a solicitação para uma delas. Existe um servidor específico para rastrear as réplicas (name node), garantindo que o dado seja sempre encontrado se estiver presente no sistema.  Além disso, o sistema permite calcular a distância entre os data nodes e o cliente, permitindo que a réplica mais próxima seja lida primeiro.  Em caso de falha de um nó, o sistema identifica uma réplica em outro nó e executa o processo novamente.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: A resposta deve ser relevante para a pergunta sobre como o Hadoop garante a redundância de dados, abordando os mecanismos e processos envolvidos. Supporting Evidence: A resposta aborda diretamente a questão, explicando que o Hadoop utiliza réplicas para garantir a redundância de dados. Ela menciona o papel do name node no rastreamento das réplicas e como o sistema direciona as solicitações para as réplicas disponíveis. Além disso, a resposta discute a capacidade do sistema de calcular a distância entre os data nodes e o cliente, o que é relevante para a eficiência na leitura das réplicas. A menção ao tratamento de falhas de nós também é pertinente, pois demonstra como o Hadoop mantém a disponibilidade dos dados. Portanto, a resposta é completa e relevante para todos os aspectos da pergunta.  Score: 3


---
