**Pergunta 40**: Quais desafios foram enfrentados ao tentar automatizar a análise de recursos de multas, e como a tecnologia de reconhecimento de caracteres (OCR) se mostrou inadequada para lidar com a escrita manuscrita? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 7159
- *Score:* 0.8842727541923523
- *URL:* oculto
- *Início:* 01:09:57
- *Fim:* 01:11:59
- *Transcrição:* é outra história né talvez a gente precise eh de uma base de conhecimento geral de vários textos manuscritos talvez a gente precisa de uma base de conhecimento associada àquele aquele escritor né aquela pessoa que escreveu tá então é um outro problema eh e aqui tem alguns outros exemp professor Oi fale s parênteses assim tô interrompendo Porque você deu a liberdade no início mas assim a gente já teve um um Case aqui no cpro eh de um projeto que a gente precisava fazer um trabalho de ocr em cima de manuscritos que era justamente o são recursos que o cidadão coloca quando ele vai recorrer a uma multa então ele tem que manuscrito lá explicar porque é que ele está recorrendo aquela multa e o Detran tinha muitas e documentos desse tava digit iado mas tava em imagem né não tava em formato texto imagem de manuscrito e a gente queria fazer uma prévia tipo assim de analisar se aquele recurso deveria ser o não deferido previamente para ele ser eh julgado de acordo com que tinha mais probabilidade de ser eh deferido e não conseguimos falhamos justamente porque a gente não conseguiu fazer ocr dos manuscritos a probabilidade assim a acurácia de acerto foi muito muito baixa a época né Isso tá com alguns 4 anos mas um menos mas assim foi um processo que gerou uma complexidade eu não sei como tá hoje não participo mais nem do time que tava trabalhando disso mas mas foi o que atrapalhou foi a complexidade de fazer o reconhecimento de manuscritos a época é é não é um problema trivial né Tá longe de ser Tá longe de ser trivial eh tem tem aquele quase que senso comum né na na hora de tu ler um um um um receituário de um médico lá de não entender nada eh então quer dizer a gente a gente precisa de de alguma forma

- *Corpus ID:* 7160
- *Score:* 0.8793370723724365
- *URL:* oculto
- *Início:* 01:11:26
- *Fim:* 01:13:45
- *Transcrição:* complexidade eu não sei como tá hoje não participo mais nem do time que tava trabalhando disso mas mas foi o que atrapalhou foi a complexidade de fazer o reconhecimento de manuscritos a época é é não é um problema trivial né Tá longe de ser Tá longe de ser trivial eh tem tem aquele quase que senso comum né na na hora de tu ler um um um um receituário de um médico lá de não entender nada eh então quer dizer a gente a gente precisa de de alguma forma hã trabalhar com isso e provavelmente soluções baseadas em learning hoje são as que melhor se adaptam a esse tipo de situação não sei se na época já era já era algo assim provavelmente né Não sei se ess se essa informação é uma informação que possa ser comentada também mas mas enfim eh é um problema que Embora tenha a o seu eh a sua variante Toi né que é essa primeira eh ele pode ficar cada vez mais difícil então um um dos exemplos difíceis é esse de manuscritos né outro é daqui a pouco eu quero aqui tem um exemplo né identificar eh placas de veículos né então isso ainda é um ocr mas nota que eu preciso primeiro saber que eu tô eh identificando um veículo depois identificar a placa do do veículo depois identificar os caracteres dentro daquela placa né No Brasil a gente tem dois modelos de placa O que é Ok eh nos Estados Unidos Por exemplo cada estado tem né uma uma legislação diferente uma liberdade diferente para para customização de placas então isso se torna um problema bem desafiador também né Além de que eh nos dois exemplos anteriores de ocr a gente provavelmente tinha uma uma foto ou um da vista frontal né quando a gente tá falando de veículo e e e ocr de placa eh a gente eventualmente vai ter uma captura enviesada né uma captura transversal ali né não necessariamente o meu veículo vai estar de frente ou de Costas paraa câmera Pode ser que ele

- *Corpus ID:* 7158
- *Score:* 0.8704887628555298
- *URL:* oculto
- *Início:* 01:08:14
- *Fim:* 01:10:26
- *Transcrição:* certa forma eh uma série de de de ferramentas aí pra gente trabalhar com essas aplicações de visão computacional bom eh passando um pouquinho para algumas aplicações pessoal H aqui a gente trouxe justamente o exemplo de ocr que o colega comentou antes né então a gente tem diversos níveis de dificuldade de ocr né então CRR é optical Character recognition né então reconhecimento de caracteres eh por imagem né dá pra gente traduzir assim eh e a gente tem desde um ocr eh em documentos tipografados escaneados escaneados barra capturados com uma imagem né O que é um cenário bastante comportado digamos assim né a gente tem a imagem de um documento impresso que foi digitado bom isso é Ok porque a gente tem um conjunto limitado de fontes e a gente sabe mais ou menos né Eh como as as as letras devem aparecer umas com relação às outras e eventualmente num nível um pouco mais abstrato como uma palavra pode ou deve aparecer em relação às outras né Eh a gente tem Talvez uma versão um pouquinho mais eh um pouquinho mais desafiadora que essa que é fazer o ocr em cima de documentos manuscritos tá então aqui eu tenho uns garranchos meus né talvez alguns de vocês entendam talvez outros não fazer com que um sistema entenda eh é outra história né talvez a gente precise eh de uma base de conhecimento geral de vários textos manuscritos talvez a gente precisa de uma base de conhecimento associada àquele aquele escritor né aquela pessoa que escreveu tá então é um outro problema eh e aqui tem alguns outros exemp professor Oi fale s parênteses assim tô

- *Corpus ID:* 7161
- *Score:* 0.8537920713424683
- *URL:* oculto
- *Início:* 01:13:10
- *Fim:* 01:15:26
- *Transcrição:* customização de placas então isso se torna um problema bem desafiador também né Além de que eh nos dois exemplos anteriores de ocr a gente provavelmente tinha uma uma foto ou um da vista frontal né quando a gente tá falando de veículo e e e ocr de placa eh a gente eventualmente vai ter uma captura enviesada né uma captura transversal ali né não necessariamente o meu veículo vai estar de frente ou de Costas paraa câmera Pode ser que ele esteja um pouco uma orientação diferente né Isso vai trazer uma distorção em perspectiva que precisa ser de alguma forma levada em consideração pelo mod mod delo tá Ah e outra ideia aqui oi ah sim eh só contribuindo Ah no serp a gente tem uma solução tá até ali naquele eh naquele link que se chama vcit vcit validador cognitivo de infrações de trânsito que ele faz exatamente isso que foi colocado nesse exemplo ah dado aqueles radares que tem nos diversos Detrans espalhados aí pelo pelo país Ah ele reconhece a a placa Mas além disso ele pega e e e Conce também o o automóvel o modelo marca do do automóvel e faz um batimento isso aí já invalida né diversas infrações de de trânsito isso é o cidadão não vai precisar recorrer dado que existe essa divergência então é uma solução já ah em produção sendo utilizada aí pelos etrans da vida Muito bom legal legal né tá aqui tá aqui o link o colega eh compartilhou Depois o pessoal pode dar uma olhada também ã muito bom eh e um outro problema também associado a isso né é o que o pessoal chama de identificação de textos in the wild né então in the wild porque eu não tenho nenhuma restrição sobre eu não tenho nenhum Prior né de onde esse meu texto pode aparecer tá eu quero pegar uma foto tirar uma foto e identificar todos os textos que eu puder naquela foto tá então eu posso ter um texto como exemplo aqui mostra né posso ter um texto eh

- *Corpus ID:* 7802
- *Score:* 0.8515450358390808
- *URL:* oculto
- *Início:* 00:36:15
- *Fim:* 00:38:29
- *Transcrição:* problema é eu quero determinar se isso é um carro ou não deve ser fácil Se eu quiser determinar Onde tá o carro Isso deve ser fácil mas se lá pelas tantas eu quero fazer um ocr da minha placa do carro puts Aí complicou né complicou por quê Porque aqui eu tenho uma vista um pouco mais frontal do carro que me permitiria enxergar a placa vamos assumir né que eu tenho um zoom ok aqui né Eh então permitiria eu enxergar a placa essa vista também é um pouco mais frontal comparado com as outras duas mas eu já tenho uma distorção de perspectiva bem grande né então eu já tenho um problema maior aqui eu teria que basicamente chutar a placa né e aqui eu não tenho nem como chutar a placa tá então eh que eu quero dizer com essas quatro imagens aqui é que dependendo da tarefa que a gente tem né A forma como a minha né o ângulo com a com o qual a minha câmera tá em relação à Cena ou objeto ele impacta bastante né no no algoritmo né no desempenho do algoritmo tá E aí por fim né o problema de escala né o problema de escala ele já aparece um pouquinho aqui então talvez na imagem do carro se eu quisesse detectar a placa por mais que ele estivesse frontal Eu não conseguiria né mas aqui tá um pouco mais gritante né quando eu penso para vocês quando eu peço para vocês pensem no avião talvez vocês até pensem num num avião assim porque essa dependendo de onde vocês moram é é a nossa imagem de avião mais mais tradicional mais corriqueira né mas a gente consegue claramente imaginar um avião de perto e né e e talvez aquela seja a nossa imagem padrão tá a questão é será que o meu algoritmo ele deveria determinar que isso é um avião tá o avião Até aparece lá pequenininho né mas ele não é o Né o avião propriamente dito não é o traço marcante de avião nessa imagem né provavelmente a gente sabe que isso aqui

- *Corpus ID:* 1198
- *Score:* 0.8508902192115784
- *URL:* oculto
- *Início:* 00:41:10
- *Fim:* 00:43:17
- *Transcrição:* recurso que está sendo feito e um problema dois seria quais as variáveis que explicam essa aceitação ou rejeição do recurso a partir daí Isso aí foi o slide que a gente aproveitou na internet tá a gente identificou dois problemas de mineração né um seria uma atividade preditiva Ou seja a gente treinar algum algoritmo treinar algum classificador para prevendo que isso que aquele determinado contribuinte Vai haver a aceitação a catação pelo pelo órgão competente né que o carro dessa desse despacho que foi feito desses recursos dele a gente já classifica previamente e diz olha não vamos emitir o despacho não vamos gastar todo o processo Porque isso vai ser aceitado pelo CAF e outro problema seria simplesmente associar o que é que está fazendo o que é que está causando essa aceitação ou rejeição através de regras de associação tá o que é que a gente encontrou disponibilizar de onde a gente usou o datle house da receita a gente tem uma um acesso lá mesmo que restrita um ambiente de desenvolvimento então nós é todo mundo trabalha no CEP sabe a dificuldade que é de conseguir dados autorizados né homologados para receita para gente fazer esse tipo de de análise Então os dados não são sensíveis ou seja não a gente não sabe qual é o CPF ou CNPJ não sabe o endereço ou não tem nenhuma característica que permite identificar ou individualizar ou contribuinte a extração da fonte foi lá dentro da televisão da Receita e os atributos foram esses Unidade da Federação o tempo de documento tipo de crédito se é IPI se é cofins se é pinsche a natureza jurídica do contribuinte se ele é um contribuinte individual seria uma empresa pouca cooperativa bom E aí vai a atividade econômica situação cadastral receita bruta data do despacho data do julgamento o senhor não o valor

- *Corpus ID:* 8645
- *Score:* 0.8499636054039001
- *URL:* oculto
- *Início:* 00:40:38
- *Fim:* 00:42:56
- *Transcrição:* perguntando o quanto aqueles erros não estão arrastados lá dentro porque vocês fizeram uma inspeção nos nos zeros e isso pode ter ocorrido para outros casos né de ter teses ali em português que Como Tu disseste o objetivo era traduzido em inglês para pro português ou aqueles casos do espanhol então talvez tu ten essas ocorrências ou seja acho que tu botaste no trabalho futuro não sei fazer uma limpeza ali uma investigação dessa base porque esse esse erro pode tá acontecendo né E aí tu tá com um valor de repente ele tá desempenhando bem ou separar um conjunto bem confiável sabe e Verê assim que não que atingiu alta pontuação mas talvez pensando para trabalhos futuros sabe porque eu acho que realmente isso aí poluiu o dataset pode est com vários problemas que não gerou zero Mas que que vai baixar aquela pontuação né sim sim é possível eh só eh a gente tem muita informação que pode colocar aqui claro né mas a restrição de tempo nos atormenta um pouco né Eh então assim sobre o Mistral bem rapidamente a ti curiosidade caso alguns dos colegas se interesse né Ele é um modelo feito com licença da par eh ele tem ele foi treinado a especialidade dele é gerar código porém ele teve performances muito boas em outras outros domínios também Existem algumas variações desse modelo para chat para instruct eh enfim esse modelo tá bem Popular mesmo porque ele é um modelo eficiente e capaz de rodar no infraestrutura no no no no infraestrutura de de casa assim praticamente que foi o caso a gente rodou aqui no meu notebook por exemplo eh e a gente eu encontrei alguns trabalhos que criticam o uso do Blur inclusive para essa tarefa atualmente porque a llm ela faz eu eu aí aí é uma off the record digamos assim né algumas tradições que de qualidade eh baixa digamos assim elas apenas não obedeceram digamos assim palavra a palavra sentença a sentença mas no

- *Corpus ID:* 8684
- *Score:* 0.8499414920806885
- *URL:* oculto
- *Início:* 01:52:49
- *Fim:* 01:54:47
- *Transcrição:* ele vem a um custo de processamento muito alto e a gente a gente começou a perceber nessa fase da da da nossa histria das nossas etapas aí da da modelagem que isso não ia ser uma coisa legal pra gente poder explorar um pouco mais aí as outras etapas então a gente acabou utilizando ROM resarch validation porque ele trabalha com um um Range menor de variação desses IP parâmetros ele não pega provavelmente né o melhor como Grid search mas ele ele busca o também os melhores parâmetros então Eh Ele trabalha com um conjunto eh de dados Eh vamos dizer assim mais embaralhado mas ao mesmo tempo não rende menor de parâmetros mas é o que a gente conseguiu utilizar para atender em tempo hábil aí pro nosso trabalho tá el Desc comportou até razoavelmente bem para tanto treino né Eh então Eh além da dessa desse tipo de Grid Search aí um pouco diferente a gente acabou também eh iterando como eu falei acima eh todos os tipos de textos que eh se comportariam melhor ou não para cada um desses modelos então a gente ainda fez uma interação para esses textos ou seja o o na base vai se comportar melhor com o texto só com a re mantendo os Stop WS ou só com Rex removendo os Stop WS ou com reex com eh o stem ou lemmatization né então nós fizemos essa interação o que realmente levou um um tempo bem maior do que o o normal né Eh em todas essas essas interações aí essa exploração de de melhores e parâmetros né Eh e melhores tipos de textos pré-processados a gente eh fez a extração aí né para armazenar as métricas eh de acurácia precisão Recall e F1 n isso aí pra gente usar no no no no futuro nós utilizamos no na nas nas etapas finais de avaliação e comparação dos modelos tá Ah daí agora vem os os modelos baseados em de learning que a gente escolheu aí o lstm eh que é um tipo aí de de rede neural recorrente né Eh assim pel pela o que pesquisamos ele se aplicaria bem a nossa tarefa aí de

- *Corpus ID:* 3181
- *Score:* 0.8499182462692261
- *URL:* oculto
- *Início:* 00:44:11
- *Fim:* 00:46:26
- *Transcrição:* E aí Digamos que essa limitação né do outro ver que talvez a rede neural tivesse que resolver E aí vamos passar terminar as dúvidas aqui para eu passar para Qual é a rede né que poderia tentar processar esse tipo de conjunto de dados em que cada elemento cada entrada tem o número diferente né de colunas digamos assim né Cada um vetor aqui com número diferente de elementos aqui tem dois elementos que tem dois aqui tem quatro que tem cinco vamos lá primeira dúvida Carlos depois o Denis Bom dia é só por curiosidade Essa é faz essa essa transformação de palavra para vetor é uma coisa manual né assim é um ano que chega lá e cria essas associações né ah boa notícia é que não é o método automatizado tá ele é criar isso assim é um método é meio que talvez eu não o método meio que não supervisionado porque ele tenta ele tem o primeiro né o primeiro trabalho de outro velho que foi feito para o idioma inglês então o cara pegou lá sei lá qual qual o corpo de texto não sei se era literatura o que que era E aí botou um algoritmo lá que ficava tentando bolar esses vetores aí e o gordinho aí ajustando né os vetores que representavam as palavras de forma que ficasse consistente nesse sentido de palavras ficarem próximas quando elas estão no espaço quando ela se referem a mesma coisa ou coisas parecidas e que essas contas aritméticas ficaram fizessem sentido aqui né e aí então acabou que deu deu bastante certo né Eu não sei exatamente qual é o mecanismo né mas é automático tá é um algoritmo que foi ajustando esses representações das palavras aqui obrigado é que a gente vai mais curiosidade né dá para pesquisar Deixa eu ver se eu consigo achar aqui no Google Acadêmico é onde o repositório de artigos Qual é o artigo original do outro

- *Corpus ID:* 8673
- *Score:* 0.8491215705871582
- *URL:* oculto
- *Início:* 01:32:40
- *Fim:* 01:34:58
- *Transcrição:* talvez no relatório tu dá uma dimensão disso porque essas instâncias que eu me recordo elas não são muito longas desse dataset então talvez assim só para saber assim ah são 20% das instâncias que que fura porque realmente aí é tu tem tu perdeu a Instância né só traduziu sei lá se lá tem 800 caracteres só traduziu 500 Então seria bom vocês fazer uma análise um pouquinho mais sobre isso foi eu um do dos motivos professoras que fez a gente abandonar essa estratégia sabe assim a gente ficou não vamos traduzir agora com essa ferramenta o Data Set todo aí a gente já levou já levou esse banho de água fria aí logo no começo a gente mudou inclusive outra linguagem não foi merg Inclusive a gente tentou até o espanhol a gente vamos botar para espanhol para comparar os três mas aí a gente não não teve resultado inclusive travava com a a partir de uma quantidade ele Ele parava e dizz Ó você só pode rodar agora depois de 12 horas depois de 16 horas é aí ele mandava meio que ó é como se fosse assim eu pude traduzir até aqui de graça aí a gente não não quis adquirir nenhum pacote mas enfim Valeu como pesquisa também né professora aí a gente vai aprendendo acho que vai botar você você v colocar no relatório uhum ISO isso professora no relatório tem a gente faz a o estudo sobre as sentenças então tem puxando de memória tá porque tá no relatório lá não no colab eu acho que tem comentários com mais de 500 sentenças então assim tem gente que realmente Deserta um livro no comentário é o camar a gente a gente tem de tudo ali eu tem um crítico de arte ali que quis Mostrar toda sua experiência e tem o e tem o o o o usuário que foi assistir o filme e Quis expressar com uma frase que o filme não era ruim então assim tem de tudo lá e tá não tá Tá ok ber Só acho assim se puder dar uma simplesmente fazer uma conta lá e colocar que olha essa foi abandonada a estratégia Porque tantos por cento a estouram esse


**Resposta gerada pelo LLM**: Ao tentar automatizar a análise de recursos de multas, um projeto de OCR em manuscritos falhou devido à baixa acurácia do reconhecimento, gerando alta complexidade.  A complexidade de reconhecer manuscritos se mostrou um problema difícil, comparável à dificuldade de ler receituários médicos. Soluções baseadas em machine learning são mais adequadas, mas na época do projeto (há cerca de 4 anos), a tecnologia não era suficiente.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT, addressing both the challenges faced in automating the analysis of fines and the inadequacy of OCR technology for handwritten text. Supporting Evidence: The RESPONSE directly addresses the challenges encountered in automating the analysis of fines by mentioning the failure of the OCR project due to low accuracy and high complexity. It also provides a relevant comparison to the difficulty of reading handwritten prescriptions, which supports the claim about the inadequacy of OCR for handwritten text. Furthermore, it discusses the evolution of technology and suggests that machine learning solutions could be more suitable, which ties back to the inadequacy of OCR. Overall, the RESPONSE comprehensively covers both aspects of the PROMPT.  Score: 3


---
