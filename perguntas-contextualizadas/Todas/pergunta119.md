**Pergunta 119**: Quais são os principais pontos que devem ser considerados ao desenvolver um modelo de aprendizado de máquina, e como essas decisões influenciam a metodologia utilizada? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2314
- *Score:* 0.8646547794342041
- *URL:* oculto
- *Início:* 00:00:04
- *Fim:* 00:02:18
- *Transcrição:* ok pessoal então bom dia a todos vamos dar início então a essa semana dessa disciplina de metodologia de aprendizados supervisionado onde a gente vai começar a falar sobre o processamento de dados tá então na semana passada a gente falou sobre a parte de avaliação de modelos Claro que não é um assunto encerrado né conforme vocês tenham dúvidas a gente a gente pode discutindo a gente pode detalhar algumas coisas a mais em momentos de aula pelo fórum e é uma coisa que vocês vão usar ao longo da disciplina tá E de outras questão de avaliação de modelos certo só que a disciplina ela também tem uma ideia de discutir a parte para processamento de dados né então hoje a gente vai fazer uma introdução a esse tema e a gente vai falar sobre diferentes tarefas envolvidas nessa parte de limpeza e transformação de dados tá então a primeira etapa para processamento comentando assim alguns problemas comuns algumas soluções comuns tá é difícil né já adiantando nessa área a gente a gente dá uma receita de bolo né dizer Olha dessa situação esse tipo de solução melhor nessa situação esse tipo de solução é melhor eu tento trazer dicas para vocês Tá mas digamos assim nada que a gente pode afirmar que uma solução ou outra é a melhor a gente vai precisar realmente dependendo dos dados do contexto fazer essa essa avaliação Tá bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou

- *Corpus ID:* 2315
- *Score:* 0.8624780178070068
- *URL:* oculto
- *Início:* 00:01:45
- *Fim:* 00:03:41
- *Transcrição:* bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou quase tudo eu diria quase tudo a gente também tem que fazer o conjunto de teste tá então as etapas que a gente vai discutir hoje de limpeza do conjunto de Treinamento praticamente todas a gente tem que replicar no conjunto de teste tá tem outras conforme a gente for avançando eu vou comentando com vocês o que que a gente não faz no conjunto de teste porque tem algumas questões que a gente realmente não é adequado a gente fazendo o conjunto de teste bom E aí lembrando também que a gente falou na nossa aula introdutória que quando a gente está falando de desenvolvimento de modelos de aprendizado de máquina está falando de uma metodologia envolvida né e diversos Passos Então as nossas decisões a respeito dessa metodologia é o que é decisões a respeito de cada passo é o que define a nossa metodologia do ponto de vista de pré-processamento a gente tem tanta parte de decisões da coleta e preparo dos dados Então quais são os atributos como é que vou transformar esse atributos como é que eu vou particionar os dados para desenvolver o modelo né treinar validar otimizar e preparamos como é que eu vou lidar com valores faltantes enfim tá E também a parte de engenharia de atributos Então a gente vai estar discutindo um pouquinho essas etapas iniciais esse processo de preparar os dados

- *Corpus ID:* 2112
- *Score:* 0.8623079061508179
- *URL:* oculto
- *Início:* 00:11:10
- *Fim:* 00:13:08
- *Transcrição:* Claro que tem outros aspectos podem ser importantes como a gente vai discutindo o seguinte a interpretabilidade por exemplo mas não adianta nada o modelo que só funciona bem nos dados que eu usei para desenvolver o modelo eu preciso de um modelo que saia bem dados que ele nunca viu e essa ideia essa ideia da generalização tá generalizar é isso ele é aprender além daquilo que ele viu em tempo de treinamento eu consigo aprender a partir daquilo e aplicar esse conhecimento a novos exemplos a novas situações a novas instâncias ok bom e tem uma coisa muito importante aqui eu compilei alguns exemplos tá que foram vistos ao longo da ao longo da disciplina a gente foi vendo né notebooks E aí explorando um pouquinho o efeito na fronteira de decisão de algumas questões como hiper parâmetros dos algoritmos né especificamente Mas tem uma coisa muito importante para vocês lembrarem tá esses da esses algoritmos esse viés indutivo que é a forma que ele representa o modelo né o seu modelo a forma que ele encontra esse modelo né a sua estratégia para partir do nada e chegarem um modelo isso é o viés indutivo do algoritmos e esses algoritmos que a gente viu eles todos têm viés e educativos Diferentes né Então essa questão do aprendizado de como ele ele gera os hipótese é diferente então isso faz com que os modelos encontrados a partir de diferentes algoritmos também seja diferente na maioria das vezes não quer dizer que o diferente vai fazer com que eles tenham predições distintas para todas as instâncias né não quer isso quando digo o modelo diferente não quer dizer que um vai dizer que é a outra é b e o outro diz que é bem outro e aí e aqueles que é algo que eles estão discordando não quer dizer não é nesse sentido

- *Corpus ID:* 1320
- *Score:* 0.8618817329406738
- *URL:* oculto
- *Início:* 00:00:03
- *Fim:* 00:02:02
- *Transcrição:* ei pessoal então desculpa aí vamos Vamos recomeçar aqui então a gente falou né bastante até agora sobre a questão do QI onde é que se encaixa pintado de máquina O que é aprendizado de máquina né do ponto de vista de capacidade de aprendizado ali dentro da em relação uma e a mais clássica né e a simbólica a questão do uso de aprendizado de máquina como uma ferramenta eu vou chamar assim né importante para a parte de ciência de dados agora vou falar um pouquinho mais entrar um pouquinho mais a parte de aprendizado de máquina para a gente entender assim um pouco melhor o que que é o aprendizado de máquina né como uma como uma área do conhecimento e depois a gente vai falar um pouquinho sobre a questão das tarefas principais ele classificação e regressão tá disciplina em si muitas outras coisas que eu vou falar para vocês hoje a gente vai repetir elas ao longo do curso tá então Não se preocupem é claro tirei em dúvidas né a vontade mas não se preocupem se algumas coisas ficarem Claras porque elas vão a gente vai discutindo nessa medida que a gente for estudando os algoritmos especificamente Tá mas eu gosto de contextualizar essa parte mais geral antes da gente falar de questões específicas tá que seria os algoritmos então quando a gente está falando de aprendizado de máquina então a gente quer aprender a partir dos dados né fazer com que os métodos programas sejam capazes de aprender a partir dos dados ao invés de serem explicitamente programados para resolver uma tarefa tá então de aprendizado de máquina está falando de um processo de indução de hipótese a partir da experiência passada essa experiência passada elas são os dados né e a gente normalmente trabalha mas tem um conjunto de dados representativos são os nossos exemplos ali nossas instâncias

- *Corpus ID:* 1438
- *Score:* 0.8610107898712158
- *URL:* oculto
- *Início:* 00:06:22
- *Fim:* 00:08:26
- *Transcrição:* Qual é o melhor modelo tá então por isso que eu preciso ser capaz de avaliar o desempenho desses modelos só tomar uma água aqui então assim ó essa etapa de validação e seleção de modelos é o que a gente chama né a validação como eu comentei antes etapa de avaliação e selecionar o modelo da determinado todos os modelos que eu treinei com as suas variações de algoritmos de prepararmos Esse é o melhor modelo tá essa é uma etapa extremamente crítica quando eu tô desenvolvendo um modelo tá e a gente vai iniciar nesse assunto de como fazer isso usando uma estratégia como eu falei uma estratégia simples que é o rolda alto mas ela ainda é muito utilizada em alguns alguns casos principalmente o aprendizado profundo que o custo de desenvolver treinar múltiplos modelos é mais alto então ela ainda é utilizada Tá mas depois a gente vai discutir formas de fazer isso com um pouco mais de robustez assim principalmente em relação a variação de desempenho enfim tá mas ela é uma etapa crítica seja se eu não fizer isso bem se não fizer isso usando dados Independentes avaliando bem o desempenho dos meus modelos né as medidas de desempenho certo eu posso estar seleciodo o modelo que não é o melhor então quando a gente está falando de poder generalização eu quero saber isso né como é que o meu modelo se citai né para fazer previsões né o determinar a saída para dados que ele nunca viu tá então a gente tem Normalmente quando a gente faz esse tipo de tarefa a gente tem um conjunto de dados Então olha aqui tá esse conjunto de dados aqui eu gostaria que você treinasse que um classificador vai determinar se um aluno de uma universidade vai desistir ou não do curso tá então amor tem uma base histórica né de alunos forma matriculados de desistências enfim eu quero ser capaz de prever isso para agir

- *Corpus ID:* 2162
- *Score:* 0.8602522611618042
- *URL:* oculto
- *Início:* 00:00:06
- *Fim:* 00:02:01
- *Transcrição:* Então tá pessoal Bom dia nem Bom dia a todos vamos dar início hoje a disciplina quarta disciplina do curso né a última desse módulo primeiro módulo que seria a metodologia de aprendizados previsionado tá vocês vão ver que muitas das coisas que a gente discutiu um pouquinho vou compartilhar minha tela aqui na disciplina de aprendizado supervisionado Muitas das coisas que a gente discutiu né que a gente tocou em alguns pontos elas vão surgir quem mais detalhes tá e muitos as coisas que a gente vai falar aqui vão ser úteis para outras disciplinas que vocês vão discutir por exemplo aprendizado não supervisionado né ela também demanda para processamento de dados aprendizado profundo redes neurais também demanda alguns para processamentos né E até a parte da metodologia de desenvolvimento do modelo no sentido de validação dos modelos é um dos pontos que a gente que é bem importante e vai ser um dos pontos iniciais da nossa discussão né até aproveitando para consolidar assim um pouco esse conhecimento que vocês têm praticado no projeto da disciplina anterior né E então acho que vai ser vai ser interessante porque na disputa anterior a gente tocou nesse assuntos repetido em alguns exemplos Mas a gente não chegou a aprofundar tanto isso tá então a ideia da aula de hoje é a gente primeiro introduzir um pouco o que que essa metodologia de aprendizados introduzir disciplina né a gente tá fazendo uma mudança de contexto como a gente comentou aqui a gente tá agora falando de uma outra disciplina né embora mesmo professora então vou fazer uma apresentação da disciplina introdução ao tema E aí depois a gente vai falar sobre a primeira parte de avaliação de modelos preditivos que são estratégias de

- *Corpus ID:* 2177
- *Score:* 0.8600249290466309
- *URL:* oculto
- *Início:* 00:23:02
- *Fim:* 00:25:13
- *Transcrição:* treinamento do modelo né mas da parte já é essa divisão dos dados dados Independentes treinamento a validação enfim se eu fizer isso de forma Impecável se os meus dados forem muito ruins essa modelagem Impecável do ponto de vista de metodologia ela não salva esses dados ela dificilmente salva esses dados certo então a gente tem que cuidar a gente tem que entender o que que a gente precisa trabalhar em nível de dado né para que a gente possa tentar melhorar esse esse dado aqui que não é não é bom mas a gente também tem que cuidar para que a nossa metodologia do ponto de Treinamento não insira viésis não faço uma avaliação ruim né do ponto de vista de não perceber que tem um overfite tem coisas desse tipo ok e tem a questão da metodologia né do ponto de vista de risco de vieses e esse ponto apareceu um pouquinho naquele notebook que a gente fez né do nave base com dados de risco de doenças cardíacas em que tinha pessoas de diferentes Ali era variável raça né quantificada então e aí chamava atenção o caso ali que por exemplo nós tínhamos não tínhamos asiáticos com registro para doença né cardíaca e a gente discutiu um pouco isso pode ser uma questão de amostra de dados né um viés de amostra enfim a questão é que quando a gente não não Cuida dessa questão metodológica do desenvolvimento dos modelos e nesse ponto tá incluso né A questão da gente avaliar os dados perceber se a gente tem potenciais vieses enfim a gente acaba criando modelos com viés Então o que a gente tem que ver é que o nosso modelo ele não pode se cumprir com o nosso objetivo da tarefa de aprendizado de máquina né claro que a gente quer fazer isso aí mas isso não é a única questão a gente tem que garantir que ele não tenha implicações sociais

- *Corpus ID:* 2614
- *Score:* 0.8598393797874451
- *URL:* oculto
- *Início:* 00:00:03
- *Fim:* 00:02:07
- *Transcrição:* só confirmando aqui tá então tá pessoal bom dia um dia hoje o assunto que a gente tem para discutir ele é o último assunto da nossa da nossa súmula e ele é um assunto bem interessante Porque se vocês têm acompanhado assim discussões na área de aprendizado de máquina vocês vão ver cada vez se fala mais a necessidade da gente ter uma forma de interpretar ou explicar esses modelos preditivos tá em aprendizado de máquina então a aula de hoje ela visa na verdade o seguinte né A primeira objetiva é que vocês comecem a pensar nesses detalhes Na necessidade dessa interpretação tá então vai ter uma parte Inicial que é um pouco conceitual e algumas questões pouco filosóficas para a gente discutir né E aí a segunda parte ainda dessa parte teórica mas é a gente falar de alguns métodos concretos que a gente pode usar né com essa intenção de interpretar os modelos tá e tem um livro que eu coloquei um livro gratuito online então eu coloquei o coloquei o PDF no Moodle é um livro excelente para quem tem interesse né em estudar mais sobre essa questão de terpretabilidade Tá e aí o que quando a gente está falando de interpretabilidade basicamente o que a gente quer evitar esse tipo de situação tá isso aqui é uma Charger inclusive desse livro que eu comentei que basicamente né como se tivesse um modelo um computador rodando o modelo preditivo né regressão E aí o usuário que diz bom mas por que que você retornou essa produção de 42 para esse data Point ou seja para essa entrada e aí aquele silêncio estranho né ou seja nada nada é dito nada explicado a respeito dessa saída tá então isso aqui basicamente É um cenário que por muito tempo muitos os modelos essa era a situação ninguém conseguia entender porque era uma série porque era aquela saída para aquela entrada e agora cada vez mais se tem uma consciência de que em muitos domínios é extremamente

- *Corpus ID:* 1504
- *Score:* 0.8596537113189697
- *URL:* oculto
- *Início:* 01:55:02
- *Fim:* 01:57:08
- *Transcrição:* com aprendizado de máquina e a gente olhar para os dados olhar para os dados e encontrar questões ali nos dados que eventualmente vamos chamar atenção né Por exemplo se a gente olhar para os atributos e a distribuição deles por classe ali a gente consegue já perceber alguns atributos que tem um valor muito diferente entre as classes Então são atributos que Possivelmente são relevantes para aquele problema né então são essas questões a mais para acostumando vocês olharem e analisarem assim criticamente esse tipo de dado tá professora sem querer pressionar ou aperrear pela correção assim mais a gente consegue ter um feedback assim do primeiro mais ou menos quando é porque eu percebi que o segundo temas perguntas que envolve o primeiro é tipo assim eu fiz uma percepção errada muito errada de dados eu vou continuar errando né daqui para frente né sim é assim ó eu não vou conseguir garantir né infelizmente da gente ter resposta no primeiro antes do entrega desse segundo tá então essas essas novas monitoras elas começaram a trabalhar no curso essa semana então agora por exemplo todo esse material que está sendo entregue né a entrega desse do um tá até domingo né se eu não me engano era é eu pedi que você estivesse até hoje né idealmente Mas eu deixei no mundo até domingo Então me diga que eu ver por exemplo tá é então é bom eu não vou mudar isso agora mas fechando a tarefa eu vou passar para elas tá então realmente essa primeira eu não vou conseguir que elas entreguem para vocês antes a entrega do segundo Tá mas a ideia é que a gente possa não demorar muito nesse feedback foi uma coisa que eu conversei com ela sobre isso também né Para a gente tentar se para organizar para que o mais rápido possível tem o feedback e usem esse feedback para melhorar nos próximos exercícios

- *Corpus ID:* 1705
- *Score:* 0.8581076264381409
- *URL:* oculto
- *Início:* 00:18:08
- *Fim:* 00:20:14
- *Transcrição:* tendo essas essas Como é que vão ser essas orientações em relação que é mais recomendado é muito em função do que se observa experimentalmente tá E aí é só isso é importante que vocês tenham em mente porque quando a gente tem essas diferenças de escala como no fim das contas o que o algoritmo tá fazendo também tem relação com aquela ideia de distância entre entre instâncias porque eu tô vendo os vetores de suporte esses vetores suportes são vetores de atributos de entrada eu quero vetores que estejam os mais próximos entre si né classes diferentes mais próximos entre si eu quero calcular uma fronteira de decisão que seja aqui distante esses pontos Então sempre que eu tô falando de distância escalas diferentes de dados impactam muito tá então é para o SPM a ideia de dados normalizados E aí esse exemplo aqui que eu tirei da referência do livro mostra claramente a diferença né se eu tenho dados que não estão padronizados tá então aqui eu tenho os vetores de suporte e dados que estão padronizados a gente percebe que mesmo mesmo que eu tenha uma boa separabilidade aqui entre esses exemplos tá que eu tenho uma classe quadrada classe círculo a gente percebe que ainda assim o fato de eu não ter usados padronizados gera uma fronteira de decisão que não é interessante nesse caso né porque ela é muito envezada por essa diferença de escala que tá falando de 0 a 80 que de 0 a 6 E aí percebam como que fica essa fronteira com a simples transformação com base nesse nessa estratégia de padronização tá então enfim poderia usar o Max também a gente nesse momento dessa disciplina a gente também não vai discutir tão a fundo todos essas possibilidades para processamento Mas a questão é vocês garantirem que as escalas aqui são comparáveis tá então uma das formas é usar o Max que transforma entre zero e um ou esse de padronização que calcula


**Resposta gerada pelo LLM**: Ao desenvolver um modelo de aprendizado de máquina, é crucial considerar a preparação dos dados (limpeza e transformação), a divisão em conjuntos de treinamento e teste (replicando as etapas de limpeza no conjunto de teste), a escolha dos atributos e sua transformação, o tratamento de valores faltantes, a engenharia de atributos, a avaliação do desempenho do modelo com dados independentes para garantir a generalização, e a interpretabilidade do modelo.  As decisões em cada etapa definem a metodologia de pré-processamento, influenciando a capacidade do modelo de generalizar e evitar vieses.  É importante também considerar o viés indutivo dos algoritmos e o risco de vieses nos dados e na metodologia, para evitar implicações sociais negativas.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should address the main points to consider when developing a machine learning model and how these decisions influence the methodology used. Supporting Evidence: The RESPONSE effectively identifies several key points relevant to developing a machine learning model, such as data preparation, splitting datasets, attribute selection, handling missing values, feature engineering, model performance evaluation, and interpretability. It also discusses how these decisions impact the methodology, particularly in terms of generalization and bias. This comprehensive coverage of the prompt's requirements demonstrates a clear understanding of the topic.  Score: 3


---
