**Pergunta 63**: Quais são as duas fases do MapReduce?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 6033
- *Score:* 0.8458340764045715
- *URL:* oculto
- *Início:* 00:45:16
- *Fim:* 00:47:21
- *Transcrição:* do serviço data node que tá com aquele bloco levar ele até um nó onde foi alocado aquela tarefa de mapeamento eh eh bom então assim na saída do Map Então a gente tem dados efêmeros tá que eles não são feitos não são escritos no hdfs porque eles são temporários eles são intermediários né então o que que o o map faz ele registra Eh esses dados eh no disco local digamos assim né fora do hdfs né E esses dados intermediários eles vão ser lidos pelas tarefas de redução né porque é a tarefa de redução é a segunda etapa digamos assim né o mapeamento Ele simplesmente massivamente paralelo mapeamento é massivamente paralelo em função da quantidade de blocos que a gente tem é um mapeamento para cada bloco E aí o que que tem na saída vai ter tipo um checkpoint só que esse checkpoint como ele é efêmero né é a saída do mapeamento é uma coisa assim que daquela aplicação Então é assim ele salva no disco local ele não injeta no hdfs a gente não precisa de replicação eh essa ideia porque se porventura eh aquele no que tem que executou a tarefa de mapeamento tem que tem o dado da saída do mapeamento falhar se esse nó falhar não tem problema tipo assim o yarne vai se dar conta disso e vai dizer assim ó onde é que tá um bloco uma réplica daquele bloco que aquele mapeamento lá executou Aí ele diz ah tá em outro nó ele vai lá e lança de novo o mapeamento lá não tem problema então assim tipo é a ideia de tolerância Fes É nesse aspecto também então aí entra a fase de redução então a a fase de redução infelizmente ela não consegue usufruir da localidade dos dados né porque vocês Imaginem tem blocos espalhados pela máquina inteira cada bloco foi processado por um mapeamento em cada um desses nós onde esse esse mapeamento foi executado vão ter os as saídas do mapeamento aí agora a tarefa de redução ela é É como tem esse nome né de redução Então ela tem que se

- *Corpus ID:* 6034
- *Score:* 0.8437729477882385
- *URL:* oculto
- *Início:* 00:46:48
- *Fim:* 00:49:05
- *Transcrição:* nesse aspecto também então aí entra a fase de redução então a a fase de redução infelizmente ela não consegue usufruir da localidade dos dados né porque vocês Imaginem tem blocos espalhados pela máquina inteira cada bloco foi processado por um mapeamento em cada um desses nós onde esse esse mapeamento foi executado vão ter os as saídas do mapeamento aí agora a tarefa de redução ela é É como tem esse nome né de redução Então ela tem que se alimentar da saída de vários mapeamentos né então ela não consegue usufruir da localidade dos dados porque tu não vai colocar uma tarefa de redução para cada tarefa de mapeamento não faz sentido você tem que ter uma tarefa de redução para um monte de tarefas de mapeamento então Eh nesse caso daí não tem o que fazer eh os dados vão ser transferidos pela rede né ã eh e aí nesse caso eh né naquele exemplo ali de ano temperatura né como a gente eh Precisa ter eh eh uma única temperatura máxima para cada ano então vai ter uma única tarefa Luce Para para tudo né Então as saídas que foram ordenadas eh elas vão trafegar pela rede tá para serem eh levadas até a tarefa de redução que tá representado por esse retângulo azul aqui né então o que que acontece acontece que aquelas ã aquelas saídas ordenadas do mapeamento então o mapeamento gera saída que é ordenado Então isso é feito totalmente em paralelo vamos vai existir um tráfego então dessas saídas eh para o local para nó aonde acontece a tarefa de redução e ali esse merge vai ser feito de maneira ordenado Ok então por exemplo se se essa tarefa aqui em cima gerou dado de 1992 e essa última aqui gerou dados de 1990 aqui na hora de fazer o merge vai est primeiro 90 e depois 92 vai tá ordenado Pela chave ok aí o que que acontece a redução ela recebe Então esse ordenado Pela chave né a saída de vários mapeamentos faz o que tem que fazer ali que é o programador que decide né vai

- *Corpus ID:* 6019
- *Score:* 0.8354662656784058
- *URL:* oculto
- *Início:* 00:23:27
- *Fim:* 00:25:40
- *Transcrição:* responsável por acessar aquele bloco específico tá E e aí a redução a gente pode ter uma ou mais tarefas né mas em geral São menos tarefas que o mapeamento o como que essas tarefas elas são eh gerenciadas elas são gerenciadas então pelo yarne que é esse yet another other resource negotiator que basicamente ele é quem mapeia as tarefas da aplicação sobre eh eh a plataforma né considerando a localização dos blocos que a gente tá lendo de informação né então antes daí adiante acho que eu vou passar a palavra pro Antônio fazer pergunta Antônio Fagner pode falar e Bom dia Lucas bom dia só uma perguntinha o o quando você usa o Spark é o yarn que também gerencia as fases do M rú No caso quando a gente tá usando o Spark é é uma outra é um outro modelo de programação né que ele é em Memory e não necessariamente ele usa o yarn nem o map redu por baixo entendeu ele tem uma uma outra forma de funcionar em geral ele usa o yarn mas o map redu não entendeu Tipo ele ele codifica de outra forma as tarefas entendeu muito mais próximo do que o dask faz que é aquele gráfico de tarefas tá então o map redu é um é um modelo de programação mais baixo nível digamos assim entendeu só tem duas tarefas possíveis é map e redu entendeu Ok eh então assim começando pela terminologia né O que que esse trabalho map reduz vai ser um Job uma unidade de trabalho ele tem dados de entrada aí o que a gente chama de programa map reduce nada mais é do que a implementação de duas funções a função de mapeamento e a função de redução E e esse trabalho map reduo vai ter algumas informações sobre o processamento saber assim ah qu Quais são os dados de entrada esse tipo de coisa né e E aí o que que acontece quando a gente submete esse Job né ele vai ser dividido em tarefas a gente vai ter várias tarefas de mapeamento em função da quantidade de blocos que a

- *Corpus ID:* 6030
- *Score:* 0.8344637155532837
- *URL:* oculto
- *Início:* 00:40:32
- *Fim:* 00:42:43
- *Transcrição:* né aí isso aqui dá o qu Tu faz uma vez faz bem e deu entendeu tu sabe que tu vai conseguir ter o paralelismo porque tu vai ter o mecanismo do rup lá o yarn todo eh eh fazendo né com escalabilidade né porque cada tarefa de mapeamento é completamente independente das outras né é o único momento que a gente vai ter uma comunicação mesmo na hora que fazer esse shuffle aqui né então a gente consegue ter um um uma capacidade de escalabilidade muito grande né porque o mapeamento é totalmente trivialmente paralizado né Eh jancarlo era era esse teu comentário sim eu mantive levantado desculpa beleza vamos adiante então Eh então a gente já falou então dessa questão da granularidade das fatias né que o tamanho do Split no Como existe essa proximidade do Map reduce com o hdf é o tamanho do Bloco do hdfs né que pode pode variar né mas tipo hoje em dia se tu baixa lá o rup né Tá especificado 128 MB lá mas isso a gente pode mudar né então assim eh na questão do mapeamento das tarefas né Eh o iarn que é quem é responsável pelo escalonamento dessas tarefas ele vai sempre tentar Executar a tarefa próxima aos dados Então vai ter lá a o bloco ã o bloco hdfs que são que tá representado aqui por essas eh retângulos azuis aqui então o yarne sempre vai tentar evitar a comunicação e evitar o uso da rede de interconexão então ele sempre vai pegar a tarefa de mapeamento ele vai Ah esse essa tarefa de mapeamento aqui esse map redu esse Job map redu tá usando esse dado de entrada então ele vai olhar para esse dado de entrada e vai saber onde é que tá os blocos e vai pegar as tarefas de mapeamento que ele vai criar e vai jogar uma próxima né noide ente nesse cenário a aqui né na mesma máquina no mesmo nó onde tá aquele dado esse seria o ideal porque daí tu lê do disco local não tem comunicação via rede enfim totalmente paralelo com as demais né Mas se caso

- *Corpus ID:* 6073
- *Score:* 0.8344401717185974
- *URL:* oculto
- *Início:* 00:25:53
- *Fim:* 00:27:54
- *Transcrição:* duas máquinas né na C1 e na ci2 vai fazer a execução do mapeamento em paralelo e depois vai executar uma outra única tarefa de redução não sei bem qual máquina né para fazer a redução dessas tarefas para nós gerar ah gerarmos a saída né Eh tem alguém que tá com o microfone aberto aqui eu consigo mutar Então deixa eu deixa eu ver aqui acho que agora não tem mais nenhum microfone aberto ã então tá então fazendo a execução agora vou lançar acho que deu um problema aqui que que eu escutei errado aqui deixa eu ver m sim eu passei errado aqui é reducer ok a gente diz qual que é o mapper qual que é o reducer qual que é a entrada e qual que é a saída aí a gente executa daí vai aparecer um monte de coisa na tela aqui que são a a execução e agora já terminou né tipo assim na realidade volume de dados não é muito grande né então a gente consegue perceber aqui que uma série de informações estô subindo aqui de novo para mostrar que são assim é o que que tá acontecendo né durante essa execução Então vou voltar bem lá para cima que seria aqui o início então ele lê uma série de informações ele informa né uma série de coisas que ele vai em função do que que tá acontecendo Então tem um Job submitter enfim é o log de execução n ol ele consegue detectar quantas tarefas de redução tem e e assim por diante se eu consigo mostrar alguma coisa interessante para vocês aqui eu imagino que controlar né Essa verbosidade É eu imagino que deve porque isso aqui na realidade é a saída desse programa aqui que não foi que a gente fez né a gente pode eh talvez se a gente tivesse o nosso próprio programa map reduce o verboso aí a gente poderia remover todo a gente evitaria de fazer os esses prints todos aí tem que é usado para testar só né

- *Corpus ID:* 6163
- *Score:* 0.8337175846099854
- *URL:* oculto
- *Início:* 01:18:55
- *Fim:* 01:21:13
- *Transcrição:* um Executor né então aqui na hora que esse test Schedule Aqui Acontece que é onde eu vou pegar aquele estágio que é por exemplo um group byy e ele vai distribuir aquele group buy nos vários executors al eh então assim só para vocês terem uma ideia de como é que funcionam esses estágios né que são escalonados eh separadamente na minha plataforma né Então aqui tem um pequeno trecho de código certo que tá criando uma variável um mapeamento aqui de inteiro para long onde a gente parte daquele SC que é o nosso objeto que a gente viu antes criado com Spark session E aí a gente vai fazer primeiro um mapeamento depois a gente reduz por uma chave pega duas colunas aqui e soma elas depois faz um outro mapeamento depois faz count by Key Então se a gente for olhar isso do ponto de vista dos estágios né Nós vamos ter ter então um primeiro estágio que vai pegar o arquivo vai fazer o mapeamento vai reduzir reduzir pela aqui eh e isso vai criar então uma fase inicial digamos assim e depois uma segunda fase que vai ser o estágio dois que vai ser reduz pela pela chave faz o mapeamento e conta pela chave então essa quebra desse essa transformação desse código nesses est os aqui ela é feita de maneira transparente né então eh a própria api do Spark Ela já foi feita para ser quebrada em estágios né lá internamente e o que a gente vê aqui por essas Flechas são as dependências então assim esse aqui depende desse e assim por diante né e com fronteiras aqui entre duas eh dois estágios né então esse estágio um aqui que é o é o primeiro quando ele é eh escalonado para se executado lá no meu execut nos meus executors eles vão ser transformados num grafo de tarefas nota que esse grafo de tarefas ele não aparece aqui mas ele tá ali dentro certo Seria tipo assim o gru mínimo eh eh é o gráfico de tarefas tá que a gente consegue observar lá no dask mas que

- *Corpus ID:* 6020
- *Score:* 0.833507239818573
- *URL:* oculto
- *Início:* 00:25:09
- *Fim:* 00:27:12
- *Transcrição:* que a gente chama de programa map reduce nada mais é do que a implementação de duas funções a função de mapeamento e a função de redução E e esse trabalho map reduo vai ter algumas informações sobre o processamento saber assim ah qu Quais são os dados de entrada esse tipo de coisa né e E aí o que que acontece quando a gente submete esse Job né ele vai ser dividido em tarefas a gente vai ter várias tarefas de mapeamento em função da quantidade de blocos que a gente tá analisando lá no hdfs e tarefas de redução e o que que o yarn vai fazer ele vai pegar Ah eu Ok esse esse Job map redu aqui El ele vê a função de mapeamento tá que o o programador fez e o que que ele vai fazer ele vai ele vai olhar Quais são as entradas os blocos né e o yarne vai pegar aquela função de mapeamento e vai posicionar ela exatamente Aonde está o bloco assim fisicamente falando ende vai lá no disco lá na máquina no data node lá onde tem aquele bloco é lá que ele vai lançar o m de maneira que a leitura seja em paralelo que nem a gente viu na aula passada tá então se porventura acontecer algum problema com essas tarefas né o yarne tá ali monitorando isso aí ele relança automaticamente elas então é bem Ah focado nessa questão de tolerância Fes e tal até porque a gente não usa nenhum tipo de hardware dedicado aqui né tipo são máquina simples Ok ã bué então assim Eh esses esses dados de entradas se divididas em fatias split são os blocos do hdfs tá pessoal mesma coisa então assim falando sobre aidade das fatias esse assunto bem recorrente tá a gente já falou várias vezes sobre isso né desde lá do dask vocês lembram né o tamanho do Chunk né o tamanho depois da partição do dos data frames lá no desk Array né aqui também tem essa discussão e aí a discussão é a mesma tá se a gente tem fatias pequenas né a carga ela vai ser melhor balanceada porque daí tu vai ter eh mais tarefas de mapeamento eh populando os meus recursos

- *Corpus ID:* 6001
- *Score:* 0.8331558108329773
- *URL:* oculto
- *Início:* 01:41:01
- *Fim:* 01:42:55
- *Transcrição:* digamos assim né então comparando os bancos de dados relacionais com bancos de do do Map redu né ou do hdfs por trás né então Eh enquanto os bancos de dados tradicionais eles priorizam mais esse acesso iterativo né o map redus é só processamento em Bet tá em termos de atualização a gente a gente pode escrever uma única várias vezes num banco de dados tradicional né faz update e tudo mais no hdfs map reduce tu escreve uma vez tu pode até fazer concatenação e tudo mais né num banco de dados tu tem aquelas transações acid né que é as características acid atômicas consistentes isolados e duráveis né Tem tem o conceito de transação né que é absurdamente importante para inúmeros eh problemas por exemplo de transações bancárias esse tipo de coisa né numa redus isso simplesmente não existe tá então tu tem que ter outras formas de garantir isso tá então em termos de integridade alta no banco de dados escalabilidade não é linear né mas no map redu Tu tem uma uma integridade baixa né porque pode dar problema e tudo mais e tu perder as réplicas né E talvez tu não consiga reconstruir tudo e aí tu perde a informação né então tem que ter um cuidado bastante grande nesse aspecto mas a escalabilidade é linear né então tipo se tu tem a falta de falta de tem problemas de escalabilidade é muito melhor usar o map redus só só comprar mais máquina e concatená-las né então fica fácil fazer upgrade em um cluster map redu só tu comprar mais máquina coloca o sistema roda data noes disde que aqueles data noes existem e deu né então é bem fácil estender o a plataforma e as máquinas não precisam ser necessariamente idênticas né o pessoal que botou no chat aqui né que todas as máquinas tem aquelas carterísticas mas bom se for comprar mais máquina hoje provavelmente a CPU

- *Corpus ID:* 6049
- *Score:* 0.8327374458312988
- *URL:* oculto
- *Início:* 01:10:58
- *Fim:* 01:13:07
- *Transcrição:* o acontece a contêiners avançados na inicialização E aí depois dependendo da quantidade de fases da da da tarefa de redução tem a fase de redução também alguns contêiner S E aí quando is quando essa tarefa esse Job termina aí o o todos esses contêiners são liberados né então um comportamento um pouco diferente do do uso do Spark né Então depende bastante da da da aplicação que tá rodando l sim tem várias categorias então Eh tempo de vida das aplicações podem variar né Podem ser curtas e longas então se a aplicação é uma aplicação Spark em geral ela é mais longa né porque como eu falei né ela ela instancia aquela camada digamos Spark em cima do yarn né ã então assim eh uma melhor categorização pode variar em função da aplicação né então tem basicamente três categorias né Eh o map redu é uma aplicação é um Job e e e fim tá então é mais efêmero digamos assim né Porque tu executa um map reduce tu tem esse Job e terminou embora tu possas fazer né a algumas aplicações que são map redu serem uma sequência de Map reduces né de maneira que o mapeamento usa a redução do Job anterior e aí tu cria tudo isso como V um único Job ã no Spark a gente tem uma aplicação que vira um workflow com múltiplos Jobs então é como se a gente criar uma camada mesmo mais alta né tem que reusa os contêiners que são gerenciados pelos node managers e eh a última categoria são aquelas aplicações de longa duração né Eh que são aquelas que estão sempre ligadas né então Eh que lidam por exemplo com fluxos de streams de dados né elas ficam sempre ligadas sempre funciodo então sempre tem contêiners já alocados ali nos meus node managers e aqueles contes ficam forever ali né tipo assim a gente não desliga eles muito bom para construir aplicações em arn que é raramente feito tá mas basicamente se tu for diretamente programar em yarn né que é uma coisa rara de vamos fazer

- *Corpus ID:* 6027
- *Score:* 0.8318536281585693
- *URL:* oculto
- *Início:* 00:35:59
- *Fim:* 00:38:02
- *Transcrição:* dúvida a transformação ela não poderia ser direta Isto é desse primeiro passo já para aquele para aquele outro lá onde tem as chaves do ano me parece que a gente tem todos os elementos Então qual por desse passo intermediário Qual é o passo intermediário tu fala desse desse aqui de gerar 0 140 280 esse do meio Ah tu diz esse aqui do meio entendi exatamente eu eu não poderia vir lá de cima aqui direto para baixo isso de fato acontece isso de fato acontece tu tem toda a razão é o que acontece nessa figura aqui ó tá vendo tu parte eh no mapeamento a entrada do mapeamento já é o dado é o dado bruto entendeu E essa questão do endereçamento aqui feito por linha tá essas duplas aqui isso aqui é uma coisa que o usuário acaba nem vendo entendeu Tipo isso aqui seria só assim tipo qual que é a ideia entendeu que o mapeamento recebe recebe pares chave valor e gera pares chave valor entendeu então quando tu fornece o dado pro mapeamento tu fornece o dado bruto esse aqui que tá em amarelo aqui no na figura tá vendo e essa essa fase de criar essas pares chave valor o usuário ele não precisa nem ver isso entendeu Mas ele tem que ter consciência que quando ele recebe o mapeamento ele tá recebendo linha por linha entendeu É isso que ele recebe linha por linha os dados entende então tá legal isso aqui seria mais uma são assim para mostrar assim que o mapeamento recebe par chave e valor mas na entrada dele é o dado bruto né ainda é o dado que a gente tá analisando entendeu então ok é um par chave valor assim mas tipo dá para dizer que é o dado bruto entendeu Hã Então acho que era isso então a gente já fez essa discussão aqui da das fatias né o tamanho ideal de novo né tipo assim é difícil antecipar né depende da quantidade de memória esse tipo de coisa acho que tem mais uma pergunta pode falar Marcelo Godói ô Lucas Surgiu uma dúvida aqui


**Resposta gerada pelo LLM**: As duas fases do MapReduce são mapeamento e redução.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should accurately identify the two phases of MapReduce. Supporting Evidence: The RESPONSE correctly identifies the two phases of MapReduce as "mapeamento" (mapping) and "redução" (reduction). This directly answers the PROMPT, providing complete and relevant information.  Score: 3


---
