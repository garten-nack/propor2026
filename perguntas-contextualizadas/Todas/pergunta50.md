**Pergunta 50**: Como a computação paralela evoluiu do uso de múltiplos computadores interconectados para a presença de múltiplos núcleos de processamento em dispositivos como smartphones? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 5443
- *Score:* 0.8797586560249329
- *URL:* oculto
- *Início:* 01:00:11
- *Fim:* 01:02:07
- *Transcrição:* então e a programação paralela é uma coisa que existe bastante tempo né então só que antigamente era bem mais difícil de fazer hoje em dia ela se tornou eh digamos assim ela permeia meio que tudo né desde o celular que tá no bolso da gente até o cluster de computador com um monte de nó né então H lá antigamente existiam né as máquinas sequenciais aquelas máquinas a gente tinha um único núcleo de processamento e por consequência a gente conseguia fazer só uma execução de um único passo por vez né Então as máquinas paralelas elas surgiram né isso elas já existem bastante tempo depende do tipo de máquina mas elas já existem há bastante tempo quando a gente tem esses múltiplos cores de processamento hoje em dia estes múltiplos cores Eles estão no nosso bolso né nosso celular vocês compram lá tem lá um octa core vem Oito Cores né tá no nosso bolso mas antigamente isso não tinha não era assim antigamente a gente tinha para ter esses Oito Cores a gente precisava de oito computadores totalmente eh inteiros assim né E que a gente interconecta esses computadores por rede né então a gente tinha rede uma rede de interconexão com o Switch lá conectando eles né então era muito mais complicado de programar né porque a gente tinha que programar esses vários computadores a gente foi pensar pô mas se a gente tem hoje vários cores no celular por que que eu preciso ter vários computadores eu preciso ter vários computadores porque os problemas são maiores né os problemas que a gente ataca hoje são muito grandes eles não cabem num único computador então a gente ainda assim tem hoje múltiplos cores em cada computador mas tem mú os computadores né E esse tipo de máquina então permite a execução de vários Passos por vez né a gente consegue fazer várias coisas ao mesmo tempo então exemplos de máquinas paralelas hoje em

- *Corpus ID:* 5444
- *Score:* 0.8625182509422302
- *URL:* oculto
- *Início:* 01:01:39
- *Fim:* 01:03:43
- *Transcrição:* vários computadores porque os problemas são maiores né os problemas que a gente ataca hoje são muito grandes eles não cabem num único computador então a gente ainda assim tem hoje múltiplos cores em cada computador mas tem mú os computadores né E esse tipo de máquina então permite a execução de vários Passos por vez né a gente consegue fazer várias coisas ao mesmo tempo então exemplos de máquinas paralelas hoje em dia tem inúmeras né Eu peguei o exemplo do próprio celular O celular é uma máquina paralela Mas tipo qualquer computador que vocês estão usando agora aí certamente não tem só um Core porque isso deixou de existir faz muito tempo e deixou de existir por uma boa razão na década de 90 não sei se vocês recordam mas eu lembro eu era meio criança ainda adolescente Eu lembro que e exigi uma corrida pela frequência né Vocês viam ah cada ano vinha a Intel lá vinha AMD e largava o processador com uma frequência maior né então era 400 MHz depois era 800 MHz depois 1 GHz isso funcionou por uns tempo né Acho até 2002 ali por ali 2003 ah mas o que que aconteceu aconteceu que como a frequência era muito alta essas esses processadores eles consumiam mais energia e a densidade de energia desses processadores começou a ficar tão grande que eles esquentavam demais então chegou uma que o pessoal chama de power Wall assim o muro da da potência digamos assim a partir do qual que se tu for mais longe tu derrete o processador tu não consegue aumentar a frequência mais já tinha um overclock né já podia fazer overclock ainda podiam fazer overclocking para esquentar mais isso o pessoal eu lembro PR gente a gente gostava tu ia lá na Bios né ou fazia alguma algum chaveamento lá na placa mãe e tu fazia o que o pessoal chamava de overclock que era ir além Jumps Jump o nome do da placa mãe do da chave que você mudava era o Jump ISO isso mudava

- *Corpus ID:* 5533
- *Score:* 0.8618488311767578
- *URL:* oculto
- *Início:* 00:03:19
- *Fim:* 00:05:26
- *Transcrição:* Independente de fabricante esse tipo de coisa eh qual que é a realidade atual né então eu vou rapidamente passar nesse site depois eu passo a a URL para vocês por porque isso aqui foi uma necessidade que eu senti assim nas turmas precedentes que a gente começava falando de programação Paralela em Python né e muitas vezes a gente fazia perguntas assim que na realidade São ã perguntas mais relacionadas assim a como a plataforma está organizado o hardware né digamos assim e é importante a gente saber como é que o hardware está organizado então eu decidi apresentar esse esse esse material aqui para vocês só pra gente rapidamente ver assim Quais são as as máquinas que existe que existem hoje certo então para começar a gente começa com essa máquina chamada uma que é em português seria máquinas de acesso à memória uniforme que são máquinas até um pouco mais antigas hoje em dia a gente não tem mais tanto esse tipo de máquina porque essa máquina ela tem um foco maior na memória né a memória a gente tem uma única memória e essas cpus que vocês veem aqui em volta seriam as todas essas cpus acessando uma única memória né então isso aqui era a realidade digamos assim até a década de 90 ali início da década de 2000 ali onde a gente de vez em quando tinha mais de um processador nas máquinas e esses processadores acessavam a mesma memória Então por que que é de acesso uniforme porque todos os processadores tinham o mesmo custo para acessar a memória isso aqui acabou caindo em desuso embora isso aqui ainda exista hoje tá porque quando vocês compram um computador que tem um único processador lá na placa mãe né e isso é a maior parte dos computadores é assim né temos um único processador com vários cores aquele único processador ele acessa a única memória que tem então é uma máquina de acesso uniforme mas a diferença é que só tem um processador aqui nesse caso teria quatro

- *Corpus ID:* 5538
- *Score:* 0.8613031506538391
- *URL:* oculto
- *Início:* 00:11:12
- *Fim:* 00:13:22
- *Transcrição:* vários cores né que são os vários processadores que estarão nesses nós né então a gente vai ter nós que tem vários cores com a sua memória né pode ser uma uma máquina numa também interconectadas pela rede Então isso é o o digamos assim um nó que a gente chama somente de cpus mas a gente tem também ah máquinas digamos assim que são H híbridas eh onde a gente tem em cada nó computacional a gente tem os vários cores com as suas gpus né com mais de uma GPU essas gpus Elas podem fazer parte do próprio processador né como a gente evocou na aula passada Mas podem ser também aceleradoras né ou seja placas que estão conectadas adas na na na interface PCI daqueles computadores de maneira que a gente tem que usar elas elas elas não compartilham a mesma memória né tipo assim a a placa aceleradora tem a sua memória né então a gente precisa ter um tem um nível a mais de de de memória digamos assim naquela máquina e essa é a realidade das máquinas de hoje né as máquinas de hoje assim super computadores que são focados em cálculo elas são majoritariamente misturas de CPU e GPU certo então onde onde os nós são máquinas nas Professor Oi pode falar oi bom dia professor só uma dúvida aqui para validar o entendimento Eh esses computadores que a gente tem hoje aí na mesa né desktop notebook eles estão mais para qual ali para essa arquitetura uma ou numa eu fiquei na dúvida é eu acho que assim pelo fato de que quando a placa mãe só porta somente um processador aí tu tens uma máquina uma entendeu então normalmente né os notebooks né até os computadores de mesa né É muito raro tu configurar um desses computadores com uma placa mãe que tenha dois processadores dois processadores Quando eu digo é dois chips entendeu imagina mes de ter um processador tu vai ter dois entendeu então isso normalmente é uma configuração de servidor né então

- *Corpus ID:* 5536
- *Score:* 0.8598824143409729
- *URL:* oculto
- *Início:* 00:08:08
- *Fim:* 00:10:11
- *Transcrição:* nesse Exemplo né e distribuir também as tredes de processamento de maneira que elas sejam mais Independentes né então quando a gente faz programação Paralela em um cluster normalmente a gente influencia o sistema profissional a gente diz pro sistema profissional conhecendo a nossa aplicação como é que a gente quer que ele faça né E e essa sugestão normalmente daí é obedecida né mas isso daí é um caso bem específico de programação não é Normalmente quando a gente programa numa linguagem de programação por exemplo como o Python que é interpretada então só continuando né Então tudo isso aqui esses dois casos aqui que esse segundo caso aqui da é o mais comum né e tudo isso acontece num único computador tá num único computador não tem interface de rede né a gente imagina que é um único computador tá aí existem a o que a gente chama de memória distribuída que é quando eu tem eh aquela situação anterior replicada em vários computadores e esses computadores estão interconectados por uma rede de interconexão essa rede de interconexão é aquele nosso habitual cabo Azul ali que a gente encontra né hoje em dia nem é todos os azuis né mas são esses são essas eh que tem switches de rede né Eh com endereços IPS com protocolo TCP né a gente tem num supercomputador a possibilidade de ter uma rede de interconexão ão muito mais eficiente aqui no nosso caso a gente tem por exemplo infine Band que é uma rede de interconexão de baixa latência que permite a gente fazer troca de mensagens entre as máquinas de maneira muito mais eficiente então assim essa é a situação eh de todos os clusters do mundo né todos eles são eh vários múltiplos nós interconectados pela rede de interconexão normalmente uma rede de interconexão eh mais complexa eh que tem por exemplo um nó conseguindo acessar diretamente Ã Não não somente um Switch né mas dois nós também eh diretamente né então isso

- *Corpus ID:* 5534
- *Score:* 0.8596785664558411
- *URL:* oculto
- *Início:* 00:04:54
- *Fim:* 00:07:02
- *Transcrição:* mesmo custo para acessar a memória isso aqui acabou caindo em desuso embora isso aqui ainda exista hoje tá porque quando vocês compram um computador que tem um único processador lá na placa mãe né e isso é a maior parte dos computadores é assim né temos um único processador com vários cores aquele único processador ele acessa a única memória que tem então é uma máquina de acesso uniforme mas a diferença é que só tem um processador aqui nesse caso teria quatro processadores então assim logo isso evoluiu para um tipo de máqu máqu que é a gente chama de máquina numa que são as máquinas de acesso à memória não uniforme então isso aqui é muito mais próximo da realidade hoje dos supercomputadores porque quando a gente pega os os computadores desses supercomputadores de um cluster por exemplo raramente esses nós têm um único processador Normalmente eles têm dois processadores Essa é a forma mais comum que a gente encontra e cada um desses processadores lá na placa mã tem a sua memória isso não quer dizer que um processador não consiga acessar a memória do outro ele consegue só que o custo vai ser maior então por isso que o acesso é não uniforme eu tenho uma memória entre aspas mais próxima de um processador e eu tenho uma memória um pouco mais distante e para conectar nesse exemplo aqui a gente tem quatro processadores que tem essas pequenas cpus dentro que são os cores né Quatro Cores cada um nós temos para conectá-los uma interconexão física né lá no hardware que nesse exemplo aqui é um anel certo então por exemplo esse essa CPU que tá na no canto inferior direito não consegue acessar a memória diretamente daquela processador que está no canto superior esquerdo ele precisa ter um custo dobrado né tipo assim em relação a um custo zero que seria acessar a memória local e a um custo um que seria acessar essas duas As Memórias vizinhas

- *Corpus ID:* 7032
- *Score:* 0.8582724332809448
- *URL:* oculto
- *Início:* 00:30:29
- *Fim:* 00:32:31
- *Transcrição:* quebrada em dois pedaços e aí nós temos ã eh camadas que são elas são são no mesmo nível Mas elas estão separadas eh tem tem pedaços dela como a gente pode ver aqui na figura nesse caso né a gente pode fazer o paralelismo da forma que a gente viu por último antes né E aí a gente vai ter menos comunicação né Porque aqui no início vai ter uma comunicação entre as gpus mas depois as duas gpus podem avançar ainda que sejam camadas né né Elas podem avançar de maneira independente porque a configuração dessas camadas permite isso certo então assim isso porque a gente tá usando camadas convolucionais porque tá usando entradas que podem ser de dados separados né tem toda uma série de condições para que isso aqui possa acontecer tá então fica mais fácil realmente quando tem camadas com velocidad por mais que que isso possa parecer né convolucionais são mais complexas né mas com elas fica mais fácil separar entre os devices porque a gente tem menos comunicação e ã né tipo assim o fato de ter essa realização já ajuda né a fazer op de modelo então como Tem cada vez redes orais mais complexas isso aqui começa a ter uma um interesse maior de fazer esse tipo de paraíso de modelo Ok e depois eh sobre as redes neurais recorrentes Profundas né que tem várias camadas né aqui a estratégia de colocar cada camada eh em em um device diferentes seria uma opção né porque a gente pode ter H as entradas e aí a gente tem como se fosem gerações aqui né E aí nesse caso a gente tem efetivamente um paraliso porque esse número um aqui vocês estão vendo ó Ele é processado na primeira GPU depois alimenta a segunda GPU e ao mesmo tempo que a segunda GPU tiver processando esse um a gente já tá lidando com esse dois aqui certo e a gente consegue fazer o um e o dois em paralelo vai chegar um ponto em que a gente tem eh todas as entradas

- *Corpus ID:* 5535
- *Score:* 0.8565012812614441
- *URL:* oculto
- *Início:* 00:06:31
- *Fim:* 00:08:35
- *Transcrição:* uma interconexão física né lá no hardware que nesse exemplo aqui é um anel certo então por exemplo esse essa CPU que tá na no canto inferior direito não consegue acessar a memória diretamente daquela processador que está no canto superior esquerdo ele precisa ter um custo dobrado né tipo assim em relação a um custo zero que seria acessar a memória local e a um custo um que seria acessar essas duas As Memórias vizinhas que estão na outra diagonal então isso aqui caracteriza bastante então a a As máquinas atuais tá normalmente só para né pensar assim pô mas como que eu gerencio isso tudo isso normalmente né como a gente tá em cima do sistema operacional em cima de um midware e lá em cima fazendo a nossa aplicação a gente não se preocupa com absolutamente nada eh sobre isso né porque todas as camadas de software que estão subjacent elas já gerenciam esse tipo de situação né então Sobretudo o sistema operacional então o sistema operacional ele ele consegue tipo assim na hora que lança uma aplicação dizer assim a em qual memória ele vai colocar essa aplicação e também em qual processador essa aplicação vai ser executada e normalmente o sistema operacional faz boas escolhas colocando a a as trades né da aplicação próximas dos dados Onde estão daquela aplicação isso nem sempre é o que a gente quer né porque a gente Talvez queira distribuir né os dados espalhando eles nas quatro memórias aqui nesse Exemplo né e distribuir também as tredes de processamento de maneira que elas sejam mais Independentes né então quando a gente faz programação Paralela em um cluster normalmente a gente influencia o sistema profissional a gente diz pro sistema profissional conhecendo a nossa aplicação como é que a gente quer que ele faça né E e essa sugestão normalmente daí é obedecida né mas isso daí é um caso bem específico de programação não é Normalmente quando a

- *Corpus ID:* 6245
- *Score:* 0.8556877970695496
- *URL:* oculto
- *Início:* 00:45:15
- *Fim:* 00:47:47
- *Transcrição:* trazendo para Ram a cada vez tu deixa lá oado e fica só processando na GPU bom então assim essa estío de comparação tá então ah como que tá organizado uma GPU né Eh a GPU ela tem eh o que a gente chama de stream processors que são esses SMS a gente chama de SMS em português SMS eh e aí h a gente tem aqui a arquitetura de uma delas que é a visão incompleta de uma delas tá então esse aqui é o arquitetura ada ada lovelace né 102 que equipas rtx 40 que é essa aqui por exemplo que eu mostrei para vocês aqui na caixa tá então eh se a gente olhar dentro dela a gente vai ver então que esses verdinhos aqui ó são os SMS esse aqui seria o a placa inteira tá então a gente tem eh vários SMS estão vendo aqui os SMS ó sendo que cada SM tem lá um um o seu eles são independentes entre si primeira coisa né então lá dentro essa parte verde que vocês estão vendo ali são as as unidades de cálculo mesmo então cada SM tem uma determinada quantidade de cuda cores tá e eh uma placa né um chip né Tem um monte de s Ok E aí o que que tem acontece que quando a gente vai processar a gente tem que eh distribuir o cálculo para esses vários SMS essa distribuição do cálculo ela é transparente pro programador a gente não vê esse escalonamento acontecer Ok a gente só precisa fazer a programação lá daquele aquele código que nem eu vi a gente mostrou antes depois eu vou entrar em mais detalhes então eh a quantidade de sms tem evoluído bastante né Eh ao longo do tempo aquela GeForce GTX lá que eu mostrei para vocês ela tinha somente 28 SMS isso lá em 2016 tá eh Hoje em dia a 4090 que é essa que eu mostrei para vocês ela foi lançada no ano passado ela tem 144 smms Ok sendo que aa tá organizada em 12 clusters de SMS que vocês podem ver aqui ó tem 1 2 3 4 5 6 e mais seis lá embaixo com uma Cash L2 aqui enorme no meio deles tá e Eh quantos kuda cores tem por por SM hoje em dia tem 128 ca corse então

- *Corpus ID:* 6422
- *Score:* 0.8554025292396545
- *URL:* oculto
- *Início:* 00:52:03
- *Fim:* 00:54:01
- *Transcrição:* acontecendo Tem várias coisas aqui que a gente não pode abordar tá pessoal porque realmente assim esse universo é bem grande mas por exemplo eh essas placas elas elas elas aceitam Não elas tu não precisa executar um Kernel por vez entendeu tu pode executar múltiplos kernels por vez porque é um stream processor é um é um processador de stream então tu pode por exemplo ao invés de fazer uma única invocação do teu Kernel daquela forma que a gente viu aqui ó lá em C não sei como é que isso é in numba Tá mas em C em de fazer uma única invocação tu coloca um laço de repetição em volta disso e tu faz invocação massiva de kernels Ok e a deixa a placa se virar para executar E aí tu vai conseguir ter uma ocupação melhor da placa entendeu então são situações onde se o teu Kernel não consegue ocupar bem os SMS tu consegue fazer submissão de vários k simultaneamente E aí tu consegue usar melhor a placa Ok Tem vários tipos de coisas que dá para fazer assim é realmente um universo bastante grande não é muito intuito aqui explicar para vocês todos esses detalhes mas assim eh um caminho é tu começar programando em NBA para para para cuda e depois tu migrar uma coisa em se aí usar outros outras funcionalidades que vão permitir tu acelerar mais aind Luiz Guilherme pode falar Eh mestre só uma observação mais do que um comentário uma pergunta o colega nosso ele teve uma dúvida sobre o retorno do timage em cima do do de uma de usando função Magic e eu tinha uma experiência aí depois eu pesquisei para orientar melhor então se você botar o t igual Tim e o menos o você consegue transferir pro t e ele vira um objeto que tem vários vários métodos associados que é o pior tempo a melhor tempo quantidade de Loops isso pode ser útil pra gente aqui durante o trabalho tá bom só um comentar Obrigado legal obg eu bot eu printei aqui no no chat tá só para


**Resposta gerada pelo LLM**: Antigamente, para ter processamento paralelo, eram necessários múltiplos computadores interconectados em rede.  A evolução levou à integração de múltiplos núcleos de processamento (cores) em um único chip, como se vê hoje em smartphones com processadores octa-core, por exemplo. Isso ocorreu porque, embora os problemas a serem resolvidos se tornaram maiores e exigissem mais poder computacional, a tecnologia permitiu a miniaturização e a integração de múltiplos núcleos em um único dispositivo.  A busca por maior frequência de processamento na década de 90 atingiu um limite devido ao consumo de energia e aquecimento excessivo, levando à adoção de múltiplos núcleos como solução para aumentar a performance.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: A resposta deve ser relevante para toda a pergunta sobre a evolução da computação paralela, desde o uso de múltiplos computadores até a presença de múltiplos núcleos em dispositivos modernos. Supporting Evidence: A resposta aborda a transição histórica do uso de múltiplos computadores interconectados para a integração de múltiplos núcleos em um único chip, especificamente em smartphones. Ela menciona a necessidade de maior poder computacional e como a tecnologia permitiu a miniaturização, além de discutir as limitações da frequência de processamento que levaram à adoção de múltiplos núcleos. Isso demonstra uma compreensão clara da evolução da computação paralela, cobrindo todos os aspectos solicitados no prompt.  Score: 3


---
