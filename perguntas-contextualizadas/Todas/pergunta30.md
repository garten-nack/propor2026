**Pergunta 30**: Como o Pandas lida com a performance?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 5782
- *Score:* 0.8645164966583252
- *URL:* oculto
- *Início:* 00:09:51
- *Fim:* 00:11:55
- *Transcrição:* Alto desempenho existe então uma preocupação do pandas de ser rápido né então tem muitas das coisas que não são escritas em Python Python Seria somente a casquinha digamos assim pros usuários né porque muita coisa escrita realmente em em C mesmo né uma linguagem compilada né toda aquela discussão que a gente já conversou ali e a gente vai ver na segunda parte da aula o pandas é totalmente sequencial e e realmente ele é um ele é um ele é sequencial não foi feito em nenhum momento Assim nenhum momento o pessoal pensou ah vou paralelizar ok até pode ter ali algum tipo de uso de multicore tipo de coisa mas é a grosso modo é sequencial tá então eh Por que que foi assim né Eu acho que é uma questão de simplicidade a pessoa não precisa se preocupar com a paralelização quando tá fazendo uma nova transformação de estado Tá mas o que que aconteceu com ao longo do tempo né é que isso acabou se tordo um limitante muito grande porque a pessoa queria fazer grande volume de dados né E aí tu eras obrigado a quebrar manualmente as coisas em pedaços para fazer as transformações né E aí surgiu o dask né O dask veio para resolver esse problema para nós né então a gente vai ver na segunda parte da aula assim H então assim a moral né AF de contas ass sobre essa questão paralela tá não sei se vocês estão me acompanh mas a moral é que a gente tem que aprender bem a usar o panas entendeu porque a paralelização ela já tá feita e a a única coisa que a gente precisa realmente se preocupar na paralelização vocês já tão se preocupando que é o tamanho do Pedaço do trabalho entendeu é o Chunk é a partição Ok é o grão de trabalho finalmente certo e isso daí é a única coisa certo o resto tá feito certo a gente consegue influenciar a quantidade de paralelismo se tá bem paralelo se tá pouco paralelo com o tamanho do grão do trabalho então

- *Corpus ID:* 6265
- *Score:* 0.8611758947372437
- *URL:* oculto
- *Início:* 01:18:03
- *Fim:* 01:20:03
- *Transcrição:* equipe ela nem sabe o código da aplicação entendeu Tipo assim eh não vai tá usando eficientemente a placa aceleradora ela não vai ter a menor ideia porque tipo ela nem conhece a aplicação entendeu é quem conhece a aplicação que consegue influenciar esse tipo de parametrização que a gente tá vendo nesse slide entendeu então assim o desempenho eu acredito que seja a responsabilidade do programador mesmo sabe só que nota que aqui a gente tá num nível absurdamente baixo entendeu tá assim tu tá diante de uma placa né então num cenário onde tu tá distante que nem tu mencionaste né ah tem lá uma equipe tem várias camadas várias equipes no meio do caminho e tá tuo lá programando teu workflow né então assim eh nesse caso eh é muito difícil tu ter acesso à informação útil que vai te permitir alterar alguma coisa na tua aplicação ação né então eu acho que é um caso perdido Tá mas ah é muito possível que tu esteja programando num nível de abstração que não seja este né esse aqui é bem baixo nível né Talvez tu estejas programando um nível de abstração mais alto né onde tu tem eh pela distância do Hardware eh menos poder de eh mesmo menos influência entendeu Talvez tu nem tenha que decidir essas coisas que estão aparecendo aqui nesse slide E aí nesse caso bom mas aí nesse caso talvez eh tu tu tu nem tem o que fazer entendeu Tipo desempenho tá ruim talvez nem seja te né Tu não tem que fazer porque tu é é o software que tu tá usando e é o pandas ou o dask né Aí no caso daí é essas outros eh intermediários aí né que teriam que eh ter alguma responsabilidade tem né então é bem complexo não não sei dar uma resposta definitiva assim entendeu é é porque eu penso assim quando você massifica a quantidade de pessoas né Porque hoje a gente tá a realidade hoje no s é assim a gente tá saindo de muitas pessoas que programavam pra web e tal e

- *Corpus ID:* 5884
- *Score:* 0.8591716885566711
- *URL:* oculto
- *Início:* 01:28:52
- *Fim:* 01:30:43
- *Transcrição:* pena se tá se tá bem se tem paralelismo se não tem paralelismo se precisa dividir né então assim qual que é a forma de funcionamento depois disso tá a gente vai falar mais sobre isso mais na frente eu já passo para tua pergunta tá aber só para fechar o raciocínio é que ã uma vez que a gente criou esse grafo né a gente não executou ainda tá aí a gente Talvez queira assim fazer uma execução E aí essa execução ela a gente vai usar um um dashboard que eu não mostrei para vocês ainda mas vai vir tá vai vir Fiquem tranquilos e onde a gente vai porque a gente vai refazer isso aqui depois lá na frente tá eh a gente vai olhar pra execução do grafo olhando pro dashboard E aí olhando pro dashboard a gente vai chegar a uma conclusão a gente vai olhar para esse dashboard vai ver assim ah não mas tipo os workers eles estão meio ociosos né tá processando Mas tá tendo muito GAP entre cada tarefa num worker ou tem muita comunicação e tal e aí isso vai fazer a gente voltar para cá E aí eventualmente decidir de fazer um rep adicionamento diferente tá então isso é bem experimental Mas uma vez que a gente definiu assim ah esse gráfico aqui ficou bom para essa plataforma porque a plataforma não muda todo dia também né a gente define lá um cluster a gente usa um cluster sempre para fazer nosso processamento né aquele cluster tem sempre um uma configuração relativamente estável né a gente configura daí seess a a o reparticion momento enfim em função da plataforma E aí a gente coloca em produção aquele negócio que tá bem otimizado tá até a gente pode dar para alguém cuja especialidade é otimizar o grafo entendeu melhorar alguém que conhece a plataforma que pega o workflow de vocês que vocês escreveram em pandas E aí define assim ah o tamanho do grão é bom para ess ser minha máquina essa pessoa daí ela conhece bem lá e decide com a experiência que vocês estão trazendo também então Ah era isso

- *Corpus ID:* 5561
- *Score:* 0.8537460565567017
- *URL:* oculto
- *Início:* 00:23:17
- *Fim:* 00:25:39
- *Transcrição:* então assim tu imagina que tu fores usar pandas né vamos supor que tu te ambientou pandas não pai e tu tem uma tabela que não cabe na tua memória entendeu ela não cabe na tua memória aí como é que tu vai fazer entendeu então É exatamente esse o ponto entendeu É quando a memória que tu tem no teu já que a gente tá falando de dados né É quando a memória do teu computador ela não não tem não aguenta mais o volume de dados que tu tem entendeu Esse é um dos fatores que te levam assim ah não realmente eu tenho que usar mais de um computador entendeu o Outro fator que pode ser também eh importante a seria o fato de tu ter um volume não tão grande então cabe na tua memória tá Cabe aí tu faz a carga da tabela vai toda a tabela para memória mas na hora que tu for lançar o processamento desses dados aquilo que tu programou né Ah eu quero fazer isso quero fazer um um correlacionamento com essa outra tabela essas tarefas elas custam muito tempo entendeu Tipo assim em vez tu ficaria assim tipo vamos lá sei lá 4 5 horas esperando terminar um teste que que é relativamente simples tu táa só desenvolvendo né então isso é uma coisa que pode né Eh se se tu tem pressa assim e te levar a usar o processamento paralelo a ir para um para uma máquina que seja paralela para tu acelerar aquele workflow entendeu então são são duas razões né tipo bem diretas assim concretas que podem te levar para um para um ambiente que assim tu teria que colocar num ambiente que pode ser um ambiente de desenvolvimento também mas que tenha mais computadores disponíveis entendeu eh não sei se isso responde tua pergunta mas eu eu vejo dessa forma tá tá ok obrigado profess então ess essas ferramentas que a gente tá vendo aqui ó elas permit tu podes usar elas no teu ambiente de uma máquina só de 6 gb aí que tu falaste entendeu Mas elas têm a característica de que se quando tu precisar aumentar entendeu ir

- *Corpus ID:* 6629
- *Score:* 0.8533123731613159
- *URL:* oculto
- *Início:* 00:22:41
- *Fim:* 00:24:46
- *Transcrição:* que ele tá querendo dizer com esse tipo de coisa que foi algo que aconteceu um pouco no no no Exercício né assim a gente acabou chegando uma solução se elegante ou não eu deixa o seu PR seu juiz quando eu corrigir mas eh se possível deixar um não deixar tão lado mais específico na questão isso um pouco é não o tanto que o Senor julgar né Uhum aí é não mas mas prova é na prova a prova vai ser mais conceitual né falando da prova assim mas tipo o que eu quero dizer assim se tiver se vocês fossem expostos a um questionamento que fosse assim talvez mais específico assim H Antônio então no teu caso tu consegue responder tu consegue imaginar qual que é a sequência de operação iso para fazer acho que sim tem que pensar um pouquinho mas sim obviamente eu tô vendo na tela aí algumas dicas né mas sem olhar eu teria que acessar a minha memória aqui o que você queria era é tal daquela Rolling Window pandas pode ser por exemplo poderia ser Rolling Window é poderia usar uma janela deslizante né E aí tu usar a janela deslizante fazendo cálculos em cada uma e fazendo com que esses grupos que a gente tá agrupando aqui não seja baseado num valor de uma janela de uma de uma coluna mas seja numa janela de tempo assim imag então dá para fazer Rolling Window também isso é uma técnica bem clássica para responder esse tipo de pergunta né mas eu assim a grande pergunta é assim tipo eu preciso saber as coisas que estão disponíveis para mim né então por exemplo essa aí é uma é uma delas Ah o que que é Rolling Wi Tipo isso aí a gente não entrou nesse detalhe né porque não não né a gente tava num um curso aqui mais de paralelismo assim né mas saber esses mecanismos O que que está disponível né pra gente poder usarlas né É é bastante importante né então isso tá muito mais no no no no na questão do pandas né e a gente poderia usar o livro

- *Corpus ID:* 6266
- *Score:* 0.8523675799369812
- *URL:* oculto
- *Início:* 01:19:33
- *Fim:* 01:21:24
- *Transcrição:* o software que tu tá usando e é o pandas ou o dask né Aí no caso daí é essas outros eh intermediários aí né que teriam que eh ter alguma responsabilidade tem né então é bem complexo não não sei dar uma resposta definitiva assim entendeu é é porque eu penso assim quando você massifica a quantidade de pessoas né Porque hoje a gente tá a realidade hoje no s é assim a gente tá saindo de muitas pessoas que programavam pra web e tal e estão começando a entrar nesse mundo né a gente tá aqui por exemplo na terceira turma aqui de cências de dados então assim vai ter uma equipe muito grande que vai manter essa infraestrutura de GPU que tá sendo construída ainda é muito pequena mas tá sendo evoluída e tem uma equipe pensando em manter esse ambiente infraestrutura de GPU né e tem outra galera que vai implementar aplicações que vai fazer uso dessa infura mas eu acho que precisa de uma ferramenta que o cara que esteja na ponta consigui entender se ele tá usando de forma otimizada ou não aquela infraestrutura para ele dar feedback para quem configura e quem configura dá feedback para ele que ele não tá programando da melhor forma possível perfeito mas assim eh quando tu instancia assim se tu tá programando nesse nível Tá quando tu instancia a tua a tua plataforma de GPU assim não tem muita coisa para fazer entendeu tu vai lá instala as placas nos nós entendeu ou tu compra nós já com as placas placa se deu e é isso entendeu não tem nada para fazer do ponto de vista de hardware para configurar essas placas é tudo feito em software entendeu então e esse software normalmente a pessoa que tá programando essas placas é ela que controla entendeu então por exemplo aqui ó quando eu lancei o meu terminal aqui ó posso lançar de novo aqui e eu fiz o acessei aqui a máquina e rodei ess vde smi eu consigo ver que o que tem instalado aqui é o

- *Corpus ID:* 4898
- *Score:* 0.8522915840148926
- *URL:* oculto
- *Início:* 00:31:54
- *Fim:* 00:33:55
- *Transcrição:* ah entendido entendido tá bom obrigado ah Só uma pergunta final vocês que têm trabalhado vocês têm alguma alguma opinião a respeito da da Performance em termos de dados grandes dos dois assim sabe sabe se os dois são são compatíveis em termos de suporte para para dados maiores ou se um é melhor do que o outro essa essa é uma discussão longa e a gente já fez alguns Laboratórios aqui né quando a gente pega o clique e eh que a gente tem mais fluência a própria Carol aí pode dizer isso Nós temos duas possibilidades né de tratar com com com dados A primeira é você pega os teus dados né e joga tudo aquilo para para pro teu painel então o painel incorpora aquele conjunto de de dados aquilo vai pra memória e pá começa a atender as pessoas é muito mais eficiente muito mais ah performático Porém quando a gente pensa em em Big Data em grandes dados por exemplo uma nota fiscal eletrônica sei lá ah essa tu tu não consegue imaginar né todo um conjunto de notas cais eletrônicas indo paraa memória de um mega ser do não não não é razoável Então você mantém apenas uma quantidade pequena em memória e a partir da da da necessidade você né Vai lá na tua fte de dados que enfim pode ser o datalake ou algo do gênero ah a gente tem feito a ali alguns experimentos mas ainda a gente não tem uma digamos ah algo categórico com relação a essa ou aquela ferramenta a Microsoft Tá vendendo muito a ideia de cara coloca na nossa nuvem que o espaço aqui infinito mas nós não chegamos a a testar entendi entendi entendi interessante eu eu fiquei curioso de saber até teve um um de vocês queria saber se a performance do stream datat me mandou mensagem antes do curso não me Lembo quem foi mas eh essa é uma parte interessante também bom eh o streit professor o stream leit ele tá sendo utilizado tem uma uma poc aqui é para

- *Corpus ID:* 5781
- *Score:* 0.8512511849403381
- *URL:* oculto
- *Início:* 00:08:16
- *Fim:* 00:10:24
- *Transcrição:* entrada de dados que é bem Ampla Tem a parte de transformação né E e aí Eu sempre gosto de fazer a ponte com com SQL porque acho que muitos de vocês já TM bastante experiência com SQL né então assim pensem que tudo que vocês fazem em SQN entendeu existe uma uma a mesma coisa pra gente fazer em pandas assim essa é a ideia geral então tem desde reformatação pivoteamento eh fateo Fancy indexing que a gente inclusive viu já no num pai também dá para fazer aqui eh group buy que é uma das Ferramentas bem Poderosas assim pra gente fazer sumários né Eh as operações de mer Joy tem um monte de coisa tá inclusive funcionalidades parciais temporais é bem amplo certo e e o que é interessante sobre essa parte de transformação é que o é que o pandas ele começou com uma pessoa ali com uma ideia né e e hoje assim tem um monte de gente trabalhando com isso né Então realmente virou um negócio gigantesco assim tem um monte de coisa dá para fazer que inclusive é objeto de reclamação da galera do dask né que a gente vai ver na segunda parte da aula né que é quem tem que prover o paralelismo né pro pandas né então eles têm que pegar todas essas transformações possíveis e torná-las paralelas para que as pessoas que usam dask possam usufruir disso né E aí como tem muita coisa nem tudo é suportado para dask né então acaba sendo um problema da quantidade de funcionalidades que tem tá hã então assim eh do ponto de vista de Alto desempenho existe então uma preocupação do pandas de ser rápido né então tem muitas das coisas que não são escritas em Python Python Seria somente a casquinha digamos assim pros usuários né porque muita coisa escrita realmente em em C mesmo né uma linguagem compilada né toda aquela discussão que a gente já conversou ali e a gente vai ver na segunda parte da aula o pandas é totalmente sequencial e e realmente ele é um ele é um ele é

- *Corpus ID:* 5777
- *Score:* 0.8510774970054626
- *URL:* oculto
- *Início:* 00:01:38
- *Fim:* 00:03:50
- *Transcrição:* também fazer uma atividade dirigida que basicamente vai ser uma revisita das atividades dirigidas anteriores eh só que daí usando Eh o dask ok então a gente vai começar então falando sobre uma visão Geral do pandas Tá certo Deixa eu só configurar aqui min slides page então Eh o pandas então ele se autointitula como sendo uma data wrangling platform eh que assim traduzindo esse wrangling para português não sei bem mas seria tipo assim uma plataforma para tu trabalhar com dados digamos assim né então ela serve tanto para data ingestion que seria assim a tua é o nome que o pessoal usa né em ciência de dados para eh a tu trazer a informação paraa memória digamos assim né e depois fazer alguma transformação que seria segundo objetivo do pandas E aí essa transformação que ali que tá tudo que tu queres fazer né com o dado né extrair informação derivar informação e aí depois exportar exportar para um outro formato ou para um formato que enfim no teu o teu pipeline de transformação sei lá para onde vai essa esse dado né talvez paraa visualização então tu tem como exportar então num Pai a gente importa ele como NP né o pandas a gente tem essa abreviatura habitual eh pd né então sempre nos blocos aí que a gente vai ver ao longo da da aula de hoje né e eu espero que vocês possam incorporar isso também na vida no cotidiano de vocês eh vocês vão sempre usar essa nomeclatura porque ela ajuda daí a a vocês mesmos entenderem no futuro e aos colegas também então assim falando um pouco da história do pandas né Eh ele começou em 2008 por uma pessoa em uma empresa assim um negócio bem assim tipo uma pessoa começou e tu vê 2008 não é não faz tanto tempo né mas logo em seguida já foi transformada em open source ainda assim gerenciado digamos assim por essa uma pessoa ela continua envolvida até hoje né que é o West nome

- *Corpus ID:* 5860
- *Score:* 0.848861575126648
- *URL:* oculto
- *Início:* 00:51:07
- *Fim:* 00:53:18
- *Transcrição:* e custa muito né tu ter uma máquina que tem 1 TB de memória então Eh normalmente eh tu nas máquinas assim mais comuns vamos lá tu rapidamente chega nesse limite assim sabe tipo assim ah por exemplo essa máquina que eu tenho aqui tem 32 GB com esses 32 diga B que para alguns Pode parecer ah bastante né não é o suficiente pra gente fazer eh A análise por exemplo de usando só pandas né Desse dataset do tempo aí e muito menos dos Aviões certo então assim não não é o suficiente para usando pandas tá Então qual que é a ideia a ideia é que o dask ele vem para resolver esse problema ele tem toda essa questão do paralelismo né que a gente já viu né mas o que que ele faz ele pega os ã as as as tabelas que a gente tem e reparticion elas né E e aí a ideia é fazer com que tu consiga fazer uma operação que envolve terab de dados né numa máquina que tenha 32 GB de memória porque o dask ele vai ficar monitorando a memória e vai usar né Eh Vai imagido que a gente preparou isso né a gente vai reparticion os dados de maneira que os pedacinhos caibam na memória e a gente faz as operações Pedacinho por pedacinho tudo isso que eu nem falei lá no instal entendeu de maneira assim uma vez que tu definiu o tamanho da partição né de maneira transparente o importante é que o a nossa análise sejam esses esses encadeamentos de operações esses encadeamentos de operação continua exatamente igual entendeu a única diferença é que esse DF aqui ele não é mais um pandas dataframe ele é um TK dataframe que é basicamente um uma coleção de pandas dataframe Só que essa essa coleção é de queê é de partições de uma única tabela entende então ah isso basicamente torna o negócio escalável ele torna ele o negócio escalável permite a gente fazer leitura de arquivos em paralelo que isso a gente já viu né então eh eh realmente essa que é a ideia então de


**Resposta gerada pelo LLM**: O Pandas tem preocupação com performance, sendo que muitas de suas funções são escritas em C, uma linguagem compilada, para ser rápido.  Apesar disso, é totalmente sequencial, o que se tornou um limitante para grandes volumes de dados, necessitando de divisão manual em pedaços para transformações.  Para resolver isso, surgiu o Dask.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. Supporting Evidence: The RESPONSE addresses the performance aspect of Pandas by mentioning that many functions are written in C for speed, which is relevant to the prompt. It also discusses the limitations of Pandas in handling large volumes of data and the need for manual division, which further relates to performance issues. Additionally, it introduces Dask as a solution, which is relevant to the context of improving performance with large datasets. Overall, the RESPONSE provides a comprehensive view of how Pandas handles performance, covering multiple aspects of the prompt.  Score: 3


---
