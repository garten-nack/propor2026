**Pergunta 54**: Quais são os três componentes fundamentais que devem ser considerados ao trabalhar com visualização de dados?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 8852
- *Score:* 0.8653519153594971
- *URL:* oculto
- *Início:* 00:40:48
- *Fim:* 00:43:33
- *Transcrição:* grafos Então são duas características principais né A primeira são as consultas de navegação né Então são aplicações em que a gente precisa fazer esse tipo de consulta e a outra é para quando a gente quer navegar e descobrir informações que não estão explícitas nos dados né então quando a gente navega pelos relacionamentos a gente pode descobrir ou não né informações eh que são relevantes pronto eh alguém tem alguma dúvida ou pergunta até aqui professora eh em relação às visualizações né Eh tem alguma ferramenta pessoal recomende para fazer uma visualização de de um de um brafo em árvore por exemplo é nud e o forj ele tem uma interface né para fazer eh para fazer as visualizações e E aí depois assim tem muita gente que usa eh as visualizações do tipo que vocês viram no na disciplina do komba né Eh do João komba de visualização que foi a outra a última disciplina aquele trabalho de TCC ali que eu mostrei para vocês do da campanha de das eleições de 2018 ele fez o processamento no newf e usou uma interface de visualização eh desvinculada do do sgbd né Então aí eh depende do que pode ser feito mas em geral os os bancos de dados hoje na o lá naquela época o newf J não tinha uma interface como ele tem hoje mas em geral as interfaces assim de visualização não são tão Claras assim como a gente vê na na área de visualização né então é muito comum essa combinação né de usar o banco de dados para processar e de fazer a visualização numa outra interface eh aproveitando a tua pergunta também tem trabalhos que que já que fizeram essa comparação assim porque eh do tempo de de processamento né quando eu [Música]

- *Corpus ID:* 3740
- *Score:* 0.8651442527770996
- *URL:* oculto
- *Início:* 01:35:58
- *Fim:* 01:39:09
- *Transcrição:* um câncer mas bem definido talvez até eu tivesse aqui um alto lá tem um elemento aqui que é um pouco mais fora da curva tem como aqui em cima tem alguns que também estão aí pera aí que analisar esse caso específico né para ver se ele faz parte ou não precisa você pode me ajudar nisso mas eu tô tentando colocar o lado não era só colocar no sub no AD sub plot Coloca aquela coordenada número de linhas números de volume e qual é a posição que aquela aquela figura sim quer colocar um do lado do outro é isso deu certo agora é mais chatinho o terceiro exercício não é complicado mas outra vez vamos ver aqui exercício 3 tá o exercício 3 só para recapitular nós temos aqui um conjunto de dados não é pronto e ele está ilustrado aqui com as etiquetas e deveriam ser as finais não é não a ideia aqui embaixo é nós aplicarmos nesse nesse data 7 aqui é um complicador é que eu devia ter adotado a mesma nomenclatura né eu tô chamando de features lá em cima era data e eu acho que Lemos enfim o nome mudou mas mas enfim estou separando entre aqueles dados que vão ser processados e o resultado Então temos que usar as features aqui embaixo e a ideia então é nós a essas features primeiro nós fazermos a transformação né usando a padronização aquela para que todas fiquem entre uma escala parecida normalizadas na média zero e uma um desvio padrão e depois aplicar o caminho doidis e o FC Mix então podemos podemos fazer juntos aqui o início pelo menos

- *Corpus ID:* 4042
- *Score:* 0.8621671795845032
- *URL:* oculto
- *Início:* 00:27:21
- *Fim:* 00:29:41
- *Transcrição:* E aí essa esse algoritmo ele vai então fazer esse ajuste dessas componentes que são linhas que separam o espaço colocando essas linhas nas melhores posições possível para manter a representação dos dados originais e aí eu uso esses componentes no restante do processamento seja a mineração de dados ou visualização e aí como eles são uma quantidade menor eu vou processar em menos tempo bom e eu tenho eu tenho um exemplo aqui de como é que nós podemos poderíamos fazer isso no corrente dados que nós já usamos né então se você lembrar lá das Flores das ilhas nós vamos carregar aquele conjunto de dados E aí vamos aplicar Então essa técnica para Que ela possa nos dizer ao invés de usar as quatro dimensões originais quantos componentes principais eu teria que ter né para poder representar o mesmo conjunto de dados né bom primeira coisa carregar Os dados aqui e algo importante que que nós devemos fazer é escalar os dados né porque nós componentes principais já que eles são separadores lineares funcione da maneira mais adequada eu preciso colocar todas as dimensões no mesmo padrão né sinal de que ele pode ter problemas na hora de identificar essa essa e não representar adequadamente a variabilidade dos dados já que eles têm dimensões de tamanho diferente e depois não tem muito muito mistério basta eu executar não é o modelo distanciar o modelo E aí tem alguns parâmetros o principal parâmetro aqui é a quantidade de componentes vocês vão ver depois que tem outros outros parâmetros se vocês pegarem aqui pegar o decomposition sempre vão dar uma olhada no

- *Corpus ID:* 4611
- *Score:* 0.8613948822021484
- *URL:* oculto
- *Início:* 00:43:26
- *Fim:* 00:45:47
- *Transcrição:* tabela ess fazer uma análise um pouco mais cuidadosa você vai ver que você consegue identificar que esses dados aqui são diferentes né você vê que tá quase toda a coordenada x aqui é sempre oit né enquanto varia os outros mas o que chama atenção é que as informações elas são estatíticas são as mesmas E aí né no sentido de eh esse é um trabalho antigo né clássico na área de estatísticas P olhar e olhar no o trabalho do ancom uncom Quart é porque é um Quarteto né são quatro conjuntos de dados eh em estatística isso aqui é clássico is aqui é dado em aula de estatística para mostrar que eh a estatística ela precisa ser eh considerada com cuidado e e complementada a análise né mas mais recentemente na na área de visualização esse problema foi revisitado no que eles chamaram de conjunto de de uma dúzia de dados que eles chamaram de datas e a razão e eu tô mostrando essa animação aqui para mostrar para vocês é o seguinte eles quiseram fazer a mesma coisa eles queriam gerar eh estatísticas de média di o padrão e com relação a mesma para o conjunto de dados né até a segunda casa decimal e o que eles estão fazendo aqui à esquerda eles estão permitindo os pontos se mexer mas não alterando o as estatísticas básicas e todas esses essas diferentes visualizações que eles geraram todas elas têm a mesma estatística básica então o eles escreveram um algoritmo que permite fazer um processo que é chamado de relaxamento dos ados que é relaxamento da posição dos dos vér que permitem você gerar outras foras geométricas E essas outras formas geométricas elas tem as estatísticas básicas nome do artigo same stat generating

- *Corpus ID:* 4041
- *Score:* 0.8611013889312744
- *URL:* oculto
- *Início:* 00:25:37
- *Fim:* 00:27:55
- *Transcrição:* coisas que não se misturam é um segredo tá em achar esses componentes principais que são ortogonais entre si e que representam então a variação naquela naquela naquele sentido não é independente dos outros digamos assim então o componente principal são essas dimensões ou elementos que capturam a variância nos dados E aí eles possuem uma uma direção e uma magnitude ou um tamanho né então o segredo tá em matematicamente descobrir né Qual é a direção de cada um desses componentes e a magnitude deles e aí fazer esse ajuste no espaço de dimensões para que eles têm uma direção uma magnitude que represente a maior quantidade de variância possível do conjunto de dados E aí a ideia é que esse esses elementos eles vão ter uma uma correlação né com quantidades originais bom aqui tem tem uma explicação mais detalhada para quem gosta de matemática né mais importante é que eu consigo Então criar um conjunto mínimo aí de componentes vou chamar de dimensões os PCs como os principais só podem ser como dimensões que substituem substituir as dimensões originais a ideia então é eu pego o conjunto de dados que eu tenho eu aplico a técnica de PCA para criar um novo conjunto de dimensões que são os componentes principais E aí essa esse algoritmo ele vai então fazer esse ajuste dessas componentes que são linhas que separam o espaço colocando essas linhas nas melhores posições possível para manter a representação dos dados originais e aí eu uso esses componentes no restante do processamento seja a mineração de dados ou visualização e aí como eles são uma quantidade menor eu

- *Corpus ID:* 5083
- *Score:* 0.8608838319778442
- *URL:* oculto
- *Início:* 00:22:22
- *Fim:* 00:24:54
- *Transcrição:* enfrenta quando trabalha com visualização de dados é que os dados eles principalmente dados numéricos eles têm uma faixa de variação e você eh quer fazer essa faixa de variação mapear para uma cor para você conseguir mostrar nuances variações tem mais daquele valor menos daquele valor no caso aqui a gente pode eh mapear paraa cor muitas informações daqueles dados né mas escolha uma delas pode ser o número de bicicletas que tem na estação né bom ah o que que eh a gente eh pode fazer e o que eu já mostrei né Essa visualização aqui à esquerda basicamente é o processo que a a gente fez por exemplo nos corredores a gente tinha um gráfico de linha tava mostrando um digamos assim uma quantidade ao longo do tempo essa quantidade a gente pode mapear paraa cor para descrever um pouco mais dessa informação e a gente fez isso com o batimento cardíaco quando a gente desenhou batimento cardíaco e depois a gente transformou isso aqui numa linha né e ao transformar nessa linha se digamos assim esse achatamento a gente consegue consegue fazer com que a informação seja mais compacta para ser mostrada né então aqui eh eu tô mostrando ah um ao longo dessa linha aqui a ocupação da da estação eh essa ocupa ação ela ela é medida em percentual de bicicletas eh em função do número de espaços como cada Estação tem um número de bicicletas ou de vagas disponíveis diferentes para você poder comparar entre elas você você pode usar os números absolutos Mas isso fica difícil mas você também pode usar os números relativos ao ao número de bicicletas então quanto mais escuro aqui mais próximo de tá 100% che né Então essa eh você vê aqui quando os valores estão Claros a a a estação tá vazia e aqui vai começa a encher depois esvazia depois a de novo depois esvazia né tá esse é é um problema desse

- *Corpus ID:* 4642
- *Score:* 0.8607445359230042
- *URL:* oculto
- *Início:* 00:18:34
- *Fim:* 00:21:07
- *Transcrição:* motivação do que que a gente vai ver disciplina que é tentar combinar A análise dos usando visualização mas não somente mostrando os dados mas tentando permitir com que o usuário usando o seu processo cognitivo interprete o que tá tendo de de informação que ele interaja com com os dados e ele ele consiga extrair informações que permitam com que ele consiga explicar os dados ou ou tomar fazer tomada de de decisões então Eh isso aqui resume a primeira aula né coloquei aqui como o plan das aulas então vou passar de de imediato então pr pra aula que eu teria ter iniciar 10 bom então hã nessa aula agora eu vou falar sobre fundamentos de visualização de dados e revisar alguns conceitos que vocês alguns conhecem mas alguns outros são são novos né mas eu usei para algs desses slides eh informações que estão nesse livro que é que é bem didático assim para explicação de visualizações que é o data points ele divide apresenta são ou a explicação em representação exploração visual de dados e visualização com clareza paraa representação de dados eh ele coloca o uma terminologia que permite com que a gente eh se refira a esses potes que a gente cria que são o que ele chama de expressões visuais que é como que você codificado através dos canais de a exibição pode ser for pode ser cores pode ser tamanhos são dicas que são usadas para você poder mostrar a informação você naturalmente eh em muitos desses gráficos você usa ess sistemas de coordenadas Porque você quer que de alguma forma o que tiver coordenada geométrica seja relacionado no sistema de coordenadas você usa sistemas de coordenadas associadas a eixos que tem formas diferentes a de de representação e obviamente você coloca um contexto que é poder trazer informação agregada para

- *Corpus ID:* 4051
- *Score:* 0.860582172870636
- *URL:* oculto
- *Início:* 00:43:32
- *Fim:* 00:45:41
- *Transcrição:* E aí vocês vão mostrar isso e depois eu quero que vocês gerem um gráfico em três dimensões aí vocês vão criaram você pode usar os três primeiros componentes principais E aí vocês vão gerar um gráfico entender para ver como é que no espaço esses caras esses dados ficam né distribuídos e finalmente o último exercício para a gente combinar né o resultado com com que a gente já vinha fazendo é de uma maneira fazendo análise não se previsionada para agrupar dimensões né ou criar dimensões que que agrupam nesse caso aqui é a variabilidade dos dados e nós já sabemos que podemos usar isso para visualização então a tarefa do exemplo fazer a visualização disso né A projeção descontrados que tem um monte de dimensões em só três nós vemos então parcialmente usualmente né Esse é um dos objetivos da tarefa os objetivos desse tipo de análise e o outro objetivo é além de visualização eu posso usar esse Conjunto Novo dimensões para fazer alguma alguma aprendizagem de máquina seja supervisionado ou não como nós estamos fazendo não os prisionado nós vamos continuar fazendo isso eu quero que vocês aplicam médias tentando agrupar esses elementos em dois grupos porque dois grupos porque o analista de domínio já já tinha visto isso né a gente vai considerar isso que como é câncer de mama eu estou interessado em criar dois grupos um que é o grupo das pessoas que não tem câncer de mama e uma das pessoas que tiveram câncer de mama porque eu quero depois analisar esses grupos e verificar né quais são as propriedades Quais são os elementos né é que cada um desses perfis tem né Para que justamente quando chega um paciente novo esse objetivo eu poder dizer bom ele ele esse paciente tá dentro de um grupo que que teria chance alta de ter câncer de mama não ele é um paciente que

- *Corpus ID:* 4977
- *Score:* 0.8591377139091492
- *URL:* oculto
- *Início:* 00:02:14
- *Fim:* 00:04:51
- *Transcrição:* desenvolvimento de projetos de visualização de dados muito dessas propostas elas estão apeladas a artigos científicos ou a que a comunidade científica tá desenvolvendo relacionada a projeto de de visualização de dados esse primeiro o design triangle que relaciona dados com usuários e com tarefas ele foi proposto Nesse artigo ou ele foi eh eh explicado Nesse artigo para dados relacionados a eh que tem uma característica de serem temporais mas o a abordagem ela aplica-se a qualquer tipo de o projeto de visualização de dados que a gente queira trabalhar e então aqui de 2014 já tem uns 10 anos mas eh trabalhos eles mais ou menos têm essa faixa de de tempo então a ideia desse trabalho é bem simples quando você tá trabalhando com visualização de dados e até em outros aplicações você tá basicamente eh pensando ou tentando definir três componentes fundamentais Quais são os dados que vocês vão estar trabalhando Quais são as tarefas que vocês vão tá desenvolvendo em cima dos dados e quais são os usuários que vão eh se beneficiar dessas tarefas né então seguindo o roteiro que tá aqui em cima então que tipo de dado os usuários estão trabalhando você tá desenvolvendo uma aplicação você Quer tentar fazer com que usuários tenham insights tenham conclusões sobre os dados Então quais são os dados né quem são os usuários da solução de va va aqui tá é uma sigla para visual Analytics ou analítica visual e quais são as tarefas que eles usam em cima desses dados então esses três componentes eles definiram como se fossem pontas vértices de um triângulo e o Universo de métodos de análise visual ele tá vai tá relaciodo esses três componentes e eles também eh relacionam as arestas

- *Corpus ID:* 4986
- *Score:* 0.8581384420394897
- *URL:* oculto
- *Início:* 00:20:00
- *Fim:* 00:22:40
- *Transcrição:* vê que nesses três componentes aqui a gente tem basicamente o que a gente tinha anteriormente no no design triangle Você tem os usuários Você tem os dados você tem as tarefas né então é similar né e cada digamos assim a abstração ou forma de proceder é é um pouco diferente Estão tocando nos mesmos pontos né E ela eh aqui Traz essa questão do do idioma que é Como como é que você mostra os dados né Qual é o o o idioma de codificação visual que você tá usando como é que você desenha E como é que você interage com os dados né Como que você manipula os dados então tem eh digamos assim dois específicos escolhas aqui o o idioma de codificação visual e idioma de interação né e por fim um último ponto é é que tudo isso acaba precisando ser implementado né E e essa implementação ela tem que lidar com questões de de eficiência Então os algoritmos que que vão suportar tudo isso precisam ser eficientes porque você precisa para interação suportar a interatividade por exemplo e a questão é uma vez desenvolvido um projeto como esse como é que você como é que você verifica se as suas escolhas foram as melhores possíveis né Então como que você valida o o teu teu projeto né E e aí ela menciona que existem como qualquer projeto existem formas diferentes de você errar e e cada um daqueles quatro níveis que a gente desenvolveu ou porque você não entendeu as necessidades do do usuário ou do domínio né isso É frequente né análise de sistemas você frequentemente você revisa você faz reunião com usuários você faz análise de requisitos você faz diferentes processos para entender as necessidades e às vezes existe uma falha de comunicação por idiomas diferentes que as pessoas conversam enfim você pode também errar no nível de abstração de dados e tarefas né né Você pode est mostrando eh algo que não é exatamente o que o usar quer ver né


**Resposta gerada pelo LLM**: Dados, tarefas e usuários.

**Referências**:
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should address the three fundamental components of data visualization. Supporting Evidence: The RESPONSE identifies "Dados, tarefas e usuários" as the three fundamental components, which directly answers the PROMPT. It is relevant to all parts of the PROMPT, providing a complete and accurate response.  Score: 3


---
