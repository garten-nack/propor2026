**Pergunta 3**: Como o viés pode ser introduzido em um modelo de aprendizado de máquina?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2178
- *Score:* 0.8714905977249146
- *URL:* oculto
- *Início:* 00:24:42
- *Fim:* 00:26:45
- *Transcrição:* desenvolvimento dos modelos e nesse ponto tá incluso né A questão da gente avaliar os dados perceber se a gente tem potenciais vieses enfim a gente acaba criando modelos com viés Então o que a gente tem que ver é que o nosso modelo ele não pode se cumprir com o nosso objetivo da tarefa de aprendizado de máquina né claro que a gente quer fazer isso aí mas isso não é a única questão a gente tem que garantir que ele não tenha implicações sociais negativas porque por exemplo se eu falando Aquele modelo que eu comentei do risco de câncer de mama se eu fizer um modelo consegue identificar precocemente o risco de câncer de mama com uma acurácia vou falar curaça né ou uma sensibilidade melhor uma boa sensibilidade mas esse modelo não funciona para mulheres negras ele tem uma implicação social negativa porque ele está discrimido mulheres negras e não permitindo que elas tenham por exemplo um tratamento precoce tenho mais chances de se recuperar da doença e isso a gente sabe que acontece muito ainda tá eu coloquei um exemplo né mas a gente sabe que acontece muito isso então quando falo vieses né um viés é uma tendência associada ao determinado por um fator externo que não deveria implicar na decisão do modelo por exemplo nessa questão do risco da doença dependendo se eu não tô avaliando o background genético das pessoas eu tô avaliando outras questões como uma biópsia enfim não deveria estar ponderando né idade enfim não deveria estar sendo sendo impactado Ou seja eu ter um sistematicamente um desempenho pior para determinados grupos de pessoas tá então em aprendizado de máquina quando a gente fala que a gente tem vezes é porque a gente faz o modelo tá fazendo predições injustas ele tá privilegiando um grupo em relação aos outros então por exemplo poderia estar privilegiando mulheres

- *Corpus ID:* 2037
- *Score:* 0.8616363406181335
- *URL:* oculto
- *Início:* 01:23:28
- *Fim:* 01:25:30
- *Transcrição:* permitir que vocês variam esse modelo se vocês quiserem agora uma coisa que vai chamar atenção de vocês que vocês vão ver é que a própria implementação desse método por exemplo não permite né pelo menos eu não sei uma forma de fazer de usar diferentes algoritmos para treinar esses modelos então a gente foi o que eu falei a gente varia os dados mas não varia o algoritmo tá o algoritmo Ele é o único certo entre todos os modelos e o behrin ele é um uma samba o que a proposta dele é reduzir a variância desses modelos então ao agregar esses diferentes modelos que são treinados com algoritmos instáveis Ou seja que tendem a ter uma variância alta em função de mudança nos dados A ideia é que o bag em possa reduzir essa variância né como se ele tivesse eu coloquei entre aspas aqui a média porque na classificação obviamente a gente não tá pegando a média mas basicamente ele reduz essa variância de desempenho que a gente tem quando usa esse tipo de modelo né em função de variações nos dados tá quando tem algoritmos com alto viés por exemplo uma regressão logística e baixa variância não tem um benefício Claro de usar backing ou seja o bem ele foi desenhado pensado para ser trabalhado junto com algoritmo de alta variância não quer dizer que eu não posso usar com algoritmos que tenha baixa a variância mas talvez o efeito benefício de eu melhorar o desempenho né ao reduzir a variância não vai ter porque eu não tenho alta variância no modelo base tá e o viés que é o erro os erros de predições que surgem da suposições dos modelos o viés desse classificador lançando o que a gente chama desse bag ele pode vir a ser menor que os classificadores bases então o viés menor quer dizer que ele erra menos ele é melhor certo então ele pode ter um efeito sobre o viés normalmente acontece isso né que a gente tem como eu mostrei no

- *Corpus ID:* 2319
- *Score:* 0.8613526821136475
- *URL:* oculto
- *Início:* 00:07:43
- *Fim:* 00:09:43
- *Transcrição:* para realizar as predições no mundo real dados com o menor viesse possível tá então viés aquela inconsistência que a gente tem dos dados em relação ao fenômeno que ele que ele representa tá a gente comentou um pouquinho sobre essa questão dos vieses né que eles podem gerar esses erros sistemáticos por exemplo se eu tenho dado um conjunto de dados com dados de crianças que tem pouco risco para uma determinada doença e aí isso fora digamos assim um certo viés por uma questão de coleta de dados eu posso estar gerando erros sistemático no meu modelo meu modelo ele cistematicamente vai achar que crianças têm medo risco para aquela doença porque na nossa amostra é o que está representado a gente tem muito menos crianças doentes né proporcionalmente do que adultos doentes isso pode ser verdade como pode não ser então o que a gente tem que ver se esse erro você se vi essa pessoa incorporado Pelo modelo ele chega a prejudicar algum grupo específico ou indivíduo tá então ele tem que ser livre de viés né preferencialmente tá o outro ponto é que os rótulos no caso de aprendizados pelo seu lado que a gente está discutindo os rótulos sejam categóricos ou numéricos idealmente não devem ser resultados de um outro modelo de aprendizado de máquina devem ser rotulados de forma independente por especialistas enfim ou com algo que parte do domínio não da máquina né Claro porque às vezes é parte desses rótulos são acabam sendo rotulados por aprendizado de máquina se a gente tiver falando de aprendizado que a gente chama de sempre supervisionado que não é exatamente o que a gente discute aqui onde eu tenho parte dos dados do outro lado parte não do outro lado o que a gente faz normalmente aprender o modelo a partir dos dados do outro lado e aplicar esse modelo dos dados do outro

- *Corpus ID:* 1993
- *Score:* 0.8592761158943176
- *URL:* oculto
- *Início:* 00:10:57
- *Fim:* 00:13:08
- *Transcrição:* modelos com baixo viés e Alta variância ou modelos de baixo a variância E aí a pergunta que a gente vai discutir na aula de hoje que é justamente a ideia desse aprendizado no samba esse Existe algum benefício em combinar múltiplos modelos com viés diferentes ou seja se eu tenho Ou até eu coloquei viés diferente mas até modelos com alta variância né se eu tenho modelos que eles pecam por ter alta variância ou se eles pegam por ter alto viés Será que tem alguma vantagem da gente combinar né as decisões desses modelos então a gente vai justamente discutir essa pergunta através desse paradigma que eu falei para vocês que eu paradigma de aprendizado certo isso deriva de uma teoria que não tem origem aprendizado de máquina tá inclusive esse livro é bem legal para quem gosta dessas leituras né que assim interessante temas interessantes muito relacionado com questões práticas tá que a sabedoria das multidões tá does of Crowds E aí basicamente essa teoria diz o seguinte né que esse conhecimento que mede de uma decisão coletiva ou seja um grupo de pessoas né tomando uma decisão junto frequentemente tem um desempenho melhor do que a decisão de cada membro desse grupo de forma individual mesmo aqueles que são especialistas certo então é como se tivesse um grupo de pessoas né E aí obviamente a gente vai ver que tem algumas condições mas tem algum grupo de pessoas tomando uma decisão junto mesmo que eu tenha especialistas nesse grupo a decisão da maioria né dessa multidão ela tende a ser melhor do que os a decisão individual de cada de cada pessoa certo nesse nesse grupo e claro que não é digamos assim qualquer multidão que é sábia né esse o autor ele ele traz algumas questões que Inclusive a gente vai ver que são muito parecidas com requisitos que a gente tem aqui mas assim eu preciso ter diversidade de opiniões né

- *Corpus ID:* 2641
- *Score:* 0.8591910004615784
- *URL:* oculto
- *Início:* 00:41:07
- *Fim:* 00:43:06
- *Transcrição:* que é mais explícita assim para esse caso né então não nem sempre é fácil identificar as variáveis que estão carregando esse viés mas mas seria o ideal a gente tentar identificar seja por um conhecimento prévio seja por uma análise protória dos dados seja usando algumas métricas que a gente tem métricas que tentam analisar o potencial de baias antes do treinamento né o potencial de várias carregado por cada variável mas tudo isso do ponto de vista de métricas de métodos para tratar esse tipo de problema ou evitar ou tratar ainda são coisas em desenvolvimento tem bastante coisas já que foi desenvolvida que está sendo usada mas a gente pode dizer sim o problema ainda não tá 100% resolvido sabe ainda tem muito do ponto de vista de pesquisa e desenvolvimento para ser feito para realmente tornar algoritmos mais seguros em relação a isso mas de fato uma possibilidade seria isso identificar esses riscos de viés nos dados e tirar essas variáveis que carregam esse viés seja de uma forma bem explícita né ou seja dessa forma mais mascarada assim então não é uma tarefa muito fácil e a gente só consegue Observar isso imagino eu nos modelos interpretáveis e isso ou usando técnicas para interpretar os modelos né a prioridade seria usar o modelo interpretável tá E seria prioridade porque a gente consegue ver exatamente que o modelo tá aprendendo as outras técnicas a gente usa recursos para tentar estimar né Essas associações ou essas essas associações do ponto de vista né do que que tá explicando uma saída então quando a gente Depende de um outro método para compreender o nosso modelo a gente sempre fica refém do que esse método faz né E até que ponto ele consegue de fato encontrar isso né Então realmente os modelos interpretáveis eles

- *Corpus ID:* 2038
- *Score:* 0.8589663505554199
- *URL:* oculto
- *Início:* 01:24:59
- *Fim:* 01:27:08
- *Transcrição:* tenho alta variância no modelo base tá e o viés que é o erro os erros de predições que surgem da suposições dos modelos o viés desse classificador lançando o que a gente chama desse bag ele pode vir a ser menor que os classificadores bases então o viés menor quer dizer que ele erra menos ele é melhor certo então ele pode ter um efeito sobre o viés normalmente acontece isso né que a gente tem como eu mostrei no exemplo embora ali não fosse um Bootstrap mas era uma amostragem então sim eu posso ter um efeito também sobre o viés ou seja melhorar o meu desempenho ao diminuir meus erros mas isso não é o foco da metodologia ou seja ele não foi uma samba um oposto para atuar na redução do viés ele foi um samba proposto para atuar na redução da variância Tá mas eventualmente o que acontece é que a gente observa também um desempenho melhor do ponto de vista de viés de menor viés certo alguma dúvida ok E aí só eu vou eu vou falar do próximo algoritmo porque ele tem uma ele tem uma relação muito forte com bag então só para a gente aproveitar nossa linha de raciocínio antes do nosso intervalo tá então o Berg ele foi algoritmo muito bem sucedido ele ainda é muito usado vocês vão ver que a gente tem essa implementação no site plano e a partir do Berg surgiu um outro algoritmo que talvez muitos de vocês já devem ter ouvido falar que são florestas aleatórias tá então como a gente tá falando de Floresta aleatória como a gente tá falando de florestas aleatórias acho que já fica claro para vocês que a base desse algoritmo são árvores né árvore de decisão Então a gente vai ver que Floresta aleatórias é uma modificação do algoritmo bag em que o algoritmo base para cada um dos

- *Corpus ID:* 1332
- *Score:* 0.8587703108787537
- *URL:* oculto
- *Início:* 00:18:32
- *Fim:* 00:20:41
- *Transcrição:* modelos que só vão conseguir gerar sei lá a linha verde vermelha outros modelos que só conseguiriam gerar a linha azul outro só a linha laranja então assim diz respeito a algumas alguns modelos não podem ser alcançáveis não são alcançáveis com determinado algoritmos então isso Isso é uma questão e a outra na verdade falei as duas coisas juntos ele tanto causa preferência né quanto ele restringe esse conjunto de hipótese então eventualmente Eu tenho um conjunto de dados que o padrão daquele conjunto de dados não pode ser descrito por uma rede neural uma rede neural não ter capacidade por exemplo tá não tô falando do aprendizado profundo mas uma rede neural mais clássica não tem a capacidade mas ele pode ser modelado por um sei lá uma arte de decisão um nariz bem Então existe essas questões o viés indutivo ele limita aquilo que o algoritmo pode representar E aí eu vou falar para vocês o viés de representação tá eu trouxe aqui dois exemplos que são bem fáceis de analisar e a gente também falou do exemplo de neve-bay tá Então veja a representação é como o algoritmo representa o conhecimento né internamente Então esse formalismo usado por exemplo redes neurais a representação do conhecimento é uma série de pesos associadas as conexões certo que é o que ele vai aprendendo né E esse conjunto de peso sei o que faz com que o algoritmo consiga por exemplo pegar uma entrada para pagar né E aí enfim gerar uma saída para uma qualquer entrada já uma árvore de decisão a representação dela é através de regras certo então aqui eu tenho um nó que vai tomar uma decisão Então se esse alto nunca a previsão é ensolarado enfim nublado ou chuvoso ele vai tomar seguir por esse caminho então se for ensolarado vem para cá se a humildade for alta vem para cá e aqui

- *Corpus ID:* 1331
- *Score:* 0.8587597608566284
- *URL:* oculto
- *Início:* 00:17:03
- *Fim:* 00:19:07
- *Transcrição:* diferença se deve ao viés indutivo de cada algoritmo tá a gente vai falar desse conceito e a medida que a gente for vendo diferentes algoritmos vai ficar claro para vocês como esses algoritmos internamente funcionam de forma diferente tá isso se deve a um conceito que é chamado de viés indutivo o viés indutivo de um algoritmo ele tem duas componentes é o viés representação Como que o algoritmo representa um conhecimento para poder aprender gerar o seu modelo e um viés de busca ou seja como é que ele parte de uma solução por exemplo chega até faz a busca por possíveis solução soluções para achar aquele modelo que melhor mapeia entrar de saída por exemplo tá então quando a gente tem esse viés indutivo são todas essas suposições implícitas ou explícitas que o algoritmo assume que permite que ele aprenda o viésimo do tipo Pode parecer uma coisa ruim né enfim ah tem suposições né que vão vão fazer com que ele consiga aprender alguns tipos de hipóteses e outros não mas ele é algo necessário para o aprendizado Então são essas suposições que tem dizem respeito a como ele vai representar o conhecimento e como ele vai buscar o modelo como ele vai ajustar os seus parâmetros enfim e a consequência disso tá é que o viés do tipo de um algoritmo ele causa preferência sobre o subconjunto de potes ou seja pensando nesse gráfico aqui vai ter modelos que só vão conseguir gerar sei lá a linha verde vermelha outros modelos que só conseguiriam gerar a linha azul outro só a linha laranja então assim diz respeito a algumas alguns modelos não podem ser alcançáveis não são alcançáveis com determinado algoritmos então isso Isso é uma questão e a outra na verdade falei as duas coisas juntos ele tanto causa preferência né quanto ele restringe esse conjunto de hipótese

- *Corpus ID:* 2055
- *Score:* 0.8567348718643188
- *URL:* oculto
- *Início:* 00:07:56
- *Fim:* 00:10:13
- *Transcrição:* e eu vou mostrar um processo para vocês um exemplo né que foi tirado de um livro de referência sobre o que seria essa ideia toda bucho usando um modelo de Alto viés tá E aqui eu vou assumir como modelo de auto viés um modelo que tem uma fronteira linear e paralelo aos eixos certo então só para lembrar enfatizei isso né que eu acho que é um ponto importante da da Boost é que esse efeito do ajuste de pesos como eu vou aumentando né o peso das instâncias que foram erradas diminuindo o peso das distâncias que foram corretamente classificadas ou preditas a ideia é que os exemplos mais difíceis vão ser aquele sempre com maior peso então cada novo classificador vai sempre tender a focar no aprendizado desses exemplos dessas instâncias mais difíceis Então vamos para o exemplo Vamos pensar o seguinte tá aqui eu tenho meus dados de Treinamento as classes Enfim então representados como positivos e negativa e o tamanho da instância Vai representar o peso associado essa Instância tá então todos têm o mesmo tamanho aqui certo tanto negativas quanto positivo tem esse tamanho Porque inicialmente Todas têm o mesmo peso aí vamos supor que o treino um modelo com alto viés o modelo com alto viés Aqui tá um exemplo como eu falei um modelo linear por exemplo tá se vocês lembrarem um modelo que a gente viu que pode gerar uma fronteira de decisão assim é uma árvore de decisão com profundidade de um se eu tiver uma digestão com profundidade de um ser que foram né um atributo x 1 e X2 se eu fizer um ponto de corte para X1 menor ou igual Sei lá 0503 eu tenho uma fronteira de decisão neste estilo né linear paralela aos eixos tá então uma árvore de decisão uma poda bem drástica né fazendo com que a profundidade máxima seja um gera essa Fronteira de decisão Poderia gerar né o que que acontece quando o treino esse

- *Corpus ID:* 2897
- *Score:* 0.8548061847686768
- *URL:* oculto
- *Início:* 00:00:02
- *Fim:* 00:02:48
- *Transcrição:* aí tá reiniciando a gravação reiniciada Então vamos para nossa segunda parte da aula 1 deixa eu colocar o preparar o slide aqui no ponto certo onde estávamos anteriormente e vou compartilhar a tela tá então agora a gente tava né que que nós fizemos até então né a gente voltando aqui um pouquinho a gente descobriu né como é que funciona um neurônio artificial né e o primeiro modelo de neurônio que a gente viu é o neurônio com Limiar então tem uma barreira digamos assim né que se o potencial de ativação ultrapassa barreira o neurônio dispara caso contrário né ele não dispara E aí uma em uma releitura dessa modalidade a gente introduziu né um novo termo que é o baias é o baias é uma releitura do Limiar né O negativo dele e aí o nosso neurônio ele o potencial de ativação né o novo potencial de ativação é pesos vezes entradas mais obaias aí quando isso quando esse novo potencial de ativação ultrapassa o zero né então a novo ponto de corte agora é zero aí o neurônio dispara Então esse é o nosso modelo de neurônio artificial né a versão moderna é onde o Limiar foi reinterpretado como baias ou viés Ok E aí uma outra modalidade né nessa modalidade o neurônio faz uma classificação ou seja qualquer entrada que vier quaisquer números que vierem aqui né no x1 X2 e X3 qualquer números o neurônio vai mapear eles para ou zero ou um é e outros problemas exigem que a nossa rede neural tem que predizer números E aí tem o neurônio linear que aí a gente tira essa ideia de ponto de corte e simplesmente propaga o potencial de ativação é o potencial de ativação é então wx né o peso vezes entradas mais o viés né E isso aqui é uma reta Então por exemplo se eu configurar o w negativo né obtém essa reta aqui e se ela interceptar o eixo nesse ponto esse aqui é o b é o B positivo obviamente essa é


**Resposta gerada pelo LLM**: O viés pode ser introduzido em um modelo de aprendizado de máquina através de inconsistências nos dados em relação ao fenômeno que representam (2319), por exemplo, dados de crianças com pouco risco para uma doença podem gerar erros sistemáticos, fazendo o modelo achar que crianças têm baixo risco (2319).  Outro fator é a utilização de variáveis que carregam viés, seja de forma explícita ou mascarada (2641).  Modelos podem ser criados com viés se não forem avaliados dados e potenciais vieses (2178), como em um modelo que identifica risco de câncer de mama com boa sensibilidade, mas não funciona para mulheres negras (2178).  O viés também surge das suposições dos modelos (2037, 2038).  Algoritmos possuem viés indutivo, com componentes de representação e busca, que causam preferência sobre um subconjunto de hipóteses (1331, 1332).

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should address how bias can be introduced in a machine learning model comprehensively. Supporting Evidence: The RESPONSE effectively discusses multiple ways bias can be introduced in machine learning models, including inconsistencies in data, the use of biased variables, lack of evaluation of data and biases, and assumptions made by models. Each point directly relates to the PROMPT's inquiry about the introduction of bias, providing a thorough explanation of the mechanisms involved. Therefore, it addresses the entire PROMPT comprehensively.  Score: 3


---
