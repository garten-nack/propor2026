**Pergunta 95**: O que é viés em aprendizado de máquina?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2178
- *Score:* 0.8652434945106506
- *URL:* oculto
- *Início:* 00:24:42
- *Fim:* 00:26:45
- *Transcrição:* desenvolvimento dos modelos e nesse ponto tá incluso né A questão da gente avaliar os dados perceber se a gente tem potenciais vieses enfim a gente acaba criando modelos com viés Então o que a gente tem que ver é que o nosso modelo ele não pode se cumprir com o nosso objetivo da tarefa de aprendizado de máquina né claro que a gente quer fazer isso aí mas isso não é a única questão a gente tem que garantir que ele não tenha implicações sociais negativas porque por exemplo se eu falando Aquele modelo que eu comentei do risco de câncer de mama se eu fizer um modelo consegue identificar precocemente o risco de câncer de mama com uma acurácia vou falar curaça né ou uma sensibilidade melhor uma boa sensibilidade mas esse modelo não funciona para mulheres negras ele tem uma implicação social negativa porque ele está discrimido mulheres negras e não permitindo que elas tenham por exemplo um tratamento precoce tenho mais chances de se recuperar da doença e isso a gente sabe que acontece muito ainda tá eu coloquei um exemplo né mas a gente sabe que acontece muito isso então quando falo vieses né um viés é uma tendência associada ao determinado por um fator externo que não deveria implicar na decisão do modelo por exemplo nessa questão do risco da doença dependendo se eu não tô avaliando o background genético das pessoas eu tô avaliando outras questões como uma biópsia enfim não deveria estar ponderando né idade enfim não deveria estar sendo sendo impactado Ou seja eu ter um sistematicamente um desempenho pior para determinados grupos de pessoas tá então em aprendizado de máquina quando a gente fala que a gente tem vezes é porque a gente faz o modelo tá fazendo predições injustas ele tá privilegiando um grupo em relação aos outros então por exemplo poderia estar privilegiando mulheres

- *Corpus ID:* 2319
- *Score:* 0.8536010980606079
- *URL:* oculto
- *Início:* 00:07:43
- *Fim:* 00:09:43
- *Transcrição:* para realizar as predições no mundo real dados com o menor viesse possível tá então viés aquela inconsistência que a gente tem dos dados em relação ao fenômeno que ele que ele representa tá a gente comentou um pouquinho sobre essa questão dos vieses né que eles podem gerar esses erros sistemáticos por exemplo se eu tenho dado um conjunto de dados com dados de crianças que tem pouco risco para uma determinada doença e aí isso fora digamos assim um certo viés por uma questão de coleta de dados eu posso estar gerando erros sistemático no meu modelo meu modelo ele cistematicamente vai achar que crianças têm medo risco para aquela doença porque na nossa amostra é o que está representado a gente tem muito menos crianças doentes né proporcionalmente do que adultos doentes isso pode ser verdade como pode não ser então o que a gente tem que ver se esse erro você se vi essa pessoa incorporado Pelo modelo ele chega a prejudicar algum grupo específico ou indivíduo tá então ele tem que ser livre de viés né preferencialmente tá o outro ponto é que os rótulos no caso de aprendizados pelo seu lado que a gente está discutindo os rótulos sejam categóricos ou numéricos idealmente não devem ser resultados de um outro modelo de aprendizado de máquina devem ser rotulados de forma independente por especialistas enfim ou com algo que parte do domínio não da máquina né Claro porque às vezes é parte desses rótulos são acabam sendo rotulados por aprendizado de máquina se a gente tiver falando de aprendizado que a gente chama de sempre supervisionado que não é exatamente o que a gente discute aqui onde eu tenho parte dos dados do outro lado parte não do outro lado o que a gente faz normalmente aprender o modelo a partir dos dados do outro lado e aplicar esse modelo dos dados do outro

- *Corpus ID:* 1331
- *Score:* 0.8534904718399048
- *URL:* oculto
- *Início:* 00:17:03
- *Fim:* 00:19:07
- *Transcrição:* diferença se deve ao viés indutivo de cada algoritmo tá a gente vai falar desse conceito e a medida que a gente for vendo diferentes algoritmos vai ficar claro para vocês como esses algoritmos internamente funcionam de forma diferente tá isso se deve a um conceito que é chamado de viés indutivo o viés indutivo de um algoritmo ele tem duas componentes é o viés representação Como que o algoritmo representa um conhecimento para poder aprender gerar o seu modelo e um viés de busca ou seja como é que ele parte de uma solução por exemplo chega até faz a busca por possíveis solução soluções para achar aquele modelo que melhor mapeia entrar de saída por exemplo tá então quando a gente tem esse viés indutivo são todas essas suposições implícitas ou explícitas que o algoritmo assume que permite que ele aprenda o viésimo do tipo Pode parecer uma coisa ruim né enfim ah tem suposições né que vão vão fazer com que ele consiga aprender alguns tipos de hipóteses e outros não mas ele é algo necessário para o aprendizado Então são essas suposições que tem dizem respeito a como ele vai representar o conhecimento e como ele vai buscar o modelo como ele vai ajustar os seus parâmetros enfim e a consequência disso tá é que o viés do tipo de um algoritmo ele causa preferência sobre o subconjunto de potes ou seja pensando nesse gráfico aqui vai ter modelos que só vão conseguir gerar sei lá a linha verde vermelha outros modelos que só conseguiriam gerar a linha azul outro só a linha laranja então assim diz respeito a algumas alguns modelos não podem ser alcançáveis não são alcançáveis com determinado algoritmos então isso Isso é uma questão e a outra na verdade falei as duas coisas juntos ele tanto causa preferência né quanto ele restringe esse conjunto de hipótese

- *Corpus ID:* 2037
- *Score:* 0.8474782705307007
- *URL:* oculto
- *Início:* 01:23:28
- *Fim:* 01:25:30
- *Transcrição:* permitir que vocês variam esse modelo se vocês quiserem agora uma coisa que vai chamar atenção de vocês que vocês vão ver é que a própria implementação desse método por exemplo não permite né pelo menos eu não sei uma forma de fazer de usar diferentes algoritmos para treinar esses modelos então a gente foi o que eu falei a gente varia os dados mas não varia o algoritmo tá o algoritmo Ele é o único certo entre todos os modelos e o behrin ele é um uma samba o que a proposta dele é reduzir a variância desses modelos então ao agregar esses diferentes modelos que são treinados com algoritmos instáveis Ou seja que tendem a ter uma variância alta em função de mudança nos dados A ideia é que o bag em possa reduzir essa variância né como se ele tivesse eu coloquei entre aspas aqui a média porque na classificação obviamente a gente não tá pegando a média mas basicamente ele reduz essa variância de desempenho que a gente tem quando usa esse tipo de modelo né em função de variações nos dados tá quando tem algoritmos com alto viés por exemplo uma regressão logística e baixa variância não tem um benefício Claro de usar backing ou seja o bem ele foi desenhado pensado para ser trabalhado junto com algoritmo de alta variância não quer dizer que eu não posso usar com algoritmos que tenha baixa a variância mas talvez o efeito benefício de eu melhorar o desempenho né ao reduzir a variância não vai ter porque eu não tenho alta variância no modelo base tá e o viés que é o erro os erros de predições que surgem da suposições dos modelos o viés desse classificador lançando o que a gente chama desse bag ele pode vir a ser menor que os classificadores bases então o viés menor quer dizer que ele erra menos ele é melhor certo então ele pode ter um efeito sobre o viés normalmente acontece isso né que a gente tem como eu mostrei no

- *Corpus ID:* 2038
- *Score:* 0.8473840951919556
- *URL:* oculto
- *Início:* 01:24:59
- *Fim:* 01:27:08
- *Transcrição:* tenho alta variância no modelo base tá e o viés que é o erro os erros de predições que surgem da suposições dos modelos o viés desse classificador lançando o que a gente chama desse bag ele pode vir a ser menor que os classificadores bases então o viés menor quer dizer que ele erra menos ele é melhor certo então ele pode ter um efeito sobre o viés normalmente acontece isso né que a gente tem como eu mostrei no exemplo embora ali não fosse um Bootstrap mas era uma amostragem então sim eu posso ter um efeito também sobre o viés ou seja melhorar o meu desempenho ao diminuir meus erros mas isso não é o foco da metodologia ou seja ele não foi uma samba um oposto para atuar na redução do viés ele foi um samba proposto para atuar na redução da variância Tá mas eventualmente o que acontece é que a gente observa também um desempenho melhor do ponto de vista de viés de menor viés certo alguma dúvida ok E aí só eu vou eu vou falar do próximo algoritmo porque ele tem uma ele tem uma relação muito forte com bag então só para a gente aproveitar nossa linha de raciocínio antes do nosso intervalo tá então o Berg ele foi algoritmo muito bem sucedido ele ainda é muito usado vocês vão ver que a gente tem essa implementação no site plano e a partir do Berg surgiu um outro algoritmo que talvez muitos de vocês já devem ter ouvido falar que são florestas aleatórias tá então como a gente tá falando de Floresta aleatória como a gente tá falando de florestas aleatórias acho que já fica claro para vocês que a base desse algoritmo são árvores né árvore de decisão Então a gente vai ver que Floresta aleatórias é uma modificação do algoritmo bag em que o algoritmo base para cada um dos

- *Corpus ID:* 2641
- *Score:* 0.8462212681770325
- *URL:* oculto
- *Início:* 00:41:07
- *Fim:* 00:43:06
- *Transcrição:* que é mais explícita assim para esse caso né então não nem sempre é fácil identificar as variáveis que estão carregando esse viés mas mas seria o ideal a gente tentar identificar seja por um conhecimento prévio seja por uma análise protória dos dados seja usando algumas métricas que a gente tem métricas que tentam analisar o potencial de baias antes do treinamento né o potencial de várias carregado por cada variável mas tudo isso do ponto de vista de métricas de métodos para tratar esse tipo de problema ou evitar ou tratar ainda são coisas em desenvolvimento tem bastante coisas já que foi desenvolvida que está sendo usada mas a gente pode dizer sim o problema ainda não tá 100% resolvido sabe ainda tem muito do ponto de vista de pesquisa e desenvolvimento para ser feito para realmente tornar algoritmos mais seguros em relação a isso mas de fato uma possibilidade seria isso identificar esses riscos de viés nos dados e tirar essas variáveis que carregam esse viés seja de uma forma bem explícita né ou seja dessa forma mais mascarada assim então não é uma tarefa muito fácil e a gente só consegue Observar isso imagino eu nos modelos interpretáveis e isso ou usando técnicas para interpretar os modelos né a prioridade seria usar o modelo interpretável tá E seria prioridade porque a gente consegue ver exatamente que o modelo tá aprendendo as outras técnicas a gente usa recursos para tentar estimar né Essas associações ou essas essas associações do ponto de vista né do que que tá explicando uma saída então quando a gente Depende de um outro método para compreender o nosso modelo a gente sempre fica refém do que esse método faz né E até que ponto ele consegue de fato encontrar isso né Então realmente os modelos interpretáveis eles

- *Corpus ID:* 2182
- *Score:* 0.845123827457428
- *URL:* oculto
- *Início:* 00:31:09
- *Fim:* 00:33:19
- *Transcrição:* interessante Ah tem uma pergunta deixa eu passar a Caroline Pode falar É o seguinte é sobre essa questão de vieses né como você tinha comentado pode vir da coleta dos dados e pode ser amplificado pelo algoritmo pode acontecer o caso de a gente ter o dado balanceado ou seja coleta foi bem feita e ainda assim o algoritmo ter esse viés acertar mais para um tipo de classe do que para outro pode acontecer pode acontecer porque às vezes a gente olha a distribuição de um atributo né Por exemplo a classe ou por exemplo quero ver seu atributo ali borracha ou idade o gênero tá mais ou menos equilibrado né às vezes mesmo que ele esteja equilibrado o que o algoritmo vê né na maioria dos algoritmos de uma forma muito clara é um padrão entre atributos E aí isso isso pode estar causando nessas diferenças por exemplo eu tenho alguns padrões que eu tenho daqueles daquelas combinações de atributos eu tenho muito mais exemplos torna mais fácil aprender aquele Exemplo né E às vezes tem o que a gente chama essas variáveis que são relacionadas assim por exemplo tem um caso bem famoso de um algoritmo que era usado para atribuir risco de saúde no sistema usado nos Estados Unidos e aí teve uns pesquisadores que acharam que o algoritmo ele prejudicava pessoas negras então se eu tinha uma pessoa branca uma pessoa negra com os mesmos sintomas a pessoa branca era atribuído um risco maior então no processo de triagem ela tinha preferência E aí foram observar que o problema é porque tinha outras informações ali dentro que eram enviesadas Entre esses grupos que o algoritmo tava entendendo né que havia essa diferença e essa informação era custos com saúde Então como as pessoas a população Branca tinha mais custos com saúde né e ele esse custo com saúde era usado como proxy uma

- *Corpus ID:* 1332
- *Score:* 0.8439992070198059
- *URL:* oculto
- *Início:* 00:18:32
- *Fim:* 00:20:41
- *Transcrição:* modelos que só vão conseguir gerar sei lá a linha verde vermelha outros modelos que só conseguiriam gerar a linha azul outro só a linha laranja então assim diz respeito a algumas alguns modelos não podem ser alcançáveis não são alcançáveis com determinado algoritmos então isso Isso é uma questão e a outra na verdade falei as duas coisas juntos ele tanto causa preferência né quanto ele restringe esse conjunto de hipótese então eventualmente Eu tenho um conjunto de dados que o padrão daquele conjunto de dados não pode ser descrito por uma rede neural uma rede neural não ter capacidade por exemplo tá não tô falando do aprendizado profundo mas uma rede neural mais clássica não tem a capacidade mas ele pode ser modelado por um sei lá uma arte de decisão um nariz bem Então existe essas questões o viés indutivo ele limita aquilo que o algoritmo pode representar E aí eu vou falar para vocês o viés de representação tá eu trouxe aqui dois exemplos que são bem fáceis de analisar e a gente também falou do exemplo de neve-bay tá Então veja a representação é como o algoritmo representa o conhecimento né internamente Então esse formalismo usado por exemplo redes neurais a representação do conhecimento é uma série de pesos associadas as conexões certo que é o que ele vai aprendendo né E esse conjunto de peso sei o que faz com que o algoritmo consiga por exemplo pegar uma entrada para pagar né E aí enfim gerar uma saída para uma qualquer entrada já uma árvore de decisão a representação dela é através de regras certo então aqui eu tenho um nó que vai tomar uma decisão Então se esse alto nunca a previsão é ensolarado enfim nublado ou chuvoso ele vai tomar seguir por esse caminho então se for ensolarado vem para cá se a humildade for alta vem para cá e aqui

- *Corpus ID:* 1989
- *Score:* 0.842780590057373
- *URL:* oculto
- *Início:* 00:04:24
- *Fim:* 00:06:36
- *Transcrição:* classificação que obviamente tão estruturadas numa árvore né que são os testes em cadeados e eles têm diferentes estratégias para buscar a melhor Fronteira de decisão né A forma como os algoritmos determina essa Fronteira né que esse limite para tomar uma decisão a respeito de uma classe né então ou até mesmo a respeito de um valor numérico né uma regressão são feitos com base na estratégias diferentes então isso faz com que para um novo problema eu tenho que definir qual é o melhor algoritmo ou primeiro o melhor conjunto de algoritmos para explorar e depois de qual é o melhor usando experimentação análise experimental certo avaliação de modelos treinamento e avaliação de modelos E aí existe uma coisa bem importante Opa só voltando aqui uma coisa bem importante sobre os erros dos modelos tá os modelos preditivos a gente diz que os erros eles são decompostos em duas componentes direitos componentes principais mas não se confundam com análise componentes principais né com duas componentes né viés e variância tá aí já vou explicar esse trade off entre eles mas o viés diz respeito a um erro que deriva de suposições desse algoritmo que são suposições erradas digamos assim que fazem com que o algoritmo não consiga realizar predições que sejam próximas as predições esperadas certo então a gente diz que um algoritmo com alto viés ele adota muitas suposições por exemplo se eu tiver um algoritmo a gente não falou na disciplina mas uma regressão logística Vocês ainda vão ver na disciplina de redes sociais profundo é uma um algoritmo que a suposição é que o problema pode ser dividido como a fronteira linear assim como svm linear né a gente viu um modelo linear então se a minha Fronteira não for linear eu vou ter uma suposição muito forte sobre esse problema o meu modelo vai ser incapaz de

- *Corpus ID:* 1320
- *Score:* 0.8419984579086304
- *URL:* oculto
- *Início:* 00:00:03
- *Fim:* 00:02:02
- *Transcrição:* ei pessoal então desculpa aí vamos Vamos recomeçar aqui então a gente falou né bastante até agora sobre a questão do QI onde é que se encaixa pintado de máquina O que é aprendizado de máquina né do ponto de vista de capacidade de aprendizado ali dentro da em relação uma e a mais clássica né e a simbólica a questão do uso de aprendizado de máquina como uma ferramenta eu vou chamar assim né importante para a parte de ciência de dados agora vou falar um pouquinho mais entrar um pouquinho mais a parte de aprendizado de máquina para a gente entender assim um pouco melhor o que que é o aprendizado de máquina né como uma como uma área do conhecimento e depois a gente vai falar um pouquinho sobre a questão das tarefas principais ele classificação e regressão tá disciplina em si muitas outras coisas que eu vou falar para vocês hoje a gente vai repetir elas ao longo do curso tá então Não se preocupem é claro tirei em dúvidas né a vontade mas não se preocupem se algumas coisas ficarem Claras porque elas vão a gente vai discutindo nessa medida que a gente for estudando os algoritmos especificamente Tá mas eu gosto de contextualizar essa parte mais geral antes da gente falar de questões específicas tá que seria os algoritmos então quando a gente está falando de aprendizado de máquina então a gente quer aprender a partir dos dados né fazer com que os métodos programas sejam capazes de aprender a partir dos dados ao invés de serem explicitamente programados para resolver uma tarefa tá então de aprendizado de máquina está falando de um processo de indução de hipótese a partir da experiência passada essa experiência passada elas são os dados né e a gente normalmente trabalha mas tem um conjunto de dados representativos são os nossos exemplos ali nossas instâncias


**Resposta gerada pelo LLM**: Viés em aprendizado de máquina é uma tendência associada a um fator externo que não deveria influenciar a decisão do modelo, levando a predições injustas e privilegiando um grupo em relação a outros.  Pode originar-se na coleta de dados ou ser amplificado pelo algoritmo, mesmo com dados balanceados.  Um modelo com viés pode gerar erros sistemáticos, prejudicando grupos específicos.  O viés indutivo de um algoritmo, por exemplo,  influencia como ele representa o conhecimento e busca soluções, limitando os modelos alcançáveis.  O viés também se refere a erros de predição decorrentes de suposições incorretas do modelo.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should provide relevant context to all parts of the PROMPT regarding the concept of bias in machine learning. Supporting Evidence: The RESPONSE directly addresses the PROMPT by defining what bias is in the context of machine learning. It explains how bias can arise from external factors, data collection, and algorithmic amplification, which are all relevant aspects of the concept. Additionally, it discusses the implications of bias, such as unfair predictions and systematic errors, which further enriches the understanding of the topic. The RESPONSE is comprehensive and covers multiple facets of bias, making it highly relevant to the entire PROMPT.  Score: 3


---
