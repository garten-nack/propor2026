**Pergunta 90**: Quais são as etapas envolvidas no desenvolvimento de um modelo de machine learning, desde a preparação dos dados até a implantação e monitoramento? 

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2314
- *Score:* 0.8751413226127625
- *URL:* oculto
- *Início:* 00:00:04
- *Fim:* 00:02:18
- *Transcrição:* ok pessoal então bom dia a todos vamos dar início então a essa semana dessa disciplina de metodologia de aprendizados supervisionado onde a gente vai começar a falar sobre o processamento de dados tá então na semana passada a gente falou sobre a parte de avaliação de modelos Claro que não é um assunto encerrado né conforme vocês tenham dúvidas a gente a gente pode discutindo a gente pode detalhar algumas coisas a mais em momentos de aula pelo fórum e é uma coisa que vocês vão usar ao longo da disciplina tá E de outras questão de avaliação de modelos certo só que a disciplina ela também tem uma ideia de discutir a parte para processamento de dados né então hoje a gente vai fazer uma introdução a esse tema e a gente vai falar sobre diferentes tarefas envolvidas nessa parte de limpeza e transformação de dados tá então a primeira etapa para processamento comentando assim alguns problemas comuns algumas soluções comuns tá é difícil né já adiantando nessa área a gente a gente dá uma receita de bolo né dizer Olha dessa situação esse tipo de solução melhor nessa situação esse tipo de solução é melhor eu tento trazer dicas para vocês Tá mas digamos assim nada que a gente pode afirmar que uma solução ou outra é a melhor a gente vai precisar realmente dependendo dos dados do contexto fazer essa essa avaliação Tá bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou

- *Corpus ID:* 2315
- *Score:* 0.8713281750679016
- *URL:* oculto
- *Início:* 00:01:45
- *Fim:* 00:03:41
- *Transcrição:* bom eu não sei se você chegaram a dar uma olhada no material que eu deixei como material complementar a disciplina que essa check list de projeto de aprendizados de máquina né a gente está falando agora dessa questão de preparar os dados para tarefa de aprendizado de máquina Lembrando que sempre a gente tem essa ideia de separar um conjunto de teste e é importante a gente enfatizar que tudo que a gente vai fazer no conjunto de Treinamento ou quase tudo eu diria quase tudo a gente também tem que fazer o conjunto de teste tá então as etapas que a gente vai discutir hoje de limpeza do conjunto de Treinamento praticamente todas a gente tem que replicar no conjunto de teste tá tem outras conforme a gente for avançando eu vou comentando com vocês o que que a gente não faz no conjunto de teste porque tem algumas questões que a gente realmente não é adequado a gente fazendo o conjunto de teste bom E aí lembrando também que a gente falou na nossa aula introdutória que quando a gente está falando de desenvolvimento de modelos de aprendizado de máquina está falando de uma metodologia envolvida né e diversos Passos Então as nossas decisões a respeito dessa metodologia é o que é decisões a respeito de cada passo é o que define a nossa metodologia do ponto de vista de pré-processamento a gente tem tanta parte de decisões da coleta e preparo dos dados Então quais são os atributos como é que vou transformar esse atributos como é que eu vou particionar os dados para desenvolver o modelo né treinar validar otimizar e preparamos como é que eu vou lidar com valores faltantes enfim tá E também a parte de engenharia de atributos Então a gente vai estar discutindo um pouquinho essas etapas iniciais esse processo de preparar os dados

- *Corpus ID:* 2316
- *Score:* 0.8653126358985901
- *URL:* oculto
- *Início:* 00:03:12
- *Fim:* 00:05:14
- *Transcrição:* coleta e preparo dos dados Então quais são os atributos como é que vou transformar esse atributos como é que eu vou particionar os dados para desenvolver o modelo né treinar validar otimizar e preparamos como é que eu vou lidar com valores faltantes enfim tá E também a parte de engenharia de atributos Então a gente vai estar discutindo um pouquinho essas etapas iniciais esse processo de preparar os dados e a gente também falou da nossa introdução que existe esse level aprendizado de máquina que que diz que se eu tiver garba jeans garba de alto né então tudo que eu pretendo fazer com o meu modelo de aprendizado de máquina de metodologia não vai ser tão boa quanto forem é só te será tão bom quanto foi os meus dados então a gente precisa prestar muita atenção nessa etapa dos dados de preparar os dados para ter dados que sejam mais digamos assim limpos e utilizáveis né o seu valor mais facilmente explorável pelos modelos de aprendizado de máquina tá Então acho que vocês lembram né que a gente discutiu e realmente existe a estimativa que a gente gasta boa parte do nosso tempo nessa etapa de preparar os dados o que que são bons dados e aprendizados de máquina Tá eu vou passar por alguns pontos aqui porque acho que é bom a gente ter uma ideia quando a gente fala que a gente quer tomar os ossos dados melhores para serem mais facilmente explorados pelos modelos é bom a gente pensar em algumas características do que são bons dados tá então primeiros são Dados que são informativos ou seja são Dados que possuem características descritas das atributos dos dados tanto em quantidade quanto o nível de gravidade suficiente para aquele problema que eu tô querendo abordar de pressão então

- *Corpus ID:* 2138
- *Score:* 0.8649979829788208
- *URL:* oculto
- *Início:* 00:52:57
- *Fim:* 00:55:13
- *Transcrição:* então foi o foco né que a gente a gente discutiu essa questão do treinamento do modelo ou seja diferente dos as diferenças algoritmos a gente falou um pouquinho de avaliação Tá mas não é suficiente para garantir bons modelos né a gente vai discutir mais na disciplina CD 004 que é de metodologia de aprendizado de máquina o quão importante a preparação dos dados é extremamente importante e na maioria das vezes não sei se acho que aqui no projeto vocês não vão ter o tempo de sentir isso por conta do direcionamento do projeto mas essa questão de preparação de dados que é o que tá destacado aqui é o que consome mais tempo no processo de desenvolvimento de modelos mais tempo de vocês ou de quem tiver desenvolvendo vai ser aqui né se não me engano é 70% do tempo 80% do tempo teclado tem algumas estimativas que que variam né mas assim é absurda a diferença do tempo que vocês vão gastar preparando os dados Claro que tem um tempo de execução né talvez treinar um modelo se eu tô usando aprendizado profundo pode levar um tempo mas é um tempo computacional não é um tempo humano né não é o nosso tempo então a gente vai dar continuidade a nossa conversa sobre aprendizado supervisionado né Na próxima disciplina falando um pouquinho mais da preparação de dados tá e falando também um pouco mais a parte de avaliação e comparação de modelos para ir além do que a gente discutiu do roldalto que tem técnicas que são mais adequadas como a validação cruzada tá que a gente vai ver mais detalhes certo uma pergunta até aqui certinho bom pessoal então acho que esses slides estão lá no mudo então eles sumarizam esses pontos mais digamos assim né Acho que as principais mensagens digamos assim que eu gostaria de

- *Corpus ID:* 2189
- *Score:* 0.864443838596344
- *URL:* oculto
- *Início:* 00:42:13
- *Fim:* 00:44:34
- *Transcrição:* dentro dessa etapa né de depois de ter o melhor modelo tem aqui avaliação desse modelo com os dados de teste que não está escrito aqui neste checklist Depois tem apresentação da solução né para quem estiver as partes interessadas enfim né a equipe diretores clientes enfim e aí depois a parte de um deploide monitorar e manter esse sistema rodando esse modelo certo então a gente Claro a gente vai discutir um pouquinho mais na disciplina sobre essa questão de preparar os dados dessas divisões de dados da questão de ajuste finos dos modelos né então são coisas que a gente que a gente vem comentando e a gente vai aprofundar tá então alguns tópicos da disciplina né tem que ser correção ou remoção de Alto layers imputação de valores faltantes né então quando tem instâncias que não tem valores para alguns atributos transformação normalização de atributos redução de personalidade diminuiu o número de atributos seja por seleção de atributos ou por extração que aqui a gente vai ver o PCA ajuste de balanceamento de classes depois da parte de Treinamento ajuste fino os modelos a estratégia de avaliação de modelos métricas de desempenho comparação de modelos preditivos aqui também entra a parte de otimização de preparamos e alguma pelo menos uma uma introdução digamos assim e discussão de alguns métodos voltados para interpretação dos modelos tá ou seja tentar entender quem que levou o modelo tomar determinada decisão para aquela pessoa para aquele cliente para aquele paciente enfim certo então algumas coisas que a gente vai discutir são vários tópicos né Vocês podem imaginar assim que a minha ideia alonga disciplina é trazer algumas possibilidades para todas essas esses problemas digamos assim para

- *Corpus ID:* 2162
- *Score:* 0.8632358312606812
- *URL:* oculto
- *Início:* 00:00:06
- *Fim:* 00:02:01
- *Transcrição:* Então tá pessoal Bom dia nem Bom dia a todos vamos dar início hoje a disciplina quarta disciplina do curso né a última desse módulo primeiro módulo que seria a metodologia de aprendizados previsionado tá vocês vão ver que muitas das coisas que a gente discutiu um pouquinho vou compartilhar minha tela aqui na disciplina de aprendizado supervisionado Muitas das coisas que a gente discutiu né que a gente tocou em alguns pontos elas vão surgir quem mais detalhes tá e muitos as coisas que a gente vai falar aqui vão ser úteis para outras disciplinas que vocês vão discutir por exemplo aprendizado não supervisionado né ela também demanda para processamento de dados aprendizado profundo redes neurais também demanda alguns para processamentos né E até a parte da metodologia de desenvolvimento do modelo no sentido de validação dos modelos é um dos pontos que a gente que é bem importante e vai ser um dos pontos iniciais da nossa discussão né até aproveitando para consolidar assim um pouco esse conhecimento que vocês têm praticado no projeto da disciplina anterior né E então acho que vai ser vai ser interessante porque na disputa anterior a gente tocou nesse assuntos repetido em alguns exemplos Mas a gente não chegou a aprofundar tanto isso tá então a ideia da aula de hoje é a gente primeiro introduzir um pouco o que que essa metodologia de aprendizados introduzir disciplina né a gente tá fazendo uma mudança de contexto como a gente comentou aqui a gente tá agora falando de uma outra disciplina né embora mesmo professora então vou fazer uma apresentação da disciplina introdução ao tema E aí depois a gente vai falar sobre a primeira parte de avaliação de modelos preditivos que são estratégias de

- *Corpus ID:* 3401
- *Score:* 0.8617237210273743
- *URL:* oculto
- *Início:* 00:05:23
- *Fim:* 00:07:36
- *Transcrição:* esperar né Por exemplo Tá eu vou fazer uma analogia aqui que é o Andrew um ele escreveu um livro né que é machine learning eu acho até que tem esse eu sinto isso no no slide aqui mas já vão antecipar que a ideia é assim ó ele o caso de uso que ele cita né O Causo né digamos assim que a pessoa tá lá fazendo um aplicativo né de reconhecimento de sei lá de raça de gatos e aí pega um monte de gato da internet imagem fase todo o processo aqui né de coleta de dados E aí enfim passa por todas as etapas E aí chega no final aqui no feature e consegue fazer né o modelo E aí dá tudo certo né e agora que solta o aplicativo lá no na Play Store E aí pessoa começa a baixar e começa a vir uma estrela uma estrela todo mundo reclamando reclamando reclamando que o aplicativo não funciona não classifica direito e tal sendo que aqui nesse momento né a pessoa tava testando lá e tava com a curaça super boa detectava todas as raças de gato muito bem e tal e aí na hora que vai ver o que que acontece aqui ó o software foi solto no aplicativo de celular né para as pessoas tirar foto dos gatos e saber né a raça composição etc e só que aí aqui entra foto de celular né não é aquelas fotos bonitinha lá da internet que tinha no data 7 E aí então né os dados Nos quais o aplicação foi liberada não correspondiam né os dados que foram usados aqui então né vai ter que fazer o círculo aqui de novo a coletar dados né Possivelmente dos próprios usuários que fizeram né os do aplicativo e lá retornar o modelo Então essa essa parte né de manutenção faz é bastante sentido né quando se trata de uma aplicação real porque na hora que soltar o troço ali que a gente vai ter né um feedback real de um ambiente real com dados reais né Por mais que tenha sido feito um esforço aqui é na hora da verdade que a gente vai enfrentar ali nas Alô deve ter dado um corte aí perdão

- *Corpus ID:* 2188
- *Score:* 0.8614811897277832
- *URL:* oculto
- *Início:* 00:40:42
- *Fim:* 00:42:51
- *Transcrição:* balanceamento de classe talvez essas análises né de associações entre atributos para ver se a gente acha alguns questões que chamem atenção depois a parte de preparação de dados tá para tarefa de aprendizado de máquina separando um conjunto de teste então percebam que aqui peguei é claro que a gente vai discutir que essa preparação de dados ela às vezes ela pode ser feita com os dados todos né ainda juntos tipo dado original Às vezes a gente tem que fazer separado por treino validação em teste isso a gente vai discutir na disciplina mas eu chamo atenção que nesse ponto 4 já tá destacado separe um conjunto de teste esse conjunto de teste é aquele conjunto que a gente não vai olhar para ele durante todo o processo de desenvolvimento do modelo só lá no final tá depois explorem muitos modelos diferentes seleciona os melhores essa ideia dos algoritmos né então com base nesses dados fazer uma verificação rápida né de que algoritmos parece ser promissores depois para os melhores modelos né faça ajuste fino desses modelos né desses que foram selecionados Então como otimização de parâmetros né e o autor que comenta combine os em uma ótima solução ou seja não deixem de tentar explorar uma abordagem de um samba com esses modelos talvez eles essa abordagem pode ser melhor que os modelos individuais como a gente discutiu certo dentro dessa etapa né de depois de ter o melhor modelo tem aqui avaliação desse modelo com os dados de teste que não está escrito aqui neste checklist Depois tem apresentação da solução né para quem estiver as partes interessadas enfim né a equipe diretores clientes enfim e aí depois a parte de um deploide monitorar e manter esse sistema rodando esse modelo certo então a gente Claro a gente vai discutir um pouquinho mais na disciplina

- *Corpus ID:* 1438
- *Score:* 0.861343264579773
- *URL:* oculto
- *Início:* 00:06:22
- *Fim:* 00:08:26
- *Transcrição:* Qual é o melhor modelo tá então por isso que eu preciso ser capaz de avaliar o desempenho desses modelos só tomar uma água aqui então assim ó essa etapa de validação e seleção de modelos é o que a gente chama né a validação como eu comentei antes etapa de avaliação e selecionar o modelo da determinado todos os modelos que eu treinei com as suas variações de algoritmos de prepararmos Esse é o melhor modelo tá essa é uma etapa extremamente crítica quando eu tô desenvolvendo um modelo tá e a gente vai iniciar nesse assunto de como fazer isso usando uma estratégia como eu falei uma estratégia simples que é o rolda alto mas ela ainda é muito utilizada em alguns alguns casos principalmente o aprendizado profundo que o custo de desenvolver treinar múltiplos modelos é mais alto então ela ainda é utilizada Tá mas depois a gente vai discutir formas de fazer isso com um pouco mais de robustez assim principalmente em relação a variação de desempenho enfim tá mas ela é uma etapa crítica seja se eu não fizer isso bem se não fizer isso usando dados Independentes avaliando bem o desempenho dos meus modelos né as medidas de desempenho certo eu posso estar seleciodo o modelo que não é o melhor então quando a gente está falando de poder generalização eu quero saber isso né como é que o meu modelo se citai né para fazer previsões né o determinar a saída para dados que ele nunca viu tá então a gente tem Normalmente quando a gente faz esse tipo de tarefa a gente tem um conjunto de dados Então olha aqui tá esse conjunto de dados aqui eu gostaria que você treinasse que um classificador vai determinar se um aluno de uma universidade vai desistir ou não do curso tá então amor tem uma base histórica né de alunos forma matriculados de desistências enfim eu quero ser capaz de prever isso para agir

- *Corpus ID:* 2177
- *Score:* 0.8602966666221619
- *URL:* oculto
- *Início:* 00:23:02
- *Fim:* 00:25:13
- *Transcrição:* treinamento do modelo né mas da parte já é essa divisão dos dados dados Independentes treinamento a validação enfim se eu fizer isso de forma Impecável se os meus dados forem muito ruins essa modelagem Impecável do ponto de vista de metodologia ela não salva esses dados ela dificilmente salva esses dados certo então a gente tem que cuidar a gente tem que entender o que que a gente precisa trabalhar em nível de dado né para que a gente possa tentar melhorar esse esse dado aqui que não é não é bom mas a gente também tem que cuidar para que a nossa metodologia do ponto de Treinamento não insira viésis não faço uma avaliação ruim né do ponto de vista de não perceber que tem um overfite tem coisas desse tipo ok e tem a questão da metodologia né do ponto de vista de risco de vieses e esse ponto apareceu um pouquinho naquele notebook que a gente fez né do nave base com dados de risco de doenças cardíacas em que tinha pessoas de diferentes Ali era variável raça né quantificada então e aí chamava atenção o caso ali que por exemplo nós tínhamos não tínhamos asiáticos com registro para doença né cardíaca e a gente discutiu um pouco isso pode ser uma questão de amostra de dados né um viés de amostra enfim a questão é que quando a gente não não Cuida dessa questão metodológica do desenvolvimento dos modelos e nesse ponto tá incluso né A questão da gente avaliar os dados perceber se a gente tem potenciais vieses enfim a gente acaba criando modelos com viés Então o que a gente tem que ver é que o nosso modelo ele não pode se cumprir com o nosso objetivo da tarefa de aprendizado de máquina né claro que a gente quer fazer isso aí mas isso não é a única questão a gente tem que garantir que ele não tenha implicações sociais


**Resposta gerada pelo LLM**: Preparação dos dados (incluindo limpeza, transformação, tratamento de valores faltantes e engenharia de atributos), separação do conjunto de teste, exploração de diversos modelos, seleção dos melhores modelos, ajuste fino dos modelos selecionados, avaliação do modelo com os dados de teste, apresentação da solução, implantação e monitoramento do modelo.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: A resposta deve ser relevante para todas as partes do prompt, abordando as etapas do desenvolvimento de um modelo de machine learning, desde a preparação dos dados até a implantação e monitoramento. Supporting Evidence: A resposta cobre de forma abrangente todas as etapas mencionadas no prompt, começando pela preparação dos dados e incluindo limpeza, transformação, tratamento de valores faltantes e engenharia de atributos. Em seguida, menciona a separação do conjunto de teste, exploração e seleção de modelos, ajuste fino, avaliação, apresentação, implantação e monitoramento. Portanto, a resposta é relevante e responde completamente ao prompt.  Score: 3


---
