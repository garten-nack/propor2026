**Pergunta 138**: O que é um corpus?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 8024
- *Score:* 0.8524911403656006
- *URL:* oculto
- *Início:* 00:50:12
- *Fim:* 00:52:43
- *Transcrição:* exemplo mas não quer dizer que tenha uma inteligência real ali por trás então é o produto da da geração da geração do do do próximo token que a gente vai ver mais adiante então ele não tem conhecimento de de mundo que seria necessário para dizer que tem uma inteligência mais geral ali por trás mas isso é um todo um toda uma polêmica então voltando aqui ao nosso foco que é o o texto primeiro da onde que vem o texto que a gente vai usar a gente vai usar bastante esse termo Corpus Corpus linguístico cujo plural é purpura é o Corpus é um conjunto de texto um conjunto de de textos que a gente pode coletar de vários lugares ã pode ser o de um autor específico ó eu tenho aqui o Corpus do da Obra do Machado de Assis pode ser de um período eu tenho Corpus da época do do Romantismo Ah pode ser de um idioma Eu tenho um Corpus de documentos da Língua Portuguesa pode ser de um gênero específico Então eu tenho o corp que são de Notícias um Corpus literário um Corpus de arquivo de artigos científicos um um Corpus da do gênero da da da Wikipédia ou de algum domínio específico por exemplo eh de da do domínio jurídico ou do domínio da Medicina Então pode pode ser separado por por gêneros também e eh então Corpus a gente vai falar bastante simplesmente texto texto corrido que a gente coleta de ou pega disponível de de algum lugar então a gente falou que os textos Eles não têm ã estrutura né são texto não estruturado Mas eles têm propriedades estatísticas que são bem são bem interessantes e podem ser exploradas Então a primeira dessas propriedades estatísticas é a lei de zif vocês já ouviram falar dessa dessa lei eu não não não não tá então a lei de zif é uma lei empírica Ou seja é uma observação que o George kingsley fez lá nos anos 40 e todo mundo

- *Corpus ID:* 8031
- *Score:* 0.8413865566253662
- *URL:* oculto
- *Início:* 01:04:15
- *Fim:* 01:06:38
- *Transcrição:* ele vai tendendo a estabilizar mas nunca para de de crescer Então à medida que o Corpus aumenta o número de termos novos aumenta muito no início mas mas depois essa taxa de crescimento é menor e novos termos sempre vão aparecer porque vai ter erros de ortografia vai ter nomes próprios vai ter novas palavras aparecendo então a lei de hiips ela vai ter uma ã uma curva mais ou menos assim como a gente tá vendo aqui então no início cresce muito depois vai diminuindo a taxa de crescimento vai estabilizando mas nunca para porque se eu tô aumentando o tamanho do do Corpus eu tô coletando por exemplo H tweets então tô coletando tweets hoje eu coletei 100.000 amanhã mais 100.000 Então essa taxa vai crescer muito muito eh grande vai ser muito impressiote no no início e aí depois ela vai vai diminuindo eh tá então a gente falou dessas duas dessas duas leis eh mas o por que que elas são importantes para para nós por que que elas o que que é útil para pra gente saber eh que existe a lei de zif se vocês lembram lá do do vídeo desse último do Michael do vos que ele que ele mostra a distribuição vocês lembram quais eram as as palavras que apareciam lá no início as mais comuns em inglês isso era artigo preposição era um monte de de palavra que então era Ah é principalmente artigo e e preposição e pronomes ã as O que que a gente aprende daí as palavras mais frequentes elas tendem a não carregar muito significado então se eu quero fazer por exemplo um classificador eu quero classificar documentos em em assuntos ou eu quero classificar um e-mail se é spam ou se não é spam essas palavras muito comuns elas provavelmente não vão nos ajudar porque elas estão em todos os documentos isso isso tem implicações para para alguma coisa que a gente vai

- *Corpus ID:* 8218
- *Score:* 0.8389104604721069
- *URL:* oculto
- *Início:* 00:14:53
- *Fim:* 00:17:30
- *Transcrição:* Corpus é representada por um vetor como a gente viu de tamanho Vector size que corresponde ao número de dimensões Então vamos ver aqui ó tá aqui o vetor Então esse isso aqui tem sem posições e isso aqui é o que a gente vai usar depois para treinar um um classificador como nós fizemos com TF DF na aula passada a gente vai fazer usando esse essa representação aqui esse vetor representa a palavra produto tá então aqui ó olhando por exemplo a gente tem aquele velho problema do assento isso poderia ter sido aplicado na rotina de pré-processamento aquela rotina que eu coloquei lá provavelmente não faz isso né mas eu a palavra água sem acento ela tem uma representação e a água com assento tem outra representação então o ideal Talvez seja que eu junte E aí Claro tem palavras que elas têm significado diferente quando tem o não acento então voltamos a aquela discussão que a gente teve na aula passada salvando as edens treinadas então para salvar a isso aqui salva o modelo tá isso aqui é mais para Ah eu quero continuar o treinamento e esse aqui salva as palavras Então a gente vai salvar esse word.txt aí veja que ele tá aqui ó eu vou até até abrir ele aqui pra gente dar uma olhadinha que ele nada mais é do que um um arquivo TXT com as palavavras índices e os vetores H do lado e ele tem lembra ele tem 13.000 e poucas posições que é 13.905 tá que que é o nosso vocabulário então ele vai ter 13.905 linhas em cada uma dessa linha o índice é a palavra tá demorando hoje eh e as e ó aqui ó deixar aqui né então eu tenho aqui a palavra d i bom Pessoal vocês viram ali né então ele tem a palavra e o vetor ao lado simplesmente isso e isso são os vetores que a gente recebe quando a gente pega vetor pré treinado de outros locais que outras pessoas treinaram a gente usa o

- *Corpus ID:* 8260
- *Score:* 0.8352607488632202
- *URL:* oculto
- *Início:* 00:07:38
- *Fim:* 00:10:17
- *Transcrição:* aí ele vê uns pares de caracteres que que que tem muita frequência dentro de uma palavra E aí vai unir Então vamos ver um exemplo o nosso Corpus é aquele microc Corpus que só tem aqui uma duas H então tem mal males Lar lares e ser então ele tem aqui mal m s m Lar lares e ser E aí ele vai ver o e entre entre parênteses aqui tá vamos supor que seja a frequência de ocorrência de cada palavra no no nosso Corpus então mal acontece cinco vezes males acontece sete vezes e assim por diante Então esse é o ponto de partida um Corpus com as frequências separado em palavras com as frequências de cada palavra aí então a gente vai vai passar pelo passo de combinar aqui um par de apagar isso aqui então Vou combinar um par de caracteres que seja muito frequente o nosso vocabulário base é São só esses caracteres aqui então a gente vê que o par e ele tem uma frequência de 15 porque ele tem sete vezes aqui e ele tem tem oito vezes aqui então ele é um par bem frequente de todos os pares que eu for olhar aqui ele é o par mais frequente para adjacente né tem que ser o e colado no no s Então o que a gente vai fazer agora é adicionar esse token es no nosso no nosso vocabulário então o nosso vocabulário que antes tinha só caracteres únicos agora ele vai ter também esse esse Token composto por pelo e e pelo S então agora o nosso vocabulário tá assim e aí esse processo de criando tokens maiores ele vai vai continuar até que a gente chegue no número de tokens desejado então uma entrada para esse algoritmo é quantos tokens a gente quer ah quantos que usam na prática Ah se usa na prática sei lá 30.000 00 então em geral 30.000 tokens são são suficientes para para representar um um Corpus aí o que que acontece se chega uma palavra que que que não foi vista antes então vamos

- *Corpus ID:* 8228
- *Score:* 0.8286389112472534
- *URL:* oculto
- *Início:* 00:32:59
- *Fim:* 00:35:19
- *Transcrição:* você colocaria para explicar esse comportamento a gente falou um pouco aqui né da palavra banco que que acontece Então quando você puxar o most similar que pega as palavras mais similares então se eu botar a palavra eh laranja provavelmente as palavras mais similares vão ser tangerina limão sabe então a gente entende Olha tá isso aí não é uma palavra ah laranja tem a cor também ok mas vamos pensar contexto menor né ele tá trazendo coisas similares quando tu usa essas palavras polissêmicas isso pode pode ter umas confusões assim que ele vai trazer várias outras coisas então faça um racional sobre isso tá lembrando que tudo depende também do Corpus onde isso aqui foi treinado né do Corpus onde onde ele foi treinado Às vezes o Corpus não tem não dentro do Corpus ele só ele só usa uma determinada representação tá lembra palavra banco se ele não tem aquele banco de areia não vai não para ele aquela palavra vai ter uma representação do que tiver no dataset é isso que eu quero dizer né então se a pocem não tá presente ali Ah talvez até o que vier vai vai vir Palavras só de uma de uma de um significado Mas aqui é mais para vocês analisarem pensarem sobre isso né alguma dúvida no Exercício um tá no Exercício dois passa o exercício para para duas palavras escolhe uma palavra um sinônimo e um antônimo da mesma calcula a distância euclidiana e a similaridade do cosseno entre a palavra e o seu sinônimo e a palavra e o seu antônimo Aí tu bota o código aqui que você observa e qual a sua hipótese para explicar esse comportamento né então lembrando lembrem da aula passada né a gente até fez alguns exercícios ali com antônimos usando o tensor Flow aquele aquele visualizador de embeddings do

- *Corpus ID:* 8078
- *Score:* 0.8283984065055847
- *URL:* oculto
- *Início:* 01:00:48
- *Fim:* 01:03:14
- *Transcrição:* marcando onde passa a média e aí pr e aí você pode ir colocando PR pras frases em ordem crescente crescente Aí sim beleza fazal sentido isso mesmo tá deixa eu voltar aqui e a última é o que você analisou foi um Corpus ou um conjunto de dados anotados um dataset Qual a diferença entre os dois e professora explicou aqui ao longo da aula hoje né então vocês façam uma reflexão sobre isso e respondo pode colocar no próprio cab lá com texto né bota Um textinho lá aí eu só peço que vocês salvem o colab façam o download e e subam o cab ou um zip ou o próprio arquivo mas não coloquem o link tá pessoal subam o arquivo eh uma pergunta eu vi eu vi aqui na entrega que tava colocando coloque o nome dos integrantes dos participantes e é é para mais de uma pessoa ou é individual esse trabalho Esse é individual aí tem um outro trabalho que é que é o que eu vou comentar agora em seguido mas antes vamos ver se tem alguma dúvida sobre esses exercícios essas sete questões ã cujo prazo é segunda-feira que vem né Luciana isso segunda-feira que vem ai desculpa que no meu tá tá fora mais alguma dúvida pessoal dos exercícios tem uma não as dúvidas vão aparecer quando a gente tiver fazendo não tem jeito vocês podem usar o fórum tá pessoal porque eh seria interessante até vocês usarem mesmo porque às vezes a dúvida de um é a dúvida de outros então tem o fórum ali que vocês podem postar mas se preferirem também mandar e-mail particular mas para nós facilita se vocês utilizarem o fórum tá um um uma pergunta é no item quatro quando fala palavras distintas aí eu vou fazer o meu o meu pré-filtro né com como a senhora mencionou né Eh vou fazer meus tratamentos para fazer uma sair uma respostinha mais organizada né isso porque eu vendo lá que tu colocou que tu removeu removeu links por exemplo tu tá né mostrando que tu tá entendendo

- *Corpus ID:* 8035
- *Score:* 0.8282227516174316
- *URL:* oculto
- *Início:* 01:11:30
- *Fim:* 01:13:59
- *Transcrição:* salto de qualidade em processamento de linguagem natural e Recuperação de informação Então eu tenho aqui sete razões Então a primeira é a disponibilidade de corpora então disponibilidade de texto tanto em inglês como multiling então texto é fácil da gente conseguir então eu posso vou lá na Wikipedia consigo baixar dum de toda Wikipédia de um idioma específico e são mais de 200 idiomas existe um um um Corpus chamado common craw que tem petabytes de dados em 40 idiomas tem esse outro que eu colosso é o Clean CR Corpus também C4 aqui que tem uma quantidade enorme de de documentos tem o book Corpus que são são livros também número grande de tokens E aí a gente tem também em pugs tem em português um bem conhecido que foi construído aqui no instituto de informática na época era um aluno de Mestrado ou o Jorge que hoje faz doutorado e a a professora Aline Vila licencio era a coordenadora desse projeto Então esse WC w quer dizer web as a Corpus eles coletaram dados da da web eh e disponibilizaram isso como como um Corpus para para ser utilizado esse Corpus é muito utilizado para para treinar modelos de de de linguagem existe uma coleção para recuperação de informação também já bem menor né com notícias da Folha de São Paulo e do jornal o público Então esse é primeiro fator a gente tem texto e se a gente tá aprendendo a partir de texto A gente precisa de ter volume de texto depois a gente tem aqui os avanços em poder computacional Principalmente as gpus Então as gpus são GPU é uma sigla para Graphics processing unit e elas são usadas a vários anos com objetivo de acelerar a renderização de imagens e elas passaram a ser usadas para problemas que requerem computação intensiva porque elas têm uma grande uma grande capacidade de processamento paralelo então só para ter uma ideia que numa uma CPU a gente tem dezenas de operações por ciclo numa GPU a gente tem

- *Corpus ID:* 8071
- *Score:* 0.8251308798789978
- *URL:* oculto
- *Início:* 00:48:01
- *Fim:* 00:50:32
- *Transcrição:* Vocês bem sabem né a gente vai vendo só que aqui também ó eu tô tô com meus emojis nesse grupo aqui então você tem um emoji novo não vai atender então tem que sempre eh entender isso então aqui é o meu texto original vou usar esse remove emojis ó tirou aquele emojinho Ok eh normal né então agora um um outro exemplo usando um Corpus que é o Dom Casmurro né um livro eh esse Corpus ele tá disponível nesse link eh a gente chama o projeto Gutemberg ele tem vários livros disponíveis assim pra gente eh utilizar Ah o texto eles têm alguns problemas então às vezes não tem assento né tem detalhes assim que eu não tenho aqui Ah o porqu eles estão assim nós vamos nós vamos ver aqui o próprio Dom Casmurro que é um livro que tá disponível nesse projeto então a gente eh faz esse esse comando aqui para trazer esse esse arquivo eu vou abrir esse arquivo Então veja que ele começa aqui tem tem caracteres utf e uma série de ó nova linha então é um texto eh bruto né tamanho número de caracteres desse texto 40164 caracteres então usando o tokenizador de palavras e sentenças Observe tem mais esse aqui agora ó a gente tava usando o Word tokenize esse esse S tokenize Ele separa em sentencia então ele já resolve para nós o que que o português considera como pontuação separadores e já resolve para nós as sentenças são listas aqui de palavras e aqui são listas de sentenças Então esse Dom Casmurro ele tem [Música] 83.70 palavras e 4264 sentenças então aqui vamos imprimir as 10 primeiras palavras ó do Dom casmu imprimi duas sentenças lá 121 122 ó Então são sentenças eh do texto veja

- *Corpus ID:* 8100
- *Score:* 0.8240910768508911
- *URL:* oculto
- *Início:* 00:00:05
- *Fim:* 00:02:53
- *Transcrição:* tu avisa Luciana se tiver perguntas ou mão levantada porque eu não vou conseguir ver tô acompanhando Ok então vamos iniciar com o lembrete de um slide que a gente viu na na semana na aula passada em que a gente falou das grandes ondas do processamento de linguagem natural Hoje a gente vai tratar dessa segunda onda aqui da que fala dos modelos estatísticos então é importante a gente entender as coisas que que vieram a antes né pra gente conseguir H entender as motivações e as inovações que o que veio depois nos trouxe nós vamos começar aqui e depois na segunda metade da aula a gente vem para vem já paraa terceira obra Então a gente vai começar falando sobre pré-processamento de textos deixa escolher você mas antes vamos revisar um pouco da terminologia que é importante que a gente vai usar muitas vezes ao longo do curso a gente falou em Corpus cujo plural é corpora que é um conjunto de textos puros então textos sem anotação por exemplo artigos a wikipdia notícias de um jornal O Corpus de um que a gente coleta de um por exemplo decisões do do supremo ou qualquer coisa que que seja texto puro pode ser de um domínio específico ou genérico por outro lado um 7 é um conjunto de dados anotado então é é um conjunto tem tem as instâncias e tem os Labes tem as classes associadas a cada Instância a gente vai hoje mais adiante trabalhar com dataset também a gente fala bastante em sentença é o que a gente informalmente chama de frase mas o correto é é o termo é sentença e a gente fala em documento em instância em amostra em exemplo todos esses são as linhas do nosso dataset Então se a gente imagina o nosso dataset num formato tabular a gente tem as linhas que que eh que vão ter o conteúdo da instância e a classe e eh então tanto a gente pode se referir como

- *Corpus ID:* 8261
- *Score:* 0.8239376544952393
- *URL:* oculto
- *Início:* 00:09:36
- *Fim:* 00:12:13
- *Transcrição:* assim e aí esse processo de criando tokens maiores ele vai vai continuar até que a gente chegue no número de tokens desejado então uma entrada para esse algoritmo é quantos tokens a gente quer ah quantos que usam na prática Ah se usa na prática sei lá 30.000 00 então em geral 30.000 tokens são são suficientes para para representar um um Corpus aí o que que acontece se chega uma palavra que que que não foi vista antes então vamos ver aqui Professor só uma dúvida até então a gente associava tokens a palavras né agora vai ser associado a subpav letras conjunto de letras agrupadas aí você tá falando né isso pedaços de palavras pedaços de palavras certo é não é nem sílaba Porque alguns eu vou umas palavras muito frequentes eu vou ter uma um tokem vai ser a palavra inteira palavras pouco frequentes elas vão acabar sendo eh separadas em em pedaços e no pior caso é uma palavra que não assim muito estranha com com pares com sílabas que não fazem si vamos supor em um outro idioma então sei lá c y k h r uma palavra aqui que não a gente não tem uma sequência ela vai ser representada pelo aglutinação de todas as letras que compõem a palavra então uma vez que o vocabulário foi aprendido então a nova palavra vai ã vai a palavra do do teste né ela vai ser tokenizado por exemplo então seres não tá no no nosso vocabulário original a gente tinha mal males Lar lares mas não tinha seres tinha ser mas não tinha seres E aí se o nosso vocabulário base é só esse aqui como é que a gente vai tokenizar seres a gente vai tokenizar a gente o um S E aí eu tenho o e o r e o es quer dizer ele foi tokenizado e ele foi separado em em quatro tokens e esse símbolo aqui ele significa que eh é para para ser a que que esse token deve ser aglutinado com com o que vem antes então


**Resposta gerada pelo LLM**: Corpus, cujo plural é corpora, é um conjunto de textos puros, sem anotação; exemplos incluem artigos da Wikipédia, notícias de jornais, decisões do Supremo, etc. Pode ser de um domínio específico ou genérico.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: C

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should provide a clear definition of "corpus" and relevant examples. Supporting Evidence: The RESPONSE accurately defines "corpus" and provides examples of what constitutes a corpus, such as articles from Wikipedia and news articles. This directly addresses the PROMPT, which asks for an explanation of what a corpus is. The information is relevant and complete, covering both the definition and examples.  Score: 3


---
