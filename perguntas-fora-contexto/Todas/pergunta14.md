**Pergunta 14**: Como a seleção de features influencia a performance de um modelo de machine learning aplicado a séries temporais?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2506
- *Score:* 0.8737044930458069
- *URL:* oculto
- *Início:* 00:39:32
- *Fim:* 00:41:36
- *Transcrição:* todos mas eu acho que a parte revisorais eu acho que sim SPM eu tenho a impressão que sim mas não tenho certeza absoluta a gente pode confirmar depois então o único cuidado que a gente tem que ter o seguinte quando a gente usa o método de seleção de atributos que envolve de alguma forma um algoritmo de aprendizado aquela escolha tá sendo feito do ponto de vista daquele algoritmo de aprendizado e ela pode não ser a melhor decisão para um outro algoritmo que não foi avaliado muitas vezes o pessoal faz isso Tá Mas não é garantido então é então o pessoal faz mas é só lembrar isso né garantida é como se a gente fizesse assim eu digo que é mais importante na minha opinião e eu estabeleço que tu vai usar só esses mais importantes mas a tua opinião é outra sobre isso né então enfim só uma analogia errada tá por isso que talvez assim do ponto de vista de selecionar algo de forma rápida com um critério para usar diferentes algoritmos seja mais interessante usar o baseado em filtro porque o baseado em filtro ele vai usar alguns critérios Claro tem inclusive o ganho de informação mas tem outros critérios estatísticos que a gente vai ver E aí basicamente é útil porque eu não tô levando em consideração né todo viesse do tipo de um modelo específico porque é diferente é usar um ganho de informação em todos os dados e eu usar uma relevância que vem da análise do ganho de informação e interativamente dentro de uma árvore de decisão ela tem uma pequena diferença porque o segundo depende da construção do modelo e o primeiro depende só de um critério de avaliação claro essa parte tô pensando aqui professora no seguinte cenário se eu cheguei no Spot Check e os meus dois algoritmos mais promissores um é a árvore de decisão e outro sei lá svm

- *Corpus ID:* 2488
- *Score:* 0.8696151971817017
- *URL:* oculto
- *Início:* 00:10:37
- *Fim:* 00:12:40
- *Transcrição:* ao longo dessas abordagens que a gente vai discutir ok bom vamos começar a falar da seleção baseada em filtros tá essa seleção ela é a mais simples que a gente tem Tá mas a gente vai ver que ela é igual ela é muito útil principalmente em casos como a gente comentou brevemente né em outros momentos em que eu tenho por exemplo grandes volumes de dados porque cada etapa de transformação de dados dependendo do que o tecido que eu decido fazer por exemplo vou fazer uma imputação simples uma imputação por KNN se eu faço uma seleção baseada em filtros ou uma seleção baseada em breve porque a gente ainda vai ver é cada uma delas envolve um custo computacional diferente né então muitas vezes dependendo do volume de dados a gente também tem que levar em consideração o volume de dados para decidir qual a estratégia que a gente vai usar é e essa abordagem baseada em filtros ela tem algumas vantagens e tal realmente tudo tem vantagens e vantagens mas ela tem algumas vantagens que é o seguinte ela faz a seleção de atributos de uma forma independente do algoritmo de aprendizado de máquina isso quer dizer que eu poderia por exemplo usar essa seleção de atributos e o resultado dela poderia ser usado como entrada para diferentes algoritmos se eu quiser porque a decisão de como ela de como ela estabelece os mais relevantes não depende de um algoritmo específico o que ela faz é ela usa uma médica uma estratégia que avalia a cada tributo em relação a sua a sua importância para determinar que ele é tributo alvo então eu coloquei que correlação Associação porque no fundo as métricas dependendo são atributos numéricos categóricos as métricas estão avaliando esse tipo de questão tá é associação daquele atributo matribual você seja o quanto que ele contribui aquele atributo né um preditor

- *Corpus ID:* 2085
- *Score:* 0.8672099113464355
- *URL:* oculto
- *Início:* 00:57:30
- *Fim:* 00:59:48
- *Transcrição:* da gente usar um samba então aqui a gente tá usando árvores decisão a gente tá usando ela se faz alguma dúvida que pessoal Pode ficar à vontade se quiserem fazer uma pergunta só porque geralmente ele podia ser melhor mas exatamente nesse horário é isso aqui por exemplo né se eu fosse por exemplo escolher mesmo que a curasse ou algum outra métrica lá como a precisão ou Recall do Random Force de repente fosse melhor ou um pouco melhor talvez o melhor modelo a escolher mesmo com isso ou sei lá nos dados de treino de teste acaba acabaria sendo essa o bag com árvore de decisão é exatamente assim se a gente tiver olhando para essas para essas análises né a gente olharia e pensaria bom ou pega e realmente ele se eu tivesse uma análise desempenho e olhando isso aqui eu realmente acho que deve seria uma melhor escolha Mas uma coisa importante da gente tem mente a gente raramente fazer esse tipo de visualização nos modelos né porque a gente tá trabalhando com dados multi mencionais mesmo que eu trabalho é mesmo que eu trabalhe com técnicas de projeção eu posso fazer uma técnica de projeção para editar meus dados lá que tem 50 atributos em duas dimensões mas essas técnicas de projeções elas podem teria que aplicar isso né tanto para os dados quanto para as predições então torna um Pouquinho complicado não necessariamente vai refletir né aqui a gente está conseguindo ver porque é um exemplo com duas dois atributos enfim e computacionalmente deve ser bastante quando você tem diversos atributos Isso computacionalmente deve ser bastante complexo e demorado que se de você conseguir tirar essa conclusão ou seja seria pouco ganho muito esforço para pouco ganho exatamente então na prática

- *Corpus ID:* 2497
- *Score:* 0.8668413758277893
- *URL:* oculto
- *Início:* 00:24:47
- *Fim:* 00:26:56
- *Transcrição:* naqueles em boa qualidade não consegue ter um modelo com aqueles cinco atributos que te retorna um bom poder preditivo né então claro que do ponto de vista de coleta dá para continuar coletando os sensores Mas o modelo uma vez que tu determina que tu vai usar só esse Stop k basicamente o modelo só vai olhar para essas variáveis mesmo que tu continue coletando todas as outras né Então faz sentido porque aonde tu deveria dar mais atenção de por exemplo gerar dados de qualidade como você comentou certo bom Vamos abrir aqui essa outra esses slides também estão lá pessoal Espera aí que tá carregando eu ia perguntar se vocês estão escutando gente que vergonha ela fica desespera e é um entra e sai né Esse é o problema se ela ficasse aqui dentro mas ela daqui a pouco quer sair sim não entendi acho que olha acho que ela nunca incomodou tanto quanto hoje na hora da aula bom tá carregando aqui vamos voltar então pera aí que foi sem querer para o último slide Tá bom vamos dar continuidade Então tá esses primeiros dois slides eu vou passar um pouquinho porque a gente acabou de falar deles né dessa questão de seleção de atributos Qual é o objetivo na seleção de atributos então só esperar carregar aqui e o que a gente vai ver então a gente falou o seguinte a gente tem seleção de atributos por filtro embutida e baseado em rapper Então por filtro É aquela ideia eu aplico um critério faço um ranking né um critério de avaliação de relevância e a gente vai ver na prática depois né como é que esses critérios se apresentam mais o ganho de Formação seria uma possibilidade tá já adiantando

- *Corpus ID:* 1101
- *Score:* 0.8660600781440735
- *URL:* oculto
- *Início:* 01:14:12
- *Fim:* 01:16:48
- *Transcrição:* introduzindo mais ou eu vou fazer as duas coisas reduzir a classe prevalente e aumentar frequentemente é isso que dá melhor resultado acredito que vocês vão ver este conteúdo específico lá em metodologias de aprendizados previsionado e Finalmente né a gente pode ter gatem responder uma pergunta alguém fez uma pergunta alguém não sei não tô vendo aqui a colocação da pessoa vamos lá e análise da relevância então da que eu tava dizendo talvez ter que olhar redundância desprezar atributos pouco discrimites para classe alta tem várias ferramentas para a gente fazer feitio selection e as fichas que a gente tem dependendo da complexidade do problema elas vão influenciar tanto os resultados se eu tenho muitas features eu posso não conseguir achar aquelas para um mapeamento adequado em relação ao rótulo então às vezes fazer isso que a gente chama de engenharia de filhos empresário atributos de pouco influência seleciodo os mais promissores vão me levar Não só um tempo de aprendizado melhor mas é uma qualidade melhor dos meus resultados E é isso que eu tinha para vocês espero que o conteúdo não tenha sido muito denso acho que foi né mas é que tem que ficar aqui é justamente isso né diferentes estratégias para diferentes algoritmos vão reduzir em modelos que tem capacidade de previsão diferentes e vocês lidam isso medindo essas métricas num conjunto de dados que vocês usam para esse objetivo para medir o desempenho é de previsão do modelo de vocês cansaram né só um pouquinho e hoje eu perdi o concurso de popularidade então é vamos lá termido aqui a minha duas coisas que eu vou compartilhar com vocês agora é um aluno que lá no início tinha pedido que eu mostrasse onde é que conseguia

- *Corpus ID:* 1848
- *Score:* 0.8653344511985779
- *URL:* oculto
- *Início:* 01:07:51
- *Fim:* 01:09:52
- *Transcrição:* decisão baseada em proporções de exemplos por classe né então isso impacta menos né do que do que outros algoritmos que a gente discutiu ele impacta menos mas sempre que a gente vai trabalhar com aprendizado de máquinas de ruídos e outlanders que são pontos que vale a pena a gente pensar em tratar como pré-processamento tá mas ele é menos sensível a isso e essa questão da flexibilidade Eu já comentei né que ele é um algoritmo muito flexível em relação a suposições então a gente diz que ele é um método não paramétrico ele não tem nenhuma suposição sobre a natureza dos dados tipo de distribuição essa questão da comparação dos valores com escalas diferentes isso não impacta a árvore de decisão tá então ele é um algoritmo que a gente pode dizer assim é poucos requisitos em relação a pré-processamento algumas outras questões enfim alguns problemas né replicação de estruturas tá então pode acontecer de eu ter subarvores ou seja são conjuntos de testes encadeados que se repetem no modelo tá isso pode acontecer ou seja até mesmo sequência de testes mais em cima da árvore e depois mais abaixo da árvore isso pode acontecer por conta né da forma que ele olha só o que tá o que é melhor naquele momento não reviso que já foi feito nem o que vai ser feito no futuro elas são bastante propensas a over fiting pessoalmente quando tem uma árvore profunda Ou seja quando eu tô gerando partições super pequenas e aí a gente vai ver que algumas regras são geradas para se adaptar aquele ruído lá né do que tá no meu dado de Treinamento E aí isso gera um overflite no outro material que a gente não vai discutir hoje até posso mostrar rapidinho vai gerar um overfite tá ela não consegue detectar linearidade entre atributos e classes ou entradas e saídas tá justamente porque essas saídas sempre

- *Corpus ID:* 2533
- *Score:* 0.8649630546569824
- *URL:* oculto
- *Início:* 01:22:25
- *Fim:* 01:24:39
- *Transcrição:* gente seleciona esse Top Car de forma mais arbitrária Depois tem baseado em rapper tá foi na verdade esse último que a gente discutiu que a gente tem um conjunto de features e vão sendo gerados subconjuntos por exemplo né o FL vai tirando a cada interação a menos menos relevante ou atributo menos elevante vai reavaliando tá então e a embutida que aquela que dentro do processo de aprendizado ele gera esse subconjunto Então ele me retorna modelo importância por atributo tá então são algumas diferenças então esses dois aqui eles têm interação com algoritmo o primeiro não necessariamente tem interação com algoritmo tem uma pergunta pode falar Caroline professora faz sentido a gente primeiro fazer uma seleção de atributos e na sequência submeter o data 7 a uma extração de atributos tipo assim eu quero reduzir mesmo primeiro eu faço uma seleção chego num conjunto menor e na sequência eu quero dizer ainda mais faz sentido faz sentido porque mesmo a extração de atributos ela pode se beneficiar dessa seleção de atributos primeiro né porque porque se eu tiver a seleção de atributos ela vai de fato reduzir tirar o que não é relevante ela vai usar tudo só que ela vai combinar né em diferentes novas variáveis são as nossas novas dimensões Então faz sentido a gente pode usar não faz tanto sentido ao contrário tá fazer extração e depois da seleção porque dentro da extração eu vou gerar novas componentes Então o que a gente costuma fazer filtrar os componentes a partir daquelas eurídicas que eu comentei com vocês né de ver a variância acumulada enfim tá mas fazer uma baseada em filtro por exemplo seguido por um PCA sim é uma abordagem que já vi sendo bastante utilizada ok perguntas pessoal vou deixar agora um

- *Corpus ID:* 1776
- *Score:* 0.8636559844017029
- *URL:* oculto
- *Início:* 00:42:52
- *Fim:* 00:45:11
- *Transcrição:* beleza certo então esse não tem aquele problema de falta de mineralização né ele vai realmente vai estar naquele quadradinho de acordo com a regra né só que folha né e não tem problema de falta de generalização né na realidade a gente vai ver que esse algoritmo ele até pode chegar nesse problema de falta generalização para novos casos quando ele tenta se especializar muito tá vou dar um exemplo vamos supor que eu tivesse aqui um círculo tá vamos supor que tem um círculo isso aí eu tô talvez adiantando alguma coisa que a gente vai discutir mas se eu tivesse um círculo aqui essa região do lado esquerdo inferior ela não tá 100% ocupada por uma classe ela tem uma ainda um nível de heterogeneidade tá E meu coisa tá termido aqui a bateria e aí o que acontece é que eu poderia por exemplo o meu modelo poderia tentar fazer essa divisão ainda certo então quando o modelo começa a se especializar E aí vamos supor que eu tivesse aqui um triângulo tá isso meus atos de Treinamento E aí meu modelo de fazer isso aqui então desculpe o que acontece é que meu modelo ele foi criando partições muito específicas para um tipo de dado aqui que pode ser um ruído que é esse aqui E aí aqui pode gerar um overfito em que seria dificuldade de analisar para novos casos tá bom demais porque nas métricas de treinamento de teste ele Nossa tal Sei lá 99% só que na hora de ver dados novos ele vai exatamente aí o que vai acontecer nesse caso aqui né Se fosse caso é que um novo dado que cai aqui por exemplo aqui ficou meio confuso porque eu botei o Deixa eu só trocar aqui vamos supor que

- *Corpus ID:* 2485
- *Score:* 0.8633841872215271
- *URL:* oculto
- *Início:* 00:05:57
- *Fim:* 00:08:03
- *Transcrição:* modelar e diminuir a possibilidade de diminuir o over fiting né até porque o overfy tem aquela questão que a gente falou de ruídos ou particularidade dos dados que muitas vezes acontecem de forma aleatória então quando a gente reduz o número de dimensões muitos algoritmos tem a tendência de diminuir offite certo então tem uma série de benefícios interpretabilidade a rapidez os modelos melhor complexidade dos modelos melhores poder preditivo tá E lembrando que isso tudo acontece porque a gente mantém a semântico original dos dados ou seja se eu tinha lá enfim a idade da pessoa profissão idade altura basicamente eu tô mantendo essas informações só que eu tô tirando algumas que eu percebi que não são relevantes para aquele problema tudo bem até aqui então Claro não seria alguma pergunta não seria viável a gente fazer essa seleção manualmente tá ou seja muitos problemas a gente não tem o conhecimento para época de violência tributo relevante esse não é esse relevante isso não é certo a gente claro que a gente pode fazer uma limpeza prévia antes de chegar nessa etapa como a gente comentou né a partir de análise de correlação tirar atributos que estão muito relacionados a gente mantém um outro elimina atributos que tem muitos valores faltantes tá então a gente pode a gente pode obviamente reduzir essa dimensionalidade com essas outras tarefas mas reduzido ponto de vista de julgar o que que é relevante o que que não é para o nosso modelo é difícil de fazer manualmente tá é uma tarefa difícil fazer manualmente por isso que na prática a gente acaba usando técnicas para fazer essa seleção automaticamente não manualmente tá então as técnicas de seleção automática de atributos na verdade que elas vão nos ajudar isso a buscar por um subconjunto ótimo Na verdade nem todas conseguem chegar no subconjunto

- *Corpus ID:* 2520
- *Score:* 0.8626623153686523
- *URL:* oculto
- *Início:* 01:01:24
- *Fim:* 01:03:49
- *Transcrição:* classes quais são as classes e aí Olha só esse cof ele existe se eu usar o Kernel linear Então não é cvm né esse SBC como quer né linear ele tem esse cof e esse Cof é tipo um coeficiente né porque pela questão que eu quero não é linear ele pode ser usado como uma Estimativa de relevância de atributos então eu poderia usar um RF com o sdc usando cano linear mas não poderia usar qualquer certo então então a gente tem essa limitação mas assim o teu pensamento tá correto o ideal é a gente usar o algoritmo que a gente realmente almeja usar para resolver o nosso problema eu vou usar Vou tentar outra aqui que eu não lembro Deixa eu só ver aqui do KNN não lembro também tá só para a gente ver se ele tem alguma coisa nesse sentido KNN não tem tá então cai nele não poderia usar porque ele não tem nem o features em portas nem o cof Se vocês forem ver isso tá bem estabelecido ele tá bem estabelecido aqui nessa função né de desse módulo de fitoter selection vocês vão ver que tem várias funções Mas ele tá bem definido aqui então esse e ó o objetivo né selecionar atributos recursivamente considerando conjuntos cada vez menores de atributos né E aí bom é o que eu comentei com vocês ele treina o modelo com os atributos originais analisa a estimativa de importância depois tira né ele usa que a palavra enfim poda os atributos menos importantes e aí Aqui tá o esse metro né que é o algoritmo que tem que ter ou coef ou features importantes como atributos porque tem que ser capaz de avaliar essa importância de atributo o número de atributos que eu quero selecionar tá então se eu não colocar nada ele seleciona Metade dos atributos Se eu colocar um inteiro ele seleciona usa isso como número absoluto por exemplo se colocar 10 é um número absoluto são 10 atributo Se eu colocar


**Resposta gerada pelo LLM**: Não foi possível responder com o contexto fornecido


**Anotação manual**: I

**Answer Relevance (AR)**: 0.00

**Anotação automatizada**: I

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. Responses that do not answer the question or provide relevant information should receive a lower score. Supporting Evidence: The RESPONSE states that it was not possible to answer the question, which indicates a complete lack of relevance to the PROMPT. It does not provide any information or context related to how feature selection influences the performance of a machine learning model applied to time series data. Therefore, it fails to address any part of the PROMPT.  Score: 0


---
