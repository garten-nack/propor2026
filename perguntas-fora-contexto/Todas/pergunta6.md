**Pergunta 6**: Quais são as vantagens e limitações do teste de Kruskal-Wallis em relação à ANOVA, e como interpretar os resultados de um teste de Kruskal-Wallis?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 1966
- *Score:* 0.8458853960037231
- *URL:* oculto
- *Início:* 01:21:20
- *Fim:* 01:23:36
- *Transcrição:* mesmo Ah mas ele tá fazendo isso já né Depois é que na próxima eu tenho que mudar é ó perceba que eu botei de volta 42 tá então usando o mesmo Windows state né os resultados e a ideia que eu vou usar os mesmos valores de álcool então vocês podem entender que esse resultado ele vai me dar assim ele vai me dar para Vários valores de Alfa né 0.0 enfim os que estão sendo testados aqui na verdade é 0,003 ele vai me dar Vários valores já curasse então como se eu tivesse uma matriz né em que por exemplo nas colunas eu tenho os valores de alfa e na linha eu tenho o quanto que foi acurasse para cada valor então cada linha se refere a uma repetição e aí o que eu posso ver claro se eu tenho por exemplo 10 valores para Alfa igual a 0,03 então eu posso calcular uma média desenvolvido padrão usar um box plot para ver como é que tá mudando o desempenho tá E aí é melhor que eu voltei para o 42 só para deixar o padrão mas percebam que muda isso Mas alguma pergunta pessoal sobre a essa questão [Música] chama atenção né de vocês que o seguinte isso aqui eu poderia estar fazendo pera aí deixa eu só que que tem um delay aqui tá essa na linha 18 em que a gente define o intervalo de valores para ser testado para o alfa eu poderia testar isso aqui com o maxtel com mim sample Smith enfim eu poderia testar com outro preparamos a mesma mesmo procedimento devido o treino validação em teste Defina um conjunto de valores para testar por exemplo profundidade máxima de um dois três quatro cinco seis até o nome é quando eu não estabeleço nenhum limite né a gente escreve nona com n maiúsculo avalia o cada um deles e plota um gráfico como esse aqui né só que nesse gráfico eu vou ter no eixo X o hiper parâmetro de pré poda e no eixo Y o meu desempenho

- *Corpus ID:* 380
- *Score:* 0.8456109166145325
- *URL:* oculto
- *Início:* 01:18:08
- *Fim:* 01:20:22
- *Transcrição:* queria ligar aqueles dois pontos pela equação da reta exatamente são os meus pontos amostrais e eu vou tentar achar uma reta boa eu vou estimar uma reta eu vou ajustar uma reta que passe por estes pontos errando o mínimo possível aí a reta de mínimos quadrados aqui que a gente chama tá Ok outro parâmetro que a gente vai trabalhar é a proporção tipo o exemplo que eu falei ali da conscientização do lixo proporção de pessoas que coletam lixo né que fazem coleta seletiva eu quero saber se isso continua sendo 30 diferente de 30 menor que 30 menor que 30 tá aula que vem então isso aqui a gente vai ver na aula que vem tá além da distribuição normal vão ter outras distribuições que a gente vai utilizar tá que isso depende do tipo de dado e do parâmetro que a gente vai testar por exemplo que tinha falado ali né bater que é o que a gente vai ver de fato aqui porque até a distribuição assim tóptica da normal anormal a gente só pode utilizar Quando eu conheço o desvio padrão populacional que não faz sentido mas até se eu tiver um n bem grande eu posso usar né anormal que elas vão se aproximar muito tá então a gente vai ver ali até hoje de fato é a ter que a gente utiliza e não é normal até agora a gente normal só para a gente fazer referência com aquela aula lá da semana retrasada tá nossa aula de probabilidade na sexta da semana passada retrasada e outras distribuições tá algumas delas a gente vai ver outras não tipo F tipo que quadrado hoje tá Hoje nós vamos ver estes dois exemplos aqui tá três exemplos o primeiro que a gente viu que eu quero ver por exemplo se a média do tempo de dias se exercitando por semana é igual a 3,09 ou é diferente de 3,09 que é o teste para uma média comparado com valor padrão eu poderia querer comparar isso

- *Corpus ID:* 2529
- *Score:* 0.8453757166862488
- *URL:* oculto
- *Início:* 01:16:12
- *Fim:* 01:18:14
- *Transcrição:* essa linha em preto é digamos assim o desempenho esperado para o dado de teste tá isso aqui é tudo avaliação no dado de teste então eles estimam um desempenho esperado tem algumas formas de fazer isso ponto estatístico e aqui seria em vermelho então reportado pelo protocolo sem vazamento de dados em azul vazamento de dados então e a gente percebe a diferença então assim a porcentagem se eu pegar aqui 5% dos atributos selecionados esses atributos provavelmente Vão bater os mesmos os dois protocolos mas um protocolo vai dizer assim olha o sem vazamento de dados esse 5% me dá uma curar 60% E esse protocolo correto olha esses 5% me dá uma curaça de 77% tá então esse é o problema né o cuidado da gente tá estimando de uma forma muito otimista o desempenho associado com essa seleção de atributos Ok tem uma pergunta pode falar Carol professora mas essa contaminação de dados também acontece quando a gente faz quando a gente utiliza a técnica baseada em filtro porque na baseado em filtro o modelo ainda não viu né os dados a gente reduz antes e depois submete os dados reduzidos ao modelo é exatamente a técnica baseada em filtro ela é menos sensível a isso não quer dizer que ela não não exiba um pouco de contaminação de dados porque a gente vai estar avaliando Assim entre todas as instâncias que estão sendo analisadas por exemplo Qual é o ganho de informação desse atributo em relação àquela classe Então se nessas instâncias estão nos dados de teste ou de validação a gente acaba tendo vazamento de dados mas o efeito não é tão grande porque como você está comentando a gente não faz avaliação e termos do desempenho né então o desempenho atrelado a um modelo então a técnica de baseado em filtro eu diria que aquela mais tolerável da gente fazer fora da validação cruzada

- *Corpus ID:* 2710
- *Score:* 0.8452181220054626
- *URL:* oculto
- *Início:* 00:32:41
- *Fim:* 00:34:54
- *Transcrição:* Ele mesmo que acabar o meu contrato aí é pensando nisso essa variada tem ela não teria uma alta Qual a relação com alguma outra com alguma outra variável não então talvez poderia estar influenciando essas coisas porque porque eu tenho ele na verdade Ele conta para assim pelo que eu entendo ele tem ele mede o tempo que o cara tá com aquele contrato mas outras coisas outros atributos Eles é que podem definir o porque o cara ainda não encerrou o contrato então mesmo que a e o Chucky eles estão muito relacionados mas não é um que define o outro é apenas o meu modo de pensar mas eu não sei se tá certo sim isso poderia isso poderia ser analisado e até ser pensado né no sentido de limpeza dos dados se usar tênis ou não você falou em correlação temer Total charge são atributos que eu acho que estão relacionados eu não lembro da análise específica né de colação mas o total Charlies são os gastos totais então quanto mais tempo a pessoa tá no serviço provavelmente mais gastos ela tem né mas assim realmente poderia estar associado agora a importância de atributo ela vai analisar tudo que entrou no modelo então se tem alguma coisa que a gente acha que não faz sentido ela tem que sair antes desse modelo certo antes de treinamento é por isso que tinha que ter feito alguma coisa antes para tirar essa essa alta com a relação para depois sobrar realmente para treinar e chegar nesse ponto aqui sem ter essa relação entre variáveis nessa correlação isso exatamente tá eu ia mostrar para vocês né só para vocês entenderem que a permutação porque a gente fez 30 permutações tá E aí a gente tem aqui a importância Média a partir da promoção mas eu não cheguei a colocar em gráficos a gente poderia até fazer aqueles gráficos de barra com erro né enfim mas aqui a gente consegue ver a Justamente a média e o desvio padrão a média é o que é mostrado ali e o desvio padrão da

- *Corpus ID:* 2832
- *Score:* 0.84456467628479
- *URL:* oculto
- *Início:* 01:40:00
- *Fim:* 01:42:09
- *Transcrição:* informação veio ali e bom que você já já colocaram porque é uma forma diferente de explorar o desempenho e fiquei feliz que vocês pensaram em explorar essas estratégias que são menos comuns que elas deixam né mas que são interessantes quando a gente tá comparando modelos ficou bem bem interessante pessoal parabéns pelo parabéns pelo trabalho aí né todos tem uma pergunta do Antônio Deixa eu só tô confirmando aqui tem alguém como levantada é o Antônio isso é só nessa questão do na parte da estatística do dos modelos só querem entender uma coisa a gente também fez o teste ter pareado então para escolher qual dos dois sentidos realmente diferença dos dois melhores mas quando você fala de colocar o intervalo de confiança eu vou comparar também pode ser só um pode ser o outro eu tenho que depois de fazer o teste até pareado faz os dois faz um intervalo de confiança para ver se eles se sobrepõe dos dois modelos é só isso que eu não entendi como a gente pode melhorar isso na realidade vocês poderia até optar por uma ou por outro tá teste de o teste de hipótese né pelo P valor ele dá uma uma métrica muito objetiva apesar das suas falhas que é o p valor então ali pelo valor vocês vão ter esse dia vocês vão rejeitar ou não é hipótese nula então ah se o p valor é menor que 0,05 considerando que vocês definiram Esse trecho bom Existe diferença significativa entre os modelos né os modelos eles têm é então não precisa na verdade não precisa os dois tá então um só está bom pessoal fazendo um comentário os finais então eu até coloquei no Moodle um conjunto de slidesumarizando coisas que a gente conversou ao longo da disciplina tá mas dado o tempo avançado assim a gente realmente acabaria passando não cinco minutos mas talvez uns 15 do horário e ficou um pouquinho apertado mas eu acho

- *Corpus ID:* 1735
- *Score:* 0.8439337015151978
- *URL:* oculto
- *Início:* 01:06:39
- *Fim:* 01:08:57
- *Transcrição:* E aí aqui a gente tá fazendo aqui a análise da distribuição dos valores né aqui olhando as medianas tá medianas para o conjunto de vinhos bons e o conjunto desculpa divinos Medíocre pode ver que os gostam muito do teor alcoólico né porque aqui tá bem alto e a gente pode ver algumas diferenças enfim eu acho que essa é a principal diferença se a gente for ver talvez aqui um pouco esse a densidade enfim que diminui aqui tá mas enfim Isso é uma análise exploratória dos dados tá bom vamos falar um pouquinho agora da questão do treinamento do modelo certo fazendo uma otimização manual eu boto manual entre aspas porque no fim manual a gente vai programar para ele fazer o que a gente quer né se a gente sabe programar não vamos fazer de fato manual tá valor um por um vamos programar um loop que ele faça essa avaliação então o sdm linear ele é o mais simples que a gente viu até agora né então o que que a gente tá usando aqui a gente tá usando a função svc essa função sdc é o suporte Vector classifyer e se vocês forem olhar o suporte Vector classifyer tem esse preparante lado Kernel que por padrão é o RBF mas eu tô acertando ele aqui como linear então isso garante que eu estou usando um svm linear Eu poderia usar o svc linear poderia né outra função mas essa função se Descer me dá suporte ao linear também o outro o Line desculpa o linearense ele não dá suporte ao RDF tá E aí o que que a gente tá fazendo na linha 2 eu tô determido aqui uma variável Perfect Vales né a performance na validação que ele vai ser uma lista que vai me dar o valor de desempenho para cada variável que a gente testar para cada valor que a gente testar de ir parâmetro e aqui eu tenho que eu chamo da esse parangoide c é uma Grid ou seja valores possíveis que eu quero testar valor específicos para o nosso termo de

- *Corpus ID:* 7200
- *Score:* 0.8436318039894104
- *URL:* oculto
- *Início:* 00:31:55
- *Fim:* 00:34:14
- *Transcrição:* Eh bom como é que essa bolita aqui pode parar lá no no topo desse negócio né Bom na verdade a gente só tava enxergando isso de forma de uma forma que não nos favorecia o entendimento da cena a isso é bastante comum né em problemas de visão computacional a gente quer determinar a existência ou não de um de um objeto ou a classe de um determinado objeto ou enfim né Eh e nem sempre a gente tem informação suficiente para isso então Com base no No resto né no cenário a gente pode eh inferir eventualmente né e tomar decisões com base nisso tá isso vai mais ou menos ao encontro daquilo que eu comentei do nariz né então a gente interpola a informação e diz olha isso é o melhor que eu posso tá eh em nenhum momento a gente assinou um contrato com o cérebro dizendo ó você não vai enxergar o seu nariz mas eu vou né Eh é a mesma coisa aqui só que agora a gente tem poder de decisão sobre o que os nossos algoritmos vão fazer ã vamos lá tá bom Com relação à formação das imagens né Eh no nosso no nosso contexto aqui de processamento de imagens e tentando puxar um pouco para para que a gente acabou de ver eh a gente tem a noção de luz e espectro eletromagnético né então existe uma série de de frequências aqui que compõe né o nosso o nosso espectro e a gente tá bastante habituado com uma porçãozinha pequenininha aqui que é o que a gente chama de luz visível né ou espectro ou subsect espectro de luz visível tá então a gente consegue enxergar de 300 e qualquer coisa ômetros a 700 e qualquer coisa quase 800 ômetros tá fora isso a gente não enxerga e existe um universo né para um lado e pro outro então Eh né inclusive os nomes aqui das do das das porções do espectro não são nada Absurdos para nós né então

- *Corpus ID:* 2528
- *Score:* 0.8434816598892212
- *URL:* oculto
- *Início:* 01:14:28
- *Fim:* 01:16:40
- *Transcrição:* cruzada com todos os dados a diferença não é em termos dos atributos selecionados os atributos selecionados nas duas estratégias tendem a ser os mesmos a diferença tá na hora de reportar o desempenho atrelado a esse subconjunto de atributos o protocolo incorreto que é esse aqui ele tende a dar estimativas mais altas de desempenho por conta do vazamento de dados Então se o meu objetivo é selecionar atributos tá claro que a gente vai sempre selecionar atributos tentando maximizar algum desempenho mas eu quero selecionar atributos são todos exatamente comparando esse modelo com outros né O atributo selecionado vai ser no geral mesmo né com protocolo padrão que seria tipo incorreto com vazamento de dados ou com protocolo correto que ele sugerem tá a diferença é a estimativa de desempenho e eu trouxe esse gráfico do artigo que eu acho ele bem interessante tá que eles fizeram uma análise com 24 data 7 diferentes tá todos que tinham pequeno tamanho amostral e eles fizeram essa análise comparando a mudança na Estimativa de desempenho em termos de acurácia a partir comparando com diferentes porcentagens de features selecionadas tá aqui de 1 a 40% então esse essa linha azul lo eles chamam é o livonaldo que seria aquele protocolo com vazamento de dados o vermelho é o apropriado é o que ele sugerem certo que é a seleção de atributos embutida no livro Nonato tá dentro do livro Now ou de uma validação cruzada tradicional e essa linha em preto é digamos assim o desempenho esperado para o dado de teste tá isso aqui é tudo avaliação no dado de teste então eles estimam um desempenho esperado tem algumas formas de fazer isso ponto estatístico e aqui seria em vermelho então reportado pelo protocolo sem vazamento de dados em azul vazamento de dados então e a gente percebe a diferença então assim a porcentagem se eu pegar aqui 5% dos atributos selecionados esses atributos

- *Corpus ID:* 440
- *Score:* 0.8431726098060608
- *URL:* oculto
- *Início:* 00:00:12
- *Fim:* 00:02:09
- *Transcrição:* Opa bom então hoje a gente vai ver a referência para dados a gente começa com o teste para uma proporção onde a gente vai ver tanto teste assim tóxico quanto teste exato tá Depois a gente vai ver teste para duas proporções né então vocês vão ver que é exatamente os mesmos comandos ele é tudo muito parecidinho é que nem a gente vê uma aula passada teste para uma média e depois teste para duas médias tá então é tudo muito parecido Então a gente vai vir de novo os dois testes né o teste exato e o teste binomial na verdade deve ser o teste quadrado é isso e o teste encontrado de independência tá então a gente vai ver esses três estão três exemplos que a gente vai ver na sequência e mostrar todos os testes envolvidos passo a passo vou mostrar alguma coisinha vou mostrar a fórmula mas a gente vai usar muito pouco a falar das formas são bem simples mas para a gente mais para a gente entender como é que funciona o teste Qual é a ideia quando é que aquele teste resultado vai ser significativo para eu rejeitar a zero né que vai me mostrar lá que aquela evidência é uma evidência forte em favor da H1 né então portanto que a gente deveria rejeitada zero só para a gente entender dentro da Fórmula né como é que isso acontece o que que é levado em consideração na hora de calcular de teste para que aquele resultado que a gente teve na amostra que é uma evidência né a gente já viu isso que sempre que a gente vê na amostra é uma evidência da H1 contra h0 mas às vezes ela não é forte o suficiente então assim como a gente viu lá no teste da média o que que levava em consideração né que não era só a diferença do valor que eu observei na média em relação a média da amostra em relação a média da população quanto testando mas também a variabilidade dos dados tamanho da amostra né então a

- *Corpus ID:* 1907
- *Score:* 0.8431527614593506
- *URL:* oculto
- *Início:* 01:12:05
- *Fim:* 01:14:23
- *Transcrição:* mas é também importante ver como é que esse maior de validação sai em relação ao dado de treino entende porque às vezes essa diferença ela pode ser maior de validação Mas tem uma não necessariamente A diferença vai ser menor possível é isso eu quero dizer então é bom olhar as duas coisas mas eu acho que para essa questão de maior validação pode ser uma boa desde que a gente não ignore as outras características que é a diferença entre esses valores de treino e validação eu sou obrigado a plantar um gráfico porque essa decisão por exemplo ao invés de eu pegar esse esse vetor de das métrica não sei pode ser a curaça o record sei lá então em vez de eu pegar o maior valor ou Alfa relativa ao maior valor antecipação ou treinos o teste eu tenho que plotar essa diferença esses gráficos esses dois essas escadinhas porque visualmente eu falei olha essa diferença é menor e eu vou usar elas porque porque a minha métrica de teste ou de validação ela é a que eu preciso que ela é um pouquinho maior em vez de necessariamente eu escolher a maior que podia ser perto aí de repente das duas e mais Digamos que ficaria eu acho que é para entrar entendeu graficamente tem que ser importante olhar o gráfico não só buscar aquele valor que maximiza a validação tá o Alexandre tem uma pergunta só a carne deixando que ele tava esperando já e depois a gente faz Oi Alexandre Oi professora é uma pergunta a respeito da da proporção treino e teste se eu tiver uma boa quantidade de amostras seria uma estratégia eu equilibrar mais a quantidade de treino e teste para de repente diminuir essas distâncias claro que essa distância ela pode ser maior se a gente tiver um conjunto de teste né de validação menor isso pode acontecer tá então que a gente tem


**Resposta gerada pelo LLM**: Não foi possível responder com o contexto fornecido


**Anotação manual**: I

**Answer Relevance (AR)**: 0.00

**Anotação automatizada**: I

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. It should address the advantages and limitations of the Kruskal-Wallis test compared to ANOVA, as well as how to interpret the results of the Kruskal-Wallis test. Supporting Evidence: The RESPONSE states that it was not possible to answer with the context provided, which indicates a complete lack of relevance to the PROMPT. It does not address any part of the question regarding the advantages, limitations, or interpretation of the Kruskal-Wallis test. Therefore, it fails to provide any relevant information or context related to the PROMPT.  Score: 0


---
