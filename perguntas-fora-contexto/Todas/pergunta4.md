**Pergunta 4**: Como o uso de variáveis externas (exógenas) pode melhorar a previsão de séries temporais em modelos de machine learning?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 8325
- *Score:* 0.8586723208427429
- *URL:* oculto
- *Início:* 00:01:46
- *Fim:* 00:04:05
- *Transcrição:* bag of WS eh para abordagens bag of WS para reduzir a dimensionalidade tá bom professor eu fico imag eu fico imagido que para técnica é porque essa técnica do B of Wars ela já tá um pouco defasada então eu imagino que as as técnicas novas que vocês foram mostrando elas na verdade não tem necessidade da gente fazer esse tipo de coisa não é isso muitas vezes você já tem um modelo um modelo pré treinado que aí você vai transformar nos como embeds nas embeds e as embeds são os dados que a gente vai entrar para o nosso determinado modelo de de previsão eu tô tô errado ou tô entendendo corretamente essa questão eh a assim do tempo né do tempo das técnicas que n foram se desenvolvendo sim as técnicas mais atuais são baseadas em em Bedin contextuais e em Transformers principalmente acontece que as que que os modelos B of fors eles ainda têm bons resultados para várias tarefas a gente pode ver que nesse dataset das Americanas por exemplo o resultado do SV é melhor do que os resultados que a gente obteve com ah com o o lstm e as worden Bells eu acho que até melhor do que o do burt se bem que o do burt a gente treinou com menos né Igual ficou igual e ele é muito mais barato uhum ah então assim na verdade o que de uma forma geral que a gente pode fazer é de repente utilizar algumas técnicas que são mais baratas que são um pouco mais antigas Óbvio você vai ter Sei lá talvez ela seja nossa baseline e depois você usa outras técnicas mais avançadas E aí você pode comparar e Óbvio aqui se Adapt melhor os dados que você tem você vai utilizar no seu no seu processo né no seu problema isso exatamente às vezes uma técnica mais antiga e mais barata eh se dá um resultado parecido com com uma técnica que é bem mais poderosa então é é preferível até porque é porque é mais barata né mais barata no sentido bom

- *Corpus ID:* 1724
- *Score:* 0.8583070635795593
- *URL:* oculto
- *Início:* 00:48:38
- *Fim:* 00:50:53
- *Transcrição:* assim quando vocês decidem por usar o Anderson que a gente chama o ovo ele já vai gerar para vocês uma decisão uma valor por classe e qual é a classe e predita assim como o ano versus All Mas é interessante a gente começar essas discussões quando a gente falar da combinação de múltiplos modelos por exemplo usar um naipes dele para tratar o mesmo problema eu vou cair nesse ponto de pensar bom como é que eu agrego essa saídas né Então essa discussão ela já é útil para quando a gente começar a pensar nisso porque a gente vai discutir sobre isso também tá mas do ponto de vista do svm vocês podem pensar o seguinte isso tá resolvido internamente o que vocês vão definir se vocês vão usar o universo do ano ou o ano versus professora Oi pode fazer uma pergunta Talvez assim um pouco mais geral por exemplo né a gente gasta um trabalho grande aí né nessa fase de análise exploratória dos dados experimentação dos hiper parâmetros até encontrar um modelo que seja melhor para o nosso problema e aí beleza colocamos ele em produção modelo tá ali funciodo bem durante o primeiro ano e aí com o passar do tempo sei lá as características da população vai mudando e esse modelo começa a errar é importante que que esse modelo ele seja avaliado então e seja acompanhado quando ele foi posto em produção de forma que quando a gente observa que ele começa a errar muito ele tem que ser refeito Escolhido um outro modelo para tratar aquele problema sim e sim isso é bem importante porque muitos dos problemas a vida real eles de fato mudam com o tempo né e é isso alguém comentou da siglas ali desculpa e é isso muda com o tempo e isso é natural assim acontecer só que o problema é que quando a gente tem isso a gente chama de data certifiques tá de um shift deslocamento dos dados e é esse deslocamento pode ser em função as classes estão mudando por exemplo antes

- *Corpus ID:* 8463
- *Score:* 0.8567329049110413
- *URL:* oculto
- *Início:* 01:13:59
- *Fim:* 01:16:21
- *Transcrição:* Teoricamente eles aprendem mais eles têm mais capacidade de identificar padrões eh complexos esse esse eh dimensionality do do modelo não é simplesmente o número a quantidade de estados de pesos Não é só isso porque ele tem cabeças de atenção então tem uma série de de coisas dentro dessa arquitetura Tá mas entendam que é um uma um vetor de 768 que vai sendo levado em cada de de uma camada para outra e que também depois nós vamos usar para isso que é AD beding que cada um desses modelos e provê tá então aqui tem mais eh tem aqui o o trabalho ó que se chama o artigo que foi publicado isso aqui foi tudo aberto então eles de fato revelaram como como treinaram explicaram então o nome era language models are un supervised multitask learners né então eles já viram a capacidade dele fazer várias tarefas aqui né E esses modelos a gente tem formas então de avaliar ele a forma mais utilizada são essas avaliações extrinsic então no momento que a gente tem um GPT treinado né como é que a gente diz que ele Ah ele para tarefa tal ele ele ele atinge um um determinado score né então o Bert por exemplo então eu vou fazer uma tarefa de classificação uma tarefa de eh geração de texto né então ele essa avaliação extrínseca ela mede o quanto a execução dessa tarefa melhora então o melhor exemplo aqui eu o do Bert nas usando classificação ou ou até a sumarização né uma tarefa bem específica na avaliação intrínseca ela já é mais difícil da gente compreender porque ela mede a qualidade de um modelo Independente de qualquer aplicação ou tarefa Então como é que se faria isso então tem uma métrica que é usada que é a perplexidade ou perplexity é usada nessa avaliação intrínseca e ela é uma métrica assim bem complexa ela tá relacionada à entropia

- *Corpus ID:* 2641
- *Score:* 0.855743408203125
- *URL:* oculto
- *Início:* 00:41:07
- *Fim:* 00:43:06
- *Transcrição:* que é mais explícita assim para esse caso né então não nem sempre é fácil identificar as variáveis que estão carregando esse viés mas mas seria o ideal a gente tentar identificar seja por um conhecimento prévio seja por uma análise protória dos dados seja usando algumas métricas que a gente tem métricas que tentam analisar o potencial de baias antes do treinamento né o potencial de várias carregado por cada variável mas tudo isso do ponto de vista de métricas de métodos para tratar esse tipo de problema ou evitar ou tratar ainda são coisas em desenvolvimento tem bastante coisas já que foi desenvolvida que está sendo usada mas a gente pode dizer sim o problema ainda não tá 100% resolvido sabe ainda tem muito do ponto de vista de pesquisa e desenvolvimento para ser feito para realmente tornar algoritmos mais seguros em relação a isso mas de fato uma possibilidade seria isso identificar esses riscos de viés nos dados e tirar essas variáveis que carregam esse viés seja de uma forma bem explícita né ou seja dessa forma mais mascarada assim então não é uma tarefa muito fácil e a gente só consegue Observar isso imagino eu nos modelos interpretáveis e isso ou usando técnicas para interpretar os modelos né a prioridade seria usar o modelo interpretável tá E seria prioridade porque a gente consegue ver exatamente que o modelo tá aprendendo as outras técnicas a gente usa recursos para tentar estimar né Essas associações ou essas essas associações do ponto de vista né do que que tá explicando uma saída então quando a gente Depende de um outro método para compreender o nosso modelo a gente sempre fica refém do que esse método faz né E até que ponto ele consegue de fato encontrar isso né Então realmente os modelos interpretáveis eles

- *Corpus ID:* 1668
- *Score:* 0.8552994132041931
- *URL:* oculto
- *Início:* 01:07:19
- *Fim:* 01:09:29
- *Transcrição:* poderia se eu quisesse testar diferentes eu poderia também testar variações né dessas combinações então eu uso k = 1 com distância de manhatta cai igual a um com a distância cleidiana k igual a três qual a distância de manha rata cai igual a 3 com distância clidiana então assim eu poderia ter o que a gente chama de uma Grid né de valores possíveis de combinações de prepaâmetros tá por isso que quando a gente trabalha com aprendizado de máquina treido esses modelos preditivos existe um custo computacional melhor config uração de prepaâmetros para o algoritmos para o algoritmo que a gente escolheu para o conjunto de algoritmos que a gente tá usando certo mais alguma pergunta bom o que acontece acho que eu vou continuar porque ainda não sou dessa eu vou continuar mais um pouquinho antes do nosso intervalo o que acontece é o seguinte esse svm linear de Margem suaves que é esse que a gente consegue usar com esse termo de regularização em muitos casos ele vai funcionar bem tá claro de margens rígidas ele é muito restrito né o de imagens suaves ele muitas vezes conseguem porque percebam que aqui para esses dados eu não vou ter necessariamente uma divisão linear não é uma divisão linear aqui mas no momento que eu digo para ele que eu aceito que ele ergue algumas algumas instâncias né eu consigo fazer com que ele determina uma fronteira de decisão linear para tentar fazer o melhor possível né para classificar aqueles dados com essa tolerância de erro tá só que a gente vem discutindo que nem todo o problema e da grande maioria dos problemas na vida real não são linearmente separáveis Ou seja a gente já sabe que uma fronteira de decisão linear dada por uma reta o hiperplano não vai ser capaz de modelar complexidade daquela daquele problema de classificação certo então o

- *Corpus ID:* 631
- *Score:* 0.8541173934936523
- *URL:* oculto
- *Início:* 00:24:14
- *Fim:* 00:26:20
- *Transcrição:* outro eu vou mostrar para vocês o five ali no vip no caso né do inglês lá no R tá Depois a gente rodar o modelo a gente vai ver lá se a gente não tiver nenhum bife maior que 10 atendida multipolinárioidade professora uma maneira assim manual da gente fazer isso aí seria com aquela Matriz de correlação correto e isso e incluindo um a um e vendo como é que eles que é isso que até quais faz ó a gente já vai rolar agora e ir incluindo variáveis ou tirando variáveis faz as duas coisas tá tem na verdade são três metros de seleção de variáveis tem o fórum começa com o modelo vazio só a constante e vai incluindo tipo que a gente fez no caso da academia o beco começa com o modelo completo e vou tirando a menos significativa e o stepwayze ele pode tirar e botar na medida que ele vai andando passo a passo então pode ser que uma variável que saiu não passa atrás possa voltar no outro passo dependendo da variável que entrou antes dela ele vai tirando e colocando variáveis até chegar no modelo né bom e que que é um modelo bom eu vou dizer modelo bom não pode ter variáveis com P valor menor que sim maior que 5 ou não pode ter valor maior que 10 tá ou aí c que a gente não vai ver aqui mas é uma das métricas mais utilizadas né para quem trabalha bastante com modelagem se esse meu aí ser atingir lá determinado valor cheguei então no meu né minimizei o máximo meu IC não consigo enquanto menor melhor né eu minimizei o máximo meu a EC E aí eu tenho o meu modelo né alcançado na melhor modelo alcançado vejam que não existe o melhor modelo existe o meu melhor modelo tá porque o Lisiane por exemplo de não jogar fora a renda e sim trabalhar com a renda olhando comprometimento de renda um outro analista pode ter uma outra ideia

- *Corpus ID:* 607
- *Score:* 0.8537701368331909
- *URL:* oculto
- *Início:* 01:31:05
- *Fim:* 01:33:44
- *Transcrição:* então você pode misturar os dois no mesmo modelo E aí o efeito no Y pode chegar a ser anular você vê que o consumo permanece sempre o mesmo porque ontem isso um alocar que esses coeficientes aqui são interpretados de forma isolada ou seja esse valor aqui de aumento no Y Essa é aumentar o X1 mas não mexendo no X2 E se eu mexer no X2 eu tenho mais essa contribuição no Y então para eu falar desta contribuição positiva quando eu aumento o X1 não mexendo no X2 tá na próxima regressão que a gente vai chegar vai aparecer isso lá eu chamei a atenção aqui então calculei o resíduo mesma ideia lá né lembram tem os resíduos que a diferença entre observado menos esperado por agora aquela limitação estação que tem X1 e X2 reduzimos o nosso erro ou seja estamos melhorando o nosso modelo tá então os resíduos ao quadrado é outra métrica de qualidade do modelo tá bom só para a gente entender ali quando a gente colocou só o X2 ó voltei lá vamos entender o que eu tô falando aqui ó quando eu coloquei só o X2 kdm com relação o X2 Era Zero 89 a correlação coloquei só ele na minha equação e eu cheguei em 0,7964 que é a nossa o nosso R ao quadrado é o 089 ao quadrado aí eu fui lá e coloquei o X1 0,76 e não é mais agora né imagina olha o tanto que eu botei eu teria que passar junto se eu fosse só somando bota isso aqui ao quadrado quanto é que esse aqui ao quadrado 0,5 Cadê bonito lá aquele 79% que eu tenho lá já passei de 100%. então eu não vou acumulando explicações de cada variável porque as variáveis tem explicação conjunta porque elas têm associação entre elas lembram tinha a correlação eu tenho aqui mão de obra e gasto com energia né com energia elétrica quanto mais pessoas trabalhando lá mais energia elétrica eu vou gastar elas estão com

- *Corpus ID:* 8319
- *Score:* 0.853166937828064
- *URL:* oculto
- *Início:* 01:57:20
- *Fim:* 01:59:27
- *Transcrição:* poder de predição do do né da do nosso modelo ou não né então a gente começou a brincar depois que a gente fez o balanceamento das classes ficou um pouco mais eh tranquilo de a gente conseguir testar naquele colab gratuito lá né até mesmo local né então agora a gente vai começar a mexer um pouco mais e aí a gente Pens pensou também na questão de tentar utilizar o modelo com base em Deep learning né E então obscuro Mas então daí seria uma outra pergunta para vocês que é a gente ainda tá meio que esperando aliando pra barriga esperando ver se a gente aprende mais novas técnicas e ver se pode utilizar de forma mais e eficiente né no nosso trabalho mas estamos nessa linha aí Por enquanto né Por enquanto machine learning mesmo Tá previsto esse script que a gente comentou aí tu vai ter toda a Páscoa tá Alexandre tu pode aproveitar ele rodar ele eu devo gravar ele entre hoje e amanhã então quinta-feira já a gente já tenta já deixar disponível ah perfeito Obrigado professora beleza então agora Caroline Denis e Vanderlei eh bom professoras a gente não preencheu a planilha mas a gente já deu uma pesquisada no dataset e a gente queria pegar um dataset que tivesse que estivesse em português né E aí a gente até achou um lá no papers with code de tweets em português e aí a gente deu uma olhada eh começou a explorar né o dataset a a gente viu que tava um pouco desbalanceado né Uhum aí a gente adotou como estratégia para tratar o desbalanceamento eh agrupar as diferentes eh classes de de discurso com ódio né a gente tinha seis diferentes classes a gente juntou tudo em uma classe que seria com ofensa e E aí quando a gente fez isso o desbalanceamento ficou menos Severo Então a gente vai nessa linha e aí a gente pensou a gente ainda não fechou ainda a linha de pesquisa mas é de

- *Corpus ID:* 5471
- *Score:* 0.852897047996521
- *URL:* oculto
- *Início:* 00:03:06
- *Fim:* 00:05:00
- *Transcrição:* a gente vai olhar pô mas aqui eh a gente tem uma uma série de estratégias que podem ser usadas para melhorar essa performance né como foi citado aí agora a pouco né eh ah usa tabelas temporales depois você né gera uma final Eh vamos vamos dizer assim modularizar aí né o a tua consulta né ou uma aplicação spart que seja né eh ah assim aí eu fiquei na dúvida Qual a gente tem alguma ferramenta que a gente vai conseguir trabalhar aí no no no laboratório né no nosso ambiente de de trabalho aí acadêmico eh que consiga identificar essa essa questão né de o que que eu posso melhorar aqui na minha aplicação ou se realmente esse problema é é grande suficiente a ponto de eh eu não consigo mais espremer a aplicação é e assim não existe uma ferramenta mágica que te diga o problema está aqui entendeu pontualmente assim na realidade existem ferramentas que te trazem indícios entendeu então por exemplo na linguagem r quando tu tem um workflow lá que uma série de passos de transformação né tu pode usar um profiler esses profilers eles existem também em outras linguagens como Python né e Normalmente eles indicam assim ó essa essa query aqui ó Exatamente esse comando aqui tá levando tanto tempo entendeu ou tá levando sei lá 60% do tempo e aí tem muitas coisas assim que de vez em quando assim do ponto de vista sequencial só sequencial tá Talvez tu tenha como fazer isso que tu mencionou Ah vou criar uma tabela temporária vou fazer alguma coisa preliminar entendeu Vou fazer uma outra forma essa minha transformação e resolve Tá mas isso não é o foco dessa disciplina o foco dessa disciplina é que tu T já alguma coisa eficiente sequencialmente e tu quer ficar fazer ela ficar mais rápida entendeu E aí as escolhas não são exatamente assim a esse comando aqui entendeu as escolhas são mais assim em que Quais são os pedaços que foram tipo assim eu tenho o meu volume de dados

- *Corpus ID:* 744
- *Score:* 0.8525716066360474
- *URL:* oculto
- *Início:* 00:47:14
- *Fim:* 00:49:29
- *Transcrição:* para ficar no modelo Mas como eu tirei de qualquer jeito assim pensa também que se eu eu tenho a lista das que eu tirei né e eu sei quais são as que estão que tem alto colinaredidade Então nesse caso eu posso por exemplo depois sei lá fazer com que o stepwayze utiliza troque utilizando essa colocando essa essa variável que eu tirei E aí eu consigo ver qual que é a melhor eu consigo ver mas aí eu só coloco uma ou outra três ou quatro mas eu uso muito no meu no meu algoritmo no meu modelo final Eu Posso reduzir muita quantidade de variáveis que pode me dar uma melhora porque eu já tirei várias formas e essas eu posso colocar de tá vamos lá eu já sei que essas duas são colineares lembra lá alta com relação entre número de caracteres e linha qual das duas tu Tiraria sem olhar o modelo não é isso que eu tô te falando eu Tiraria uma delas não importa você entregou lá Stepway faz teu trabalho aí agora o que que eu faço aí agora eu inverto stepways faz o teu trabalho com é agora com essa daqui aí eu removo a outra tá pode ser mas na verdade eu vou estar fazendo duas vezes algo que eu poderia fazer uma vez só que se eu mandar ele testar as duas tu veja que tirar qualquer uma das duas piorava o modelo qualquer uma das duas ele fez esse teste se a gente voltar lá em cima ele tirou essa ou tirou essa qualquer dúvida se a gente voltar lá tudo bem Tá tudo bem com você aqui ó número de caracteres se eu tirar piora o modelo né que tá aqui 11:35 e cadê os Breaks ó pior o modelo Então já mandei ele olhar as variáveis que tinham potencial de entrar que melhoravam o modelo ou não ficou todo mundo que só que melhorou o modelo se eu tirar qualquer uma delas eu pioro agora


**Resposta gerada pelo LLM**: Não foi possível responder com o contexto fornecido


**Anotação manual**: I

**Answer Relevance (AR)**: 0.00

**Anotação automatizada**: I

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. It should provide relevant context and answer the question completely. Supporting Evidence: The RESPONSE states that it was not possible to answer the question, which indicates a complete lack of relevance to the PROMPT. It does not address how external variables can improve time series forecasting in machine learning models, nor does it provide any context or information related to the topic. Therefore, it fails to meet any of the criteria for relevance.  Score: 0


---
