**Pergunta 24**: Quais são as melhores práticas para lidar com dados faltantes em séries temporais antes de aplicar algoritmos de machine learning?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 2333
- *Score:* 0.8733195662498474
- *URL:* oculto
- *Início:* 00:30:12
- *Fim:* 00:32:15
- *Transcrição:* simplesmente remover essas instâncias né e usar só os valores que realmente foram coletados tá claro que quando tem poucos dados isso vai ter um custo que eu tô diminuindo essas essas distâncias e todo reduzindo mais o meu conjunto de dados dentro dessa questão de eliminar manualmente informações a gente poderia também ver atributos que tem muitos valores faltantes então atributos que tem uma proporção de valores faltantes muito alta tá Se isso for um problema geral quem Depende de classe isso provavelmente não está relacionado ao problema né do caso distinguir a classe né o valor de saída e a gente poderia simplesmente remover a coluna agora o que que não é claro para Gente o que que eu não consigo dizer para vocês né a respeito de qual é a proporção de valores faltantes que a gente tem que usar como treshow como librar para remover a coluna porque isso depende depende muito for um atributo relevante poucos valores faltantes já vai fazer muita falta se for da tributo irrelevante de repente se tiver sei lá 50 ou 60% dos valores preenchidos né a gente conseguiria trabalhar com isso de outras formas então isso seria uma estratégia como é que a gente poderia fazer dá para a gente definir manualmente os valores através de consultas especialistas se for valores razão não aleatória mais fácil fazer isso se for razões aleatórias a gente poderia pensar em definir o valor arbitrário fora do intervalo padrão daquele atributo é que se mostra nos dados ou o valor padrão para identificar que é um erro né então por exemplo tributo categórico que poderia ter uma informação não preenchido não informado entretanto acho que a solução mais comum que a gente normalmente adota é tentar corrigir esse

- *Corpus ID:* 2332
- *Score:* 0.8711901307106018
- *URL:* oculto
- *Início:* 00:28:35
- *Fim:* 00:30:41
- *Transcrição:* exemplo bebês ali registrados né então o campo vai estar vai estar faltando ali então tem que entender bom tem uma relação com outra característica não é uma razão aleatória tá essas que são de razão não aleatória a gente Normalmente consegue tratar de uma forma que não seja simplesmente inferir o valor que a gente vai discutir na sequência a gente consegue tratar a pessoa do bom eu vou criar um valor eu vou criar uma categoria que representa que o motivo de não ter sido preenchido isso seria bom como é que a gente lida com isso tá então é basicamente mostrando o que a gente quer fazer né aqui no slide anterior a gente tinha alguns valores faltantes o que a gente quer é lidar com isso Preencher esses valores estimar esses valores para que a gente possa ter o dado completo porque a maioria dos algoritmos e as implementações não vai lidar naturalmente com esse com esse cenário a gente vai ter que tratar isso antes do treinamento dos modelos bom o que a gente vai fazer depende muito de algumas questões como quantos valores estão faltando e o volume de dados tá então eu poderia por exemplo eliminar normalmente essas distâncias se tiver um grande volume de dados e essa porcentagem de distâncias que tem algum valor faltante for minoria não representar uma classe específica que represente uma diminuição da minha proporção de exemplo eu poderia simplesmente remover essas instâncias né e usar só os valores que realmente foram coletados tá claro que quando tem poucos dados isso vai ter um custo que eu tô diminuindo essas essas distâncias e todo reduzindo mais o meu conjunto de dados dentro dessa questão de eliminar manualmente informações a gente poderia também ver atributos que tem muitos valores faltantes então atributos que tem uma proporção de valores faltantes muito

- *Corpus ID:* 2329
- *Score:* 0.8701999187469482
- *URL:* oculto
- *Início:* 00:23:42
- *Fim:* 00:25:54
- *Transcrição:* de uma forma que é fácil de identificar tá por exemplo o atributo simplesmente está vazio possui o símbolo não possui o símbolo pré-definido como ponto de interrogação possui um código que definir um valor faltante então isso depende né de como foi montada a coleta dos dados tá Mas no geral é fácil de identificar tá a questão toda identificar porque que aquele valor tá faltando no sentido de até mesmo Desculpa passei que sem querer de até mesmo pensar em como lidar com isso tá tem uma pergunta ali deixa eu passar para pergunta pode ser sobre isso que a gente passou no nosso trabalho porque a gente tinha lá 5000 registro e tinha um e tinha 11 registros que eles não tinham eles não estavam vazio ele tava com espaço em branco e aí quando a gente rodou rodou aquele comandinho para ver lá se tem campo Lula eles não acusou em lugar nenhum E aí quando a gente botou o modelo para rodar para treinar ele ele ficava dando um erro erro um erro de valor né E aí foi quando a gente saiu investigando e viu que tinha tantos que ele tinha espaço em branco lá onde era para ter o número né E aí pelo volume e não vocês não tinham identificado né manualmente eu quero dizer assim às vezes é difícil a gente ver o visualmente detectar esses erros por conta do volume de dados então saber como os valores faltantes estão quantificados é importante inclusive se vocês vão projetar algo que envolve coleta de dados envolve né como é que eu vou armazenar esses dados já você já devem pensar que é importante vocês planejarem esse tipo de questão porque facilita muito análise de dados Tá tem outra pergunta da Caroline pode falar valores nulos não se enquadram nessa categoria né seria ruído o valor nulo o valor nulo seria valor faltante também a questão é como como esse vazio está

- *Corpus ID:* 2343
- *Score:* 0.869772732257843
- *URL:* oculto
- *Início:* 00:46:30
- *Fim:* 00:48:49
- *Transcrição:* faltante tipo substituí-lo pelo valor faltante tratar esse dado junto com os valores faltantes através de métodos de imputação então por exemplo aqui essa temperatura 97.6 eu poderia tentar estimar esse valor através de um método de imputação para fazer isso eu pego esse outro lá e substitua por um valor vazio e aí trata os meus valores vazios nulos da base de dados e automaticamente está tratando esse erro aqui tá esse erro ou o Outlander outro caso e depois tem duas questões que seriam alterar esses valores um é fazer um Billy tá que basicamente o Billy é uma descritização de dados tá eu pego os dados do médicos por exemplo temperatura né e separo em faixas intervalos de tamanho uniforme então sei lá de 36 a 37,5 de 37639 enfim e aí esses esses intervalos esses todos os valores que caem no mesmo intervalo eu posso optar por pegar esse esses valores que são autores vão estar nos extremos né e substituir pela média mediana da faixa correspondente ou até categorizar os dados o momento que o categoriza os dados numérico para categórico eu acabo elimido essa atuais porque ele vai estar numa faixa que vai se transformar numa categoria então todo mundo que tem Claro que uma faixa mais alta né então todo mundo que tem esse o valor 97.6 ou sei lá 41.5 vamos pensar 40 enfim temperatura super altas vou ter lá a mesma categoria que indicando que a temperatura tá muito acima do normal tá então a gente elimina esse esse alto lá e outra questão é fazer o que a gente chama de capim que é substituir os valores baseado percentil fixo então todos esses que são muito discrepantes que são ruídos ou outlines a gente ele bebeu pelo percentil 3 pelo valor que representa o percentil 3 na minha distribuição ou percentil 97 né então os mesmos extremos digamos assim

- *Corpus ID:* 5085
- *Score:* 0.8665468692779541
- *URL:* oculto
- *Início:* 00:26:08
- *Fim:* 00:28:29
- *Transcrição:* dia aqui é e cada coluna Desculpe é um dia né e aqui você pode pegar por exemplo 10 meses de dados Então você tem uma out outro tipo de agregação né E essa agregação ela introduz eh como a gente viu anteriormente a uma uma aproximação dos dados que que pode que precisa ser detalhada né paraa gente poder entender o que que tá acontecendo em cada dia mas aqui a gente só tinha uma estação embaixo a gente pegou 30 Estações mesma ideia daqui de cima só que aqui a a linha aqui é a coluna em vez de ter essa altura até bem menor porque eu tenho 30 e você empilha E aí você consegue ver que tem alguns padrões que são similares assim como muito parecido com aqueles imagens que a gente gerou nos corredores onde tem valores Escuros para quando você tá com um Bat pento cardíaco menor valores mais perto de amarelo quando tá maior então enfim você pode mexer com com a tabela de cores também tem várias escolhas que a gente pode fazer também aqui e a mesma visualização aqui à direita para essas mesmas 30 Estações ao longo de 10 meses tem uns brancos aqui porque são falhas nos dados ou você não tem a a informação naquela período cor somente especificamente bom eh um outro problema que surge também eh aqui a gente tá eh mostrando uma outra informação eh na verdade aqui a gente tá usando uma escala eh divergente porque a gente tá querendo eh separar Ou pelo menos identificar quando tá de vazio para muito cheio passando por uma ocup média então esses digamos assim os opostos são são aquelas próximos de situações que a gente tem que ter alertas né então qu tá próximo diga uma dúvida só e não existe só essa empresa que fornece bicicleta lá certamente né Deve ter algumas né foi levado em conta essa concorrência ou só se tratou porque você pode ter uma vazia mas o outro lado tá

- *Corpus ID:* 2429
- *Score:* 0.8663541674613953
- *URL:* oculto
- *Início:* 00:08:07
- *Fim:* 00:10:21
- *Transcrição:* então não teria problema agora por exemplo né é que dependendo um pouco das questões se vocês tiverem né alguma possibilidade de tentar Por exemplo discretizar variáveis ou até foi uma sugestão Na verdade uma pergunta barra sugestão não mudam né que é questão de gerar valores faltantes ou seja vocês geram valores faltantes artificialmente teve um grupo que perguntou também poderia ser feito Mas se vocês decidirem por trocar o data 7 realmente não precisa passar pelo Spot checking vocês podem pegar dois ou três algoritmos diferentes tipo por exemplo usbm que tem a questão do Kernel que vocês podem usar na otimização de preparaâmetros né enfim aí fica a questão de vocês mas pegar algoritmos um pouquinho diferentes assim e escolher uns dois ou três não mais que isso e fazer esse Fini Tá certo obrigado tinha alguma outra pergunta foi respondida alguém te levantado a mão no cheirinho mas eu ia falar a mesma coisa que a gente tinha selecionado no trabalho anterior um data 7 que tava muito os dados estavam muito certinho assim não tinha nada para fazer para o processamento daí a gente tá estudando um outro data 7 para esse trabalho não tem problema né não não teria problema não teria problema eu só o que eu queria ver com vocês bom tem outra pergunta Caroline pode falar Caroline a minha pergunta referente a essa atividade que nós vamos entregar antes do trabalho final a gente considera o conteúdo dado até redução de dimensionalidade e na que a gente vai ver hoje na verdade a ideia seria fazer até o desbalanceamento de classes Tá mas o que eu tô pensando sobre essa questão do dessa atividade que era atividade 2 e não colocar um ponto de entrega

- *Corpus ID:* 2330
- *Score:* 0.8637956380844116
- *URL:* oculto
- *Início:* 00:25:19
- *Fim:* 00:27:33
- *Transcrição:* inclusive se vocês vão projetar algo que envolve coleta de dados envolve né como é que eu vou armazenar esses dados já você já devem pensar que é importante vocês planejarem esse tipo de questão porque facilita muito análise de dados Tá tem outra pergunta da Caroline pode falar valores nulos não se enquadram nessa categoria né seria ruído o valor nulo o valor nulo seria valor faltante também a questão é como como esse vazio está codificado tá esse vazio ele pode estar codificado né é que depende muito do da base até da linguagem de que a gente está usando para usar como por exemplo site que ele olha esse Nan como como valores faltantes Tá mas poderia ser só que aí tem essa questão né antes de responder Definitivamente a tua pergunta é tem a questão da gente identificar Por que que o valor Tá Faltando Se essa se esse valor faltante ele tem uma razão aleatória ou não porque daí dependendo o nulo pode ter um significado que daí a gente quer manter por exemplo tá valores faltados por razão aleatória tá então erro da coleta de dados né então por exemplo há pessoas que são de preencher aquele Campo a coleta de dados ali será automática falhou naquele instante de tempo algo que é monitorado o tempo enfim algo aconteceu aleatóriamente não existe uma justificativa para aquela falta do dado então faltou poderia ter faltado e outra Instância naquela Instância ali ouve esse esse erro né de coleta tá agora por outro lado tem os valores faltantes por razão não aleatória que daí a falta desse Registro tem o significado tá então um exemplo mais tradicional disso é quando por exemplo você tem questionários com perguntas e cadeadas então por exemplo Ah você assina sei lá TV a cabo sim ou não aí a outra pergunta se você assina né Qual é o seu plano mensal anual então a pessoa

- *Corpus ID:* 2176
- *Score:* 0.8630298972129822
- *URL:* oculto
- *Início:* 00:21:37
- *Fim:* 00:23:35
- *Transcrição:* vezes os dados são bons só que estão cheio de ruídos precisam de tratamento né tem que falar tem alto lá ele tem valores faltantes enfim tem que passar por um pré-processamento de quantificação categórico numérico numérica categórico tem uma série de questões ali normalização então às vezes não é só o dado não quer dizer que ele seja o suficiente para aquela tarefa ele só precisa desse refinamento digamos assim tá então isso é um é digamos assim senso comum e aprendizado de máquina vocês provavelmente Vão ouvir falar várias vezes que até garganta de alta né então por isso que a gente tem que evitar alimentar esse processo de alimentos modelos com dados que são lixo que são ruins Ok E aí tem duas questões aqui importantes né Se eu tiver dados muito bons né que representam esse diamante Se eu tivesse dados muito bons tiveram um processo de modelagem de treinamentos de modelos ruins certo então por exemplo eu não cuidei overfiting eu não tô avaliando bem o meu modelo enfim o meu resultado sim pode ser ruim eu posso estragar digamos aquele potencial dos dados em função de não explorar bem essa modelagem na parte de Treinamento avaliação e seleção dos modelos agora quando eu tenho dados ruins mesmo que eu faço essa metodologia de treinamento do modelo né mas da parte já é essa divisão dos dados dados Independentes treinamento a validação enfim se eu fizer isso de forma Impecável se os meus dados forem muito ruins essa modelagem Impecável do ponto de vista de metodologia ela não salva esses dados ela dificilmente salva esses dados certo então a gente tem que cuidar a gente tem que entender o que que a gente precisa trabalhar em nível de dado né para que a

- *Corpus ID:* 1059
- *Score:* 0.8615162372589111
- *URL:* oculto
- *Início:* 01:29:07
- *Fim:* 01:31:33
- *Transcrição:* faltantes ou que tem grandes como é que a gente chama distorções então insuma né embora ela tenha essas características legais assim de ser interpretava ela do ponto de vista de desempenho desempenho sendo a sua capacidade de prever ela tá um tanto ultrapassada E aí tem várias variações né a primeira que apareceu era o id3 hoje substituído pelo C5 que justamente trouxe isso agora ela trabalha com atributos numéricos ela lida melhor com valores faltantes ela lida melhor com distorções e assim por diante e na verdade tem várias versões escaláveis entre elas a da vez né é o Randon Force E aí deixa eu só um instantinho Antônio já vou te dar a palavra vou reforçar tá aqui eu gostaria de chamar atenção que vocês vão ver isso na próxima disciplina com a professora Mariana porque eu quero mostrar para vocês é que existem diferentes estratégias de fazer criar essa função de mapeamento Tá então não vou entrar nos detalhes das florestas aleatórias diga Antônio não imagina que isso essa então esses algoritmos de árvore de decisão a gente assim a gente não precisa se preocupar com a questão de do pré-processamento de valores nulos e como a gente vai tratar isso porque ele internamente já faz isso desculpa mas você falou alguma coisa nesse sentido não muito pelo contrário tá dependendo do algoritmo ele vai ser um pouco mais robusto mas você entrega dados que tem má qualidade a capacidade dele de lidar com isso é pior então por exemplo vou só dar exemplos de técnicas que o pessoal inventou tá não tem valor faltante alguns algoritmos substitui por um símbolo tá então ele substitui por um símbolo então ele tem um valor outros algoritmos substituem por um médio então ele não ele tem um valor só que fazer

- *Corpus ID:* 4042
- *Score:* 0.8610794544219971
- *URL:* oculto
- *Início:* 00:27:21
- *Fim:* 00:29:41
- *Transcrição:* E aí essa esse algoritmo ele vai então fazer esse ajuste dessas componentes que são linhas que separam o espaço colocando essas linhas nas melhores posições possível para manter a representação dos dados originais e aí eu uso esses componentes no restante do processamento seja a mineração de dados ou visualização e aí como eles são uma quantidade menor eu vou processar em menos tempo bom e eu tenho eu tenho um exemplo aqui de como é que nós podemos poderíamos fazer isso no corrente dados que nós já usamos né então se você lembrar lá das Flores das ilhas nós vamos carregar aquele conjunto de dados E aí vamos aplicar Então essa técnica para Que ela possa nos dizer ao invés de usar as quatro dimensões originais quantos componentes principais eu teria que ter né para poder representar o mesmo conjunto de dados né bom primeira coisa carregar Os dados aqui e algo importante que que nós devemos fazer é escalar os dados né porque nós componentes principais já que eles são separadores lineares funcione da maneira mais adequada eu preciso colocar todas as dimensões no mesmo padrão né sinal de que ele pode ter problemas na hora de identificar essa essa e não representar adequadamente a variabilidade dos dados já que eles têm dimensões de tamanho diferente e depois não tem muito muito mistério basta eu executar não é o modelo distanciar o modelo E aí tem alguns parâmetros o principal parâmetro aqui é a quantidade de componentes vocês vão ver depois que tem outros outros parâmetros se vocês pegarem aqui pegar o decomposition sempre vão dar uma olhada no


**Resposta gerada pelo LLM**: O contexto menciona várias abordagens para lidar com dados faltantes, incluindo remover instâncias com valores faltantes (se o volume de dados for grande e a porcentagem de valores faltantes for pequena e não representar uma classe específica), remover colunas com muitos valores faltantes (dependendo da relevância do atributo e da proporção de valores faltantes), definir manualmente valores faltantes através de consultas a especialistas (se a razão for não aleatória), definir um valor arbitrário fora do intervalo padrão ou um valor padrão para identificar o erro (se a razão for aleatória), e usar métodos de imputação para estimar valores faltantes.  A melhor abordagem depende da quantidade de valores faltantes, do volume de dados e da razão pela qual os dados estão faltando (aleatória ou não aleatória).

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: P

**Answer Relevance (AR)**: 1.00

**Anotação automatizada**: C

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to receive a maximum score of 3. Supporting Evidence: The RESPONSE directly addresses the PROMPT by outlining various best practices for handling missing data in time series before applying machine learning algorithms. It discusses specific strategies such as removing instances or columns with missing values, consulting experts for non-random missing data, defining arbitrary values, and using imputation methods. Each of these points is relevant to the prompt's request for best practices, demonstrating a comprehensive understanding of the topic.  Score: 3


---
