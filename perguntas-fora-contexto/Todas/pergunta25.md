**Pergunta 25**: Como uma Rede Neural de Cápsulas é diferente de uma Rede Neural Convolucional?

**Segmentos recuperados pelo E5**:
- *Corpus ID:* 7629
- *Score:* 0.8689689040184021
- *URL:* oculto
- *Início:* 00:22:08
- *Fim:* 00:24:40
- *Transcrição:* Tá bom então para isso a gente precisa de outra outro tipo de arquitetura para trabalhar com essas imagens tá eu diria que provavelmente a a motivação que foi mais forte para que essa coisa toda né para que essa chave girasse foi a a primeira Tá então não tem como eu processar um volume grande de dados usando mlp tá bom ã então a gente usa essa noção de redes neurais convolucionais né uma rede neural convolucional é uma rede composta predomitemente por camadas convolucionais e uma camada convolucional é uma camada né É é é uma parte da minha rede que ã aplica convolução de parâmetros dessa rede que são ã são menos parâmetros tá então basicamente eu tenho um filtro tá como os filtros que vocês viram na aula passada a diferença é que esses filtros eles são aprendí veis né ou são aprendidos no processo de otimização tá então Pontos importantes aqui né eh deixa eu ver se tem alguma coisa não hã na mlp eu teria via de regra todas as entradas conectadas com todas os os os neurônios da primeira camada eh escondida tá isso são vários neurônios tá são várias relações que eu tenho que codificar e numa camada e numa camada convolucional Eu tenho um k que varre a imagem inteira tá então é um Kel pequenininho e os pesos que eu quero aprender né as relações que eu quero que que sejam aprendidas ou que sejam reforçadas por esses pesos eh vem justamente desse ker tá Outro ponto importante é que CNN são redes neurais convolucionais compostas predomitemente por convolucionais tá é bastante comum que as nossas cnns tenham um monte de camada convolucional

- *Corpus ID:* 7625
- *Score:* 0.8681415915489197
- *URL:* oculto
- *Início:* 00:15:15
- *Fim:* 00:17:40
- *Transcrição:* noção de cnns né de redes neurais convolucionais tá bom eh tem um histório aqui que eu não quero ser extensivo mas basicamente antes das cnns a gente usa usava as Tais das redes ã completamente conectadas né as fully connected que a gente chama hoje de fully connected eh Então dependendo do Framework que vocês estão usando para para trabalhar com learning né os caras cham de fully connected outros eles chamam de dance dance layer fully connected layer né Eh e esse termo mlp vem de mul layer perceptron né que é tudo essas três coisas é a mesma coisa tá então basicamente se eu tenho uma rede que é uma mlp ou se eu tenho uma rede que é totalmente conectada né ou se eu tenho uma rede que é totalmente densa eu tenho uma rede em que as minhas entradas se conectam com todas as as os neurônios da camada escondida primeira né os neurônios as saídas desses neurônios se conectam com todas as os neurônios da camada escondida que vem depois e por aí vai até a hora de saída tá eh isso meio que cunhou o termo né rede neural artificial né Eh e foi sendo usado aí um bom tempo em várias aplicações continua sendo usado em várias aplicações especialmente aquelas que não envolvem eh imagem vídeo e coisa assim então quando eu tenho features né específicas ah eh features nominais né ah tem tem tem tal informação não tem a varia de tanto a tanto uma medida específica esse tipo de coisa né continua tendo bastante aplicação dos algoritmos mais tradicionais de learning tá ã mas para imagens a história mudou paraa imagem depois para para processamento de linguagem natural e tudo mais tá eh mas basicamente a gente tá focando em imagens né imagens tem três edades que que pedem né que imploram na verdade por arquiteturas de learning que sejam

- *Corpus ID:* 7628
- *Score:* 0.8655701875686646
- *URL:* oculto
- *Início:* 00:20:26
- *Fim:* 00:22:45
- *Transcrição:* ã e a aí isso significa que eu vou ter que pegar a minha imagem espichar a minha imagem criar um um vetor a partir da minha imagem que é matricial e passar esse vetor para minha mlp né eventualmente pixels vizinhos vão ser neurônios um abaixo do outro eventualmente não né eventualmente eu vou ter um neurônio né Vamos pensar que eu fiz um um rasing da minha imagem assim né eventualmente Eu tenho um neurônio que é tá num Pixel específico tá pegando informação de um pixel específico uma entrada que tá pegando um pixel específico eh o Pixel que tá abaixo desse cara tá várias entradas abaixo naquela minha organização da mlp tá então eh considerar eh essa noção de espaço em mlps é bem complicado tá e um terceiro ponto né é que a interpretação de uma imagem é estável sobre transformações geométricas tá que que significa isso né ã que se eu tenho uma imagem que representa um cachorro eu tenho problema de detecção de cachorro né H cachorro versus outra coisa se eu pegar o cachorro e fazer né der um zoom no cachorro vai continuar sendo um cachorro se eu der um zoom out no cachorro vai continuar sendo um cachorro se eu girar o cachorro vai continuar sendo um cachorro né Se eu colocar ruído vai continuar sendo um cachorro tá e tudo isso é bem menos essa noção de geometria né Ela é bem menos eh passível de exploração numa mlp Tá bom então para isso a gente precisa de outra outro tipo de arquitetura para trabalhar com essas imagens tá eu diria que provavelmente a a motivação que foi mais forte para que essa coisa toda né para que essa chave girasse foi a a primeira Tá então não tem como eu processar um volume grande de dados usando mlp tá bom ã então a gente usa essa noção de redes neurais convolucionais né uma

- *Corpus ID:* 3266
- *Score:* 0.8650330305099487
- *URL:* oculto
- *Início:* 00:06:56
- *Fim:* 00:09:27
- *Transcrição:* neurônios aqui da entrada iam acender e um ter que ativar outra coisa ali dentro e aí uma arquitetura de rede neural que resolve isso são as redes convolucionais é que vou passar para parte aqui da convolução Então se a gente consegue implementar um elemento desse aqui né numa rede neural que é um filtro o filtro detecta características em qualquer posição da imagem né então quando eu posiciono isso aqui nessa na parte aqui da imagem ela detecta né onde combina né o filtro e a imagem vai ser vai ficar detectada ali para ser processado depois então a gente fazendo isso consegue deter que consegue fazer de forma mais competente ficar mais detectar característica desejada onde quer que ela esteja e o resultado né uma convulsão pelo menos nesse caso aqui né que todos os valores são um ou menos um eu vou falar esse caso especial depois o caso geral nesse caso em especial né o resultado da convolução de um filtro 3 por 3 nenhuma imagem um pedaço da imagem é numa região 3 por 3 da imagem é cada valor do filtro vezes cada valor da imagem né o somatório disso cada valor do filtro e os cara valor da imagem então fica um vezes um né esse vamos fazer aqui de novo 1 x 1 + -1 x - 1 + - 1 x - 1 - 1 - 1 aqui também menos um menos um menos ou vezes menos um e assim por diante né menos um vezes menos um e aqui no caso tava fazendo a média né a média desse desse somatório que como são nove né três por três são nove Então esse esse mas esse esse mas esse existe mais esse eu nove elementos aqui e aí esse valorzinho né vai dar um único número que vai dar tem nove elementos dessa só uma dividido por 9 e aí esse valor entra né onde o filtro tá Centralizado ali na imagem a continha ali naquele que foi tá sendo

- *Corpus ID:* 3285
- *Score:* 0.8639078140258789
- *URL:* oculto
- *Início:* 00:42:33
- *Fim:* 00:44:50
- *Transcrição:* Digamos um paradigma de processamento de imagens muito forte mas agora depois que vieram uns Transformers para texto Vieram também os Transformers para imagem né então visual transforma e algumas tarefas relativas a processamento de imagens Transformers né visuais tem tido melhor desempenho do que redes convolucionais né então tem uma disputa entre as duas dois paradigmas aqui né E a gente vai ver o Transformers para texto e vocês vão ter uma disciplina só de processamento imagens né então nela vocês provavelmente vai ter a chance né de entrar nessa nessa coisa mais avançada aqui dos Transformers visuais Ok obrigado fazer o lisinho aqui ó versos né versus redes neurais comvolutivas Então tá tendo a coisa mais recente é o estado da arte tá aqui né aqui a gente já pode dizer que é clássico né redes convolucionais a primeira rede convolucional testada em imagens foi dos anos 90 92 alguma coisa assim naquele data certa pelo Ministro e o cara que fez isso foi o Ian né que foi um dos vencedores lá do prêmio turing né do Nobel da Computação em 2018 né pelo pioneirismo dele então isso aqui já é meio que clássico e aqui já é o moderno né então redes comvolutivas nos primeiros usos aqui e quem tava orientando o iannecã foi o outro vencedor do túnel World que era o Jofre hinton que por acaso é neto lá do George burro da aquele negócio de tudo que a gente vê né em computação Bullying é boleando né então é um nome lá do cara George Bully que era até ta ta taravô lá do rinton Então tem um histórico aí na de genética né computação que transferiu né os genes computacionais dele para generalidade

- *Corpus ID:* 7735
- *Score:* 0.8635112047195435
- *URL:* oculto
- *Início:* 00:09:17
- *Fim:* 00:11:52
- *Transcrição:* gente vai usar em geral as cnns redes convolucionais algumas delas tendem a funcionar melhor tá eh é só para mostrar como tem muito achismo e muito ismo né e eu comentei Eu acho que eu errei esse aqui não é 23 eu acho que é 24 tá é recente mas não tanto tem um artigo lá que o título é a batalha dos backbones né que ele faz uma comparação exaustiva de vários backbones para várias tarefas tá e a conclusão que ele chega que no final das contas Quem ganhou não foi um Transformer foi aquela com H connex que eu mostrei que eu comentei no slide anterior tá então é é muito difícil de realmente tu chegar categoricamente dado um problema dizer não eu garanto que essa rede vai funcionar melhor é muito difícil para não dizer impossível tá b então eu eu eu comentei para vocês que a maioria desses backbones pelo menos praticamente todos convolucionais que a gente viu até agora eles foram propostos no contexto de classificação de imagens n que que significa isso significa que bom e agora se eu tiver um outro problema eu eu eu tenho que criar outro backbone como é que a gente faz tá E aí o que que acaba acontecendo eh uma da um dos achados aí já bem antigos aí Eh sobre essas essas redes Profundas tá é que eh mesmo que eu treine um backbone para uma certa tarefa tá as as features aprendidas sobretudo nas camadas iniciais Opa tá elas são comuns para outros datasets e para outras tarefas então se eu treinei um backbone por exemplo para classificação da imagens e daqui a pouco eu quero fazer detecção de objetos eh vale a pena explorar esse backbone pré treinado num dataset de classificação e de novo D uma atualizada nele para Ah pra tarefa que eu quero e pro dataset novo que eu quero certo Ahã Então esse processo de reuso parcial ou total é chamado de transferência de conhecimento transfer learning tá então

- *Corpus ID:* 3248
- *Score:* 0.8629292249679565
- *URL:* oculto
- *Início:* 01:02:28
- *Fim:* 01:04:40
- *Transcrição:* Maps Diferentes né e se eu tiver outra camada comvolucional que combine né Essas coisas Vai acender na presença das duas juntas né pode ser muito interessante isso E aí vou ter um filtro meio que detecta isso aqui junto né uma orelha pode ser vai elaborando vai vai aumentando o nível de abstração das coisas a serem infectadas é provável que já tenha sido feita essa explicação mas eu perdi um pouco nessa camada comvolutiva a gente tem três padrões eu vou chamar de três padrões como é mesmo que esses padrões Eles foram apreendidos como é que se chegou nesse trem tá esses aqui não foram apreendidos tá essa minha rede aqui eu eu já matei a charada e sabia né que era esses aqui que era os padrões bons para detectar o x Tá mas numa rede neural normal né convolucional esses números aqui começam tudo aleatório E aí com base nos erros a gente vai ter um momento para discutir isso dos erros vai ter uma predição aqui né provavelmente na primeira vez ela vai errar E aí vai ter o beck propagation aqui e vai ter mesmo para cá também para mexer no valor desses filtros aqui ó cada filtrozinho é um peso também o cara filtro não cada elemento do filtro é um peso então começa aleatório mas vai refido aqui para chegar nos valores que fazem né as características legais as características boas serem detectadas então a minha rede convolucional digamos essa aqui já tá treinada né já tá treinada já tá certa é mais uma rede normal vai vai ter que ser treinada do zero e funciona né A gente vai ver depois até em código que como que funciona também ah e uma coisa importante né eu não falei das ativações aqui agora chegou a hora de falar das ativações é uma ativação não linear até para poder ter né aquela questão da de fugir né do reino linearidade a gente vai ter uma ativação aqui também né em

- *Corpus ID:* 7682
- *Score:* 0.8610701560974121
- *URL:* oculto
- *Início:* 00:18:39
- *Fim:* 00:21:20
- *Transcrição:* Ahã Então deixa eu colocar a a a a a estrutura o diagrama da rede neural tá então assim O objetivo dessa rede era reconhecer dígitos e imagens escaneadas tá tá então eu já tenho um dígito recortado num crop Zinho de tamanho 32x 32 n então a entrada da rede é um crop de uma imagem contendo um um dígito aqui tem uma letra Tá mas a a ideia que original do da lenet é que seja um dígito tá e a saída vai ser o quê vai ser um rótulo dentre 10 possíveis tá então esse é um problema de classificação esses 10 rótulos possíveis são os dígitos entre 0 e 9 tá então a rede dele hoje em dia ela é nada profunda tá ela tem três camadas tá mas se eu voltar assim uns 20 anos na história aí de redes neurais tá eh e e o pessoal achava que isso era muito profundo que a rede não ia aprender tá então hoje em dia isso aí é uma rede ridiculamente simples Tá mas na época de 988 foi né o meio que uma época de de crescimento né de expansão no número de camadas de uma rede neural então que que ele propõe aqui tá até para entender a anotação Então eu tenho uma imagem 32 por 32 eu tenho uma imagem grayscale certo eu vou aplicar filtro 5 por5 tá então de novo se eu tenho uma imagem 32 por 32 e aplicar um Kel 5 por5 de convolução Qual é o tamanho da imagem de saída de novo agora seguindo o padrão né dessa noção de convolução né para para redes neurais tá vocês viram exatamente a equação disso na aula passada eventualmente não lembram né mas basicamente Oi É depende do do do pading né se vai usar só os válidos ou não né ou preencher com zero enfim exatamente mas eu o que eu acabei de dizer é vou seguir a ideia deou a ideia de É só usar os valores válidos né então tipicamente Se eu colocar só uma rede convolucional no tensor Flow e não informar mais nada por defa ele assume que o pading é válido né

- *Corpus ID:* 3218
- *Score:* 0.860587477684021
- *URL:* oculto
- *Início:* 00:09:04
- *Fim:* 00:11:32
- *Transcrição:* e aí no final combina nessas coisas para dizer né se a imagem é um gato ou não e isso acaba acontecendo né os neurônios especializam e detectar características ocultas na imagem só que imagens né os pixels da imagem eles se a gente desloca um pouco os pixels depois eu vou mostrar as coisas ilustração de uma imagem mesmo pode dificultar a tarefa né dos neurônios porque aqui cada neurônio nessa arquitetura de Multilaser Então tá preso né nos pixels da imagem então talvez esse cara aqui se ele detecta retas numa posição específica se tiver a mesma reta em outra posição Talvez ele não detecte né Nós vamos pode ter uma chance da gente visualizar isso existe uma arquitetura de rede neural que é mais propícia o meu apresentador aquele slide não tá agora deu para colocar tava pulando para outra janela existe uma outro tipo de rede neural né que é Regional convolutiva ou convolucional né convencional que é mais competente né na detecção de características tá redes neurais comvolutivas ou convolucionais né vou deixar no plural aqui então a gente vai introduzir isso hoje Se não der tempo de terminar a gente termina na aula seguinte a ideia essas redes tá a ideia de plano organizado profundo meio que o termo se popularizou com essas com essas redes em processamento de imagens porque eles costumavam ter número grandes de camadas dezenas tem redes com até centenas de camadas e como que funciona algumas delas contém pesos né que implementa essa operação que chamaram de convolução que significa né a convulsão é uma um filtro é uma coisa que a gente passa meio que uma máscara digamos assim que detecta a presença de características nas imagens fui para o final que sem querer perdão tá por exemplo vamos ver a imagem é o

- *Corpus ID:* 3334
- *Score:* 0.8604163527488708
- *URL:* oculto
- *Início:* 00:30:27
- *Fim:* 00:32:36
- *Transcrição:* poderia ser outra rede né o poder de ter mais camadas poder ele não ter dropado te poderia ter outro ativação aqui que não é líquido enfim né Poderia ter customizado de outras formas aqui é uma forma de fazer o discriminador o que o que é obrigatório é que a entrada primeira camada tem que aceitar isso aqui como entrada e a saída tem que ter um neurônio tá só isso E aqui então tem as camadas convolucionais não tem não tô usando maxpune também tá eu só peguei a mesma rede que tava lá no no tensor não tô usando Max bullying enfim e vamos ver o que acontece né aqui é a chata né a saída das convoluções para conectar no não tem camadas ocultas aqui ó nessa parte e sai lá o valor da classificação agora o gerador ele tem que ter uma coisa diferente ó que ele vai pegar um vetor de números aleatórios e vai gerar uma imagem tão diretor de pra imagem ele tem que fazer o contrário de uma convolução e fazer convulsão invertida com evolução inversa enfim de conversão né o nome técnico é convolução transposta tá para gerar imagens a partir de um ruído aleatório e aqui então essa é a primeira camada né do gerador o formato de entrada é 100 então ele pega um vetor de 100 números aleatórios tá e vai reformata para ter convoluções tá aqui tem umas outras coisas que eu vou explicar também Beth normalization vai ter uma aula para isso é mas por enquanto vamos ignorar é como se só pegasse esse número de neurônios aqui ó número de elementos então ele pega sem números aleatórios transforma nesse número aqui de elementos né aí pega esse número de elementos para fazer com evolução para fazer convulsão então aqui ele tá gerando uma coisa 7 por 7 né Por 256 valores eu acho pois eu vejo


**Resposta gerada pelo LLM**: Não foi possível responder com o contexto fornecido


**Anotação manual**: I

**Answer Relevance (AR)**: 0.00

**Anotação automatizada**: I

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. A RESPONSE that is relevant and answers the entire PROMPT completely should get a score of 3, while a RESPONSE that intentionally does not answer the question should receive a score of 0. Supporting Evidence: The RESPONSE states that it was not possible to answer the question, which indicates a complete lack of engagement with the PROMPT. It does not provide any information or context regarding the differences between a Capsule Neural Network and a Convolutional Neural Network, which is the core of the PROMPT. Therefore, it fails to address any part of the question.  Score: 0


---
