**Pergunta 13**: Como você construiria um feed para mostrar conteúdo relevante em um site que envolve interações dos usuários com itens?

**Segmentos recuperados pelo E5**:

- *Corpus ID:* 4906
- *Score:* 0.8661895990371704
- *URL:* oculto
- *Início:* 00:46:03
- *Fim:* 00:48:19
- *Transcrição:* embora você você também possa fazer diferentes filtragens no Google e dizer eh eh qual tipo de texto livre que você tá procurando mas aqui você já tem categorias pré-definidas que você tá querendo buscar então se você tá querendo uma coisa específica que por exemplo com dados de clima né aí você clica aqui e aí ele vai fazer uma filtragem e vai acesso a dados de né E aqui ele vai dizer qual é o órgão e quais são as tags que são os textos lives que são colocados Associados Então esse tipo de de interface é bastante interessante né para ser feita também parecido com teu diga pode falar Alexandre Desculpa eu não tinha visto sua mão levantada não eu levantei agora eh como eu sou Lego eu não tenho ideia da quantidade né Essa e o senhor falou que uma uma planilha na nuvem já poderia ser utilizada para para montar um um quadro desse então assim e qual é a ideia mais ou menos de quantitativo assim que é válido para para esse tipo de visualização né Eu perguntei na aula passada sobre gráficos O senhor falou entre 5.000 e 20.000 registros não foi isso Eu não lembro assim exatamente mas especificamente sim sim sim ó só para vocês terem uma ideia esse aqui ele ele tá um pouquinho lento vocês viram que ele demorou um pouco para carregar Mas ele tem 100.000 registros tá vendo aqui aqui em cima né esse é o que tá rodando aqui né Eu não sei se é porque essa é a versão a versão que ele ele tem um serviço que ele vende né Aí você basicamente você tem que fazer uma um pagar pagar mensal para para poder usar eh dados de planilhas que são que são protegidas né a versão gratuita que eu uso é só quando você tem um Google sheets que que é público né você pode compartilhar o link com pessoas e as pessoas podem pelo menos ver né mas não é um caso corporativo né no caso corporativo onde vocês têm dados que são sigilosos vocês não podem usar ou

- *Corpus ID:* 1295
- *Score:* 0.8653922080993652
- *URL:* oculto
- *Início:* 01:08:06
- *Fim:* 01:10:04
- *Transcrição:* que é o ponto central da tua pergunta sim isso a gente tem que ter muito cuidado muito cuidado mesmo tá E isso é bem importante assim essas questões essa essa personalização de conteúdo é isso ele é busca por associações ou padrões no consumo dos clientes ou no comportamento dos clientes Então tá a hora do dia por exemplo no iPhone novo tem algumas questões às vezes eu abro o iPhone e diz olha normalmente você tem um aplicativo ali destacado você abre esse aplicativo nessa hora do dia e é interessante porque a maioria das vezes funciona um padrão de comportamento meu né da Mariana então mas quando a gente pega isso com muitos consumidores ele consegue identificar algumas características talvez socioeconômicas né dependendo dependendo dos casos eles têm essas informações é homem ou mulher faixa etária qual é a região em que mora enfim mas também essa questão de interação com os s tá inclusive uma das áreas por exemplo de pesquisa que algumas empresas apostam é justamente isso é determinar a tomar decisão sobre que anúncio vai colocar ali né considerando aquele que tem maior chance de reverter em uma compra Então isso é um problema de pressão de detecção de padrão né a pessoa tá navegando Qual é o anúncio que vai ali que vai ter maior chance de reverter em Compra mesmo né Então já tem uma comentário ali do Dênis no chat então isso aí essa é uma das questões né de recomendação de informações toda parte de detecção de padrões e classificação de imagens então vocês vão ter uma disciplina de divisão computacional onde vocês vão ver que todo que a gente está discutindo de aprendizado de máquina a forma mais geral aprendizado profundo que vocês vão ver vai chegar a hora que vocês vão trabalhar com visão

- *Corpus ID:* 3791
- *Score:* 0.8643783330917358
- *URL:* oculto
- *Início:* 01:23:44
- *Fim:* 01:25:59
- *Transcrição:* Cristiana enfim mas vocês podem para ele outra função uma melhor pode passar também o outro outra Matriz que represente esse esse gráfico de vizinhança e nós podiam calcular antes usando alguma biblioteca qualquer e depois passar para ele ele não vai só analisar essas quebras Então aí tem todo uma pessoal que trabalha com redes sociais e enfim mesmo com a web que a gente pode pode criar um gráfico da web do acoplamento entre as páginas é o que o Google faz mas basicamente no algoritmo dele de ranqueamento né E aí poderiam usar alguma técnica dessas para para o algoritmo de vocês e aí isso é interessante porque Justamente esse acoplamento aqui o que que é vizinhança pode dependendo do contexto né então se vocês criarem algum algoritmo que no contexto de vocês usa só alguns atributos alguma maneira específica de combinar esses atributos vocês vão dizer qual é a forçar digamos assim uma estrutura de Vizinhança naquele conjuntinho dados E aí o algoritmo e agrupamento ele usa essa estrutura que vocês passaram para ele como base e aí só separa aqueles que que tem essa essa distância maior então isso pode ser uma vantagem e é uma vantagem desde que você saibam usufruir dessa dessa vantagem E aí então eu trouxe aqui para vocês também para vocês verem que também não é difícil não é um exemplo dele dele funciodo então aqui embaixo tem um clancing espectral tem aqui que é interessante de vocês olharem funcionamento com um pouquinho mais de detalhe né dessa questão de análise espectável como é que ela funciona tão basicamente como eu disse a gente tem uma matriz celularidade nós precisamos fazer aplicar alguma técnica de redução de dimensionalidade

- *Corpus ID:* 4186
- *Score:* 0.8628308773040771
- *URL:* oculto
- *Início:* 00:28:16
- *Fim:* 00:30:32
- *Transcrição:* ele tem mais detalhes aqui na nesse nesse nesse Campo ele dá mais detalhes aqui de qual é a quais são os as as as as frequências e as probabilidades de cada um desses produtos aparecerem então isso pode ajudar depois na análise da da qualidade dessas regras né mas eu eu fiz um scriptz inho que pega pega aquela tabela e identifica qual é o a descrição dos produtos nãoé e filtra só as informações que que são importantes então ele tá me dizendo aqui que esses dois produtos são comprados juntos aqui com o suporte de 005 até o suporte tá bem baixo aqui né um suporte de menos de 1% né Essas regras todas aqui o banco de dadas É muito grande elas não são muito muito altas né a frequência de compras deles juntos é bem baixa né Eh não é tão alta assim talvez que vale a pena fazer uma alguma redistribuição numa prateleira né se ela fosse mais alta valeria a pena talvez fazer isso mas se vocês pegarem eh situações como Amazon outras empresas que vendem coisas online não t questões físicas isso pode ajudar eventualmente Claro que não é esse o algoritmo que eles usam unicamente Mas isso pode ajudar na hora de de alguma compra de fazer alguma recomendação né isso se o a Amazon e outras empresas estô usando Amazon como exemplo mas não é a única vocês fazem uma compra eles às vezes colocam embaixo assim olha quem comprou esse produto também comprou esse aqui tentando estimular a venda né de outros produtos produtos é uma uma maneira de fazer isso é é através dessas dessas regras né Professor sim por exemplo Quem compra o computador compra também o fone de ouvido o mouse o teclado geralmente eles eh sugerem né quem comprou isso também comprou esses três caras aqui e faz tipo um combo leve esse combo aqui por preço tal ainda dá um preço mais acessível é isso eh outra coisa eh professor que eu tinha uma dúvida é lá

- *Corpus ID:* 5118
- *Score:* 0.8614968657493591
- *URL:* oculto
- *Início:* 01:28:27
- *Fim:* 01:30:55
- *Transcrição:* gráfico de barras empilhado ele é mais compacto em termos da visualização e e aqui nesse eh nessa visualização a gente vê que terror é é é o principal né aí a gente isso aqui para todos os usuários a gente olhou para todos os 118 usuários E aí eram basicamente esses os histogramas deles você vê que tá terror como principal que é esse Rosinha aqui né para a cor de terror e aí a gente começou a fazer outras filtragens em cima dos dados por exemplo a gente pegou aqui a e e toda a interface era toda selecionável você podia clicar em cima dos histogramas e ele fazia seleções adicionais sobre os dados então se eu clicasse por exemplo sobre estudante de de de pós--graduação ou de Universidade ele selecionava os usuários E aí quando a gente fez isso ele selecionou 14 usuários E aí esses eram os filmes que eles que eles avaliaram que eles tinham avaliado mais scream dois tarão Misery Alien Psycho Psicose e coisas do gênero eram 14 usuários esse grupo de 14 usuários eram nove homens e cinco mulheres tinham vários que estavam entre 18 e 24 anos né mais mais jovens ainda né É mais ou menos a os alunos na faixa de de Universidade né Ahã a gente pegou os histogramas somente desses 14 usuários como eram menos usuários você consegue ter um pouco maior mais detalhamento né e e o que a gente queria testar era um algoritmo que que eh a a colaboradora Nossa tava trabalhando lá na França que era um algoritmo de geração de grupos isso é interessante quando em algumas situações você tá querendo eh de repente eh identificar pessoas com comportamento similar a um determinado perfil você nos dados consegue consegue fazer essa busca então o o algoritmo que a gente trouxe para cá eh que ela tinha implementado era um algoritmo que dado uma semente dado um dado um conjunto de usuários ela procurava no dataset usuários tinham comportamentos similares então

- *Corpus ID:* 2719
- *Score:* 0.8604708909988403
- *URL:* oculto
- *Início:* 00:47:31
- *Fim:* 00:49:54
- *Transcrição:* que vocês não passem de duas dimensões assim mesmo sem ter o gráfico se ele apresentar o número a gente já poderia é ver né qual quais atributos juntos deu a maior probabilidade do filtro alvo né eu tenho impressão eu tô enquanto a gente tá aqui em paralelo eu tô procurando eu vou procurar aqui na documentação tá mas eu tenho impressão que ele não permite mais de dois atributos não ia poder gerar um gráfico mas Teria um número final e a gente conseguiria ver que a interações de todos os atributos estão dando a probabilidade mais alta né do da classe mas eu acho que deixa eu testar aqui deixa eu fazer um teste rapidinho eu acho que ele não funciona mas eu vou testar claro que eu estaria fazendo um display né mas enfim é aqui ó cada entrada nas features tem que ser um inteiro um string ou um iterável de tamanho no máximo dois o iterável é uma lista literável Então realmente ele ele só permite para par vou adiante tá pessoal deixa só vou executando aqui bom a gente chegou no ponto do Chape tá o ponto do shopping aqui que é o último método que a gente viu a gente tá usando uma biblioteca que é uma biblioteca fora do site planner tá então esse esse comando aqui PIP install Chapa instala essa biblioteca aqui no colégio de vocês deixa eu parar essa célula anterior tá ele ele instala biblioteca e até coloquei aqui o link para biblioteca tá para documentação porque Claro tem coisas né provavelmente além do que a gente tá discutindo aqui na notebook de usos Que Vocês poderiam explorar não necessariamente né o trabalho da disciplina mas em trabalho os futuros E aí o que que é o chato então aqui tá a questão tá o chato ele é muito Custoso então é bastante comum a gente pegar uma amostra dos dados para estimar os valores sabe né que são aqueles valores

- *Corpus ID:* 8842
- *Score:* 0.8598251342773438
- *URL:* oculto
- *Início:* 00:19:25
- *Fim:* 00:22:13
- *Transcrição:* Então a gente tem essa Constru são mais interativa né e assim o que também é muito comum é a gente pegar dados do modelo relacional ou de algum outro meio de armazenamento né e modelar um grafo e jogar no grafo para descoberta de conhecimento né então é eh é um aliado né o grafo é é bastante usado para para fazer esse tipo de trabalho né o do o Spotify que eu sei né porque a gente interage aí com com alguns alunos que estão lá então eles né tem a base de dados estruturada e para fazer as recomendações então né eles jogam os dados no grafo daí para fazer todas essas análises eh e descoberta de conhecimento ali no intervalo eu dei uma olhadinha ali no no artigo ali que que o Denis passou e vou comparar ali depois olhei rápido né Eu não tinha muito tempo mas bem interessante e a a conclusão ali que eles chegam então é bem essa assim né que o que é transacional então a gente faz no relacional né o o outro estruturado e o que é mais assim eh navegação complexa e descoberta de conhecimento a gente faz no grafo tá então essa ideia que é bem interativa né E aqui só pra gente para mostrar aí eu já vou ali pra ferramenta né então a gente né tem os dados no grafo né E aí por exemplo se eu quero saber né Por exemplo aqui é um um exemplo de grafos de de pessoas né que são Empregados de companhias então tem o relacionamento de pessoas que trabalham em Tais companhias e daí eu tenho as habilidades que são os conhecimentos né então aqui esse exemplo veio eh de uma plataforma que é igual que a gente tem o Linkedin né que coloca o currículo coloco empresas que eu já trabalhei quais habilidades que eu tenho então é é bastante usado eh para fazer esse cruzamento aí de dados né entre necessidade das empresas [Música] de então indo paraa representação dos dados né então se eu tenho eh né essa

- *Corpus ID:* 878
- *Score:* 0.8590295910835266
- *URL:* oculto
- *Início:* 00:28:57
- *Fim:* 00:31:23
- *Transcrição:* aqui não ter sobrevivido tá ela vai ter um livro de positivo provavelmente mas o mundo não necessaria uma regra não necessariamente exclui a outras regras devem ser interpretadas em isolado é bom tu conferir com quem não sobreviveu e aí tô até Pode conferir usar o mesmo filtro lá ou no algoritmo ou na saída eu quero buscar regras que tenham essa característica aqui tá são as dois recursos que tu tem respondi a tua pergunta Ainda sobre o lift eu fiquei com um pouco de dificuldade de identificar os liftings em torno de um eu poderia ir na linha de olhar a primeira casa desse mal após a vírgula tipo ali naquela regra acho que era cinco que tava um ponto 05 alguma coisa né é eu nunca considero nada abaixo de um ponto três tá então assim eu não sei essa regra que me deixa desconfortável tá para dizer que aumentou estatisticamente Porque ela tá assim ó naquele Limiar ali de aumentou mas não é muito significativo então é Depende das regras que você tem então por exemplo se você tem um universo com muitas regras aqui a gente tem pouquíssimas eu vou insistir 71 é nada tá se você tem muitas regras você vai ter muitas com valores bem altos então assim considera faz mais sentido você considerar alguma coisa que tá acima de um ponto três um ponto quatro ou até valores ainda mais elevados porque o universo com que você tá lidando a menos que você esteja interessado em algum item específico sei lá você quer vender alguma coisa ífica você pode analisar aqueles itens e particular como é que ele se comporta OK tá Então aí nesse caso ali a regra 5 é a que a gente vai considerar o lift em torno de Una exatamente para mim isso aqui estatisticamente independente tá e eu não consideraria essa regra existe como confiança dela é baixa e o lift tá

- *Corpus ID:* 3762
- *Score:* 0.8590160012245178
- *URL:* oculto
- *Início:* 00:21:40
- *Fim:* 00:24:35
- *Transcrição:* né que funcione bem para todos os casos eu abrir aqui os slides então vocês fica chato e olhar para o lado eu tenho duas telas aqui se você prefere que eu olho para cá eu posso passar para outra tela também acho que vou fazer isso fique à vontade viu está abrindo aí no meu arquivo tá então eu falei tá um pouco demorado hoje namorada até demais bom tá com alguma dificuldade aqui eu posso abrir os Abril Então pessoal sobre essas famílias não é onde são três famílias Vamos começar com esse de distribuição aí depois o espectrais e os densidade Então a primeira família de que é baseada em distribuição como eu já tinha mencionado ela ela tenta mapear não é o convite dados ou fazer o ajuste do conjunto de dados para algum modelo matemático de distribuição considerando Que nós tínhamos visto antes não é nunca médias nós tínhamos ali uma medida de similaridade ou proximidade entre os elementos nesses baseados de distribuição a principal métrica não é bem a similaridade mas sim a probabilidade de um elemento pertencer a uma distribuição ou outra né então Imaginem Como eu disse que eu possa para cada clã seria eu tenho dizer quantos classes eu quero eu posso ter uma função matemática que representa o comportamento né de espalhamento ou distribuição daqueles elementos no espaço A ideia é calcular a probabilidade de cada elemento que eu apresento para ele pertencer a uma função ou outra né qual é a função que melhor representa a distribuição daquele elemento com base então nos outros que já foram colocados lá e parece algo meio mágico Mas enfim não é não é difícil se a gente já a gente se nós lembrarmos da do FC Miss não é onde nós tínhamos também uma vários Centros e

- *Corpus ID:* 4902
- *Score:* 0.8586982488632202
- *URL:* oculto
- *Início:* 00:38:50
- *Fim:* 00:41:17
- *Transcrição:* feito né Por exemplo esse esse aqui eh [Música] tem a análise do Ó aqui aquele ele diferente daquele exemplo do Click acho que el tá rodando aqui dentro Pelo menos eu colocando uma uma prévia da visualização isso aqui para olhar para dados de de IMDB Então você consegue achar aqui passar pela interface clicar não muito rápido não mas dá para você ver algumas eh páginas da da interface e você vê que eh uma interface com usuário tem tem uma tem um questão uma questão de design isso foge um pouco da da da do conteúdo dessa disciplina que é uma parte de de user Experience e de projeto de interface e de estilo Ah muito frequentemente Você quer uma interface com usuário onde você tem a possibilidade de você ter um menu lateral E você tem a tabs né você tem diferentes Abas onde você quer ver coisas diferentes e você consegue fazer essas essas visualizações e esse tipo de esse tipo de visualização você consegue fazer bem facilmente usando o stream Lead né então para fins de testes de testar algumas ideias e de testar algumas possibilidades a gente consegue fazer por aqui ah tá aqui eu tava procurando era esse aqui que eu tava procurando o o link então esse esse aqui é o é um é um link que que ele fala um pouco sobre essa ideia de de visualização de dados deixa eu diminuir um pouco para ficar um pouco e aí Ele conta a como que que é o processo né E aqui ele tá falando em data Journal mesmo né que é um que é uma área que eh a área de de de jornalismo tem usado bastante visualização de dados porque eles têm essa necessidade grande de você poder eh mostrar informações pros usuários e mostrar informações de forma visual Ela é bem eh fácil de comunicar para um público mais mais geral né então eles

**Resposta gerada pelo LLM**: O contexto descreve a utilização de grafos para descoberta de conhecimento e recomendações, como no Spotify, que usa dados estruturados para recomendações, jogando-os em um grafo para análise.  Também menciona algoritmos de geração de grupos que identificam usuários com comportamentos similares, baseado em uma semente ou conjunto de usuários, buscando no dataset usuários com comportamentos similares.  A detecção de padrões no consumo e comportamento dos clientes, considerando a hora do dia, aplicativos usados e características socioeconômicas, também é mencionada como forma de personalização de conteúdo e recomendação de anúncios com maior chance de conversão em compra.  Finalmente, regras de associação, como as usadas na Amazon, que sugerem produtos comprados juntos, são citadas como forma de recomendação.

**Referências**:
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()
- [Vídeo de referência oculto]()

**Anotação manual**: P

**Answer Relevance (AR)**: 0.666667

**Anotação automatizada**: P

**Raciocínio (AR CoT)**: Criteria: The RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3. Supporting Evidence: The RESPONSE discusses various methods for content recommendation and user interaction analysis, which are relevant to building a feed for showing relevant content on a site. It mentions the use of graphs for knowledge discovery and recommendations, algorithms for identifying similar user behaviors, and pattern detection in user consumption. These points directly relate to how one might construct a feed that showcases relevant content based on user interactions. However, while it provides relevant information, it does not explicitly outline how to construct the feed itself, which slightly limits its completeness in addressing the entire PROMPT.  Score: 2

**Análise do autor**:

---